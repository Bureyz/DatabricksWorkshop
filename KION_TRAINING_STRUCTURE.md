# KION Databricks Training - Skonsolidowana Struktura Szkoleniowa

**Data**: 19 listopada 2025  
**Program**: 3-dniowe szkolenie Databricks dla KION  
**Å¹rÃ³dÅ‚o**: KION_DETAIL agenda
Notebooki w formacie jupiter (JSON)

---

## Zoptymalizowana struktura katalogÃ³w

```
databricks-dea-training-kion/
â”œâ”€â”€ DZIEN_1_Fundamentals_Exploration/
â”‚   â”œâ”€â”€ 01_databricks_lakehouse_intro.ipynb
â”‚   â”œâ”€â”€ 02_data_import_exploration.ipynb
â”‚   â”œâ”€â”€ 03_basic_transformations_sql_pyspark.ipynb
â”‚   â”œâ”€â”€ 04_data_cleaning_quality.ipynb
â”‚   â”œâ”€â”€ 05_views_workflows.ipynb
â”‚   â””â”€â”€ workshops/
â”‚       â”œâ”€â”€ 01_workspace_data_exploration_workshop.ipynb
â”‚       â”œâ”€â”€ 02_transformations_cleaning_workshop.ipynb
â”‚       â””â”€â”€ 03_views_basic_jobs_workshop.ipynb
â”œâ”€â”€ DZIEN_2_Lakehouse_Delta_Lake/
â”‚   â”œâ”€â”€ 01_delta_lake_operations.ipynb
â”‚   â”œâ”€â”€ 02_medallion_architecture.ipynb
â”‚   â”œâ”€â”€ 03_batch_streaming_load.ipynb
â”‚   â”œâ”€â”€ 04_bronze_silver_gold_pipeline.ipynb
â”‚   â”œâ”€â”€ 05_optimization_best_practices.ipynb
â”‚   â””â”€â”€ workshops/
â”‚       â”œâ”€â”€ 01_delta_medallion_workshop.ipynb
â”‚       â”œâ”€â”€ 02_ingestion_pipeline_workshop.ipynb
â”‚       â””â”€â”€ 03_end_to_end_bronze_silver_gold_workshop.ipynb
â”œâ”€â”€ DZIEN_3_Transformation_Governance_Integrations/
â”‚   â”œâ”€â”€ 01_advanced_pyspark_transformations.ipynb
â”‚   â”œâ”€â”€ 02_lakeflow_pipelines.ipynb
â”‚   â”œâ”€â”€ 03_databricks_jobs_orchestration.ipynb
â”‚   â”œâ”€â”€ 04_unity_catalog_governance.ipynb
â”‚   â”œâ”€â”€ 05_bi_ml_integrations.ipynb
â”‚   â””â”€â”€ workshops/
â”‚       â”œâ”€â”€ 01_advanced_transformations_workshop.ipynb
â”‚       â”œâ”€â”€ 02_lakeflow_orchestration_workshop.ipynb
â”‚       â””â”€â”€ 03_governance_integrations_workshop.ipynb
â”œâ”€â”€ 
â”‚   00_setup.ipynb
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ sample_data/
â””â”€â”€ README.md
```

---

## Konwencje nazewnictwa

### Notebooki demo/teoria (gÅ‚Ã³wny folder dnia):
- **Format**: `01_nazwa_tematu.ipynb`
- **ZawartoÅ›Ä‡**: Teoria + Live coding + PrzykÅ‚ady demonstracyjne
- **Cel**: Prowadzone przez instruktora

### Notebooki warsztatowe (folder workshops/):
- **Format**: `01_nazwa_workshop.ipynb`
- **ZawartoÅ›Ä‡**: Zadania TODO + Luki w kodzie + Weryfikacja
- **Cel**: Praktyczne Ä‡wiczenia dla uczestnikÃ³w

---

## Mapowanie do agendy KION_DETAIL

### ðŸ“… DZIEÅƒ 1 â€” Fundamentals & Exploration

#### Notebooki demo:

**01_databricks_lakehouse_intro.ipynb**
- Koncepcja Lakehouse (Data Lake + Data Warehouse)
- Elementy platformy: Workspace, Catalog Explorer, Repos, Volumes, DBFS
- Compute: clusters, autoscaling, spot instances, Photon Engine
- Notebooks: magic commands (%sql, %python, %fs, %md)
- Unity Catalog overview: katalogi, schematy, tabele
- RÃ³Å¼nice miÄ™dzy Hive Metastore a Unity Catalog

**02_data_import_exploration.ipynb**
- Formaty danych: CSV, JSON, Parquet, Delta
- Ingest danych do dataframe z CSV,JSON,Parquet
- DataFrame Reader API: spark.read.format().option().load()
- Opcje readera: header, delimiter, schema, inferSchema, mode
- Konstruowanie schematÃ³w: StructType / StructField
- Podstawowe operacje eksploracyjne: columns, dtypes, count(), summary()

**03_basic_transformations_sql_pyspark.ipynb**
- Transformacje na przemian w pyspark i sql
- Transformacje kolumnowe: select(), withColumn(), drop(), alias()
- Logika warunkowa: when() / otherwise()
- Operacje tekstowe: regexp_replace(), trim(), lower(), upper()
- Filtry i sortowanie: filter(), where(), orderBy()
- Agregacje: groupBy(), agg(), rollup, cube
- SQL equivalents: CREATE VIEW, SELECT, GROUP BY, CASE WHEN

**04_data_cleaning_quality.ipynb**
- ObsÅ‚uga wartoÅ›ci pustych: fillna(), dropna(), coalesce()
- Walidacja typÃ³w: cast(), to_date(), to_timestamp()
- Deduplikacja: dropDuplicates() - all columns vs key columns
- Standardyzacja: formaty dat, tekstÃ³w, kategorii
- Typowe problemy jakoÅ›ci: whitespace, niepoprawne kody, inconsistent formatting

**05_views_workflows.ipynb** 
- RÃ³Å¼nice: VIEW vs TABLE vs DELTA TABLE
- Temp views, global temp views, persistent views
- Rejestracja tabel w Unity Catalog
- PrzeglÄ…danie tabel w Catalog Explorer
- Proste pipeline'y notebookowe - w workflow
- Databricks Jobs overview: taski, retry, harmonogramy

#### Warsztaty:

**01_workspace_data_exploration_workshop.ipynb** (90 min)
*Konsoliduje: Workspace setup + Data import + Exploration*
- Konfiguracja workspace i klastrÃ³w
- Wczytywanie rÃ³Å¼nych formatÃ³w (CSV, JSON, Parquet, Delta)
- Podstawowa eksploracja danych
- Konstruowanie schematÃ³w
- Analiza brakÃ³w danych i wartoÅ›ci unikalnych

**02_transformations_cleaning_workshop.ipynb** (90 min)
*Konsoliduje: Transformacje + Data cleaning*
- Transformacje kolumnowe i warunkowe
- Filtry, sortowania, agregacje
- SQL vs PySpark comparison
- Czyszczenie: nulls, duplikaty, walidacja typÃ³w
- Quality checks i flagowanie problemÃ³w

**03_views_basic_jobs_workshop.ipynb** (60 min)
*Konsoliduje: Views + Basic workflows*
- Tworzenie rÃ³Å¼nych typÃ³w widokÃ³w
- Rejestracja tabel w Unity Catalog
- Prosty pipeline notebookowy
- Podstawowa konfiguracja Databricks Jobs

---

### ðŸ“… DZIEÅƒ 2 â€” Lakehouse & Delta Lake

#### Notebooki demo:

**01_delta_lake_operations.ipynb**
- Delta Lake core features: ACID, Delta Log, Schema enforcement
- Schema evolution (additive, automatic)
- Time Travel i Copy-on-write
- CRUD operations: CREATE TABLE, INSERT, UPDATE, DELETE
- MERGE INTO - logika zmian na kluczach
- DESCRIBE DETAIL, DESCRIBE HISTORY
- Optymalizacja: OPTIMIZE, ZORDER BY, VACUUM

**02_medallion_architecture.ipynb**
- Bronze / Silver / Gold - logika warstw
- ETL vs ELT approach
- Zasady projektowania pipeline'Ã³w
- Partitioning strategy
- Audyt i lineage - metadane w kaÅ¼dym kroku
- Data quality w kontekÅ›cie warstw

**03_batch_streaming_load.ipynb**
- COPY INTO: kiedy uÅ¼ywaÄ‡, parametry (FILEFORMAT, VALIDATION_MODE, PATTERN)
- Auto Loader (CloudFiles): file notification, checkpointing, schema inference
- Schema evolution w praktyce
- Structured Streaming: micro-batch architecture
- readStream() / writeStream()
- Triggering: once vs processingTime
- ZarzÄ…dzanie checkpointami
- MERGE na streamingu

**04_bronze_silver_gold_pipeline.ipynb**
- Bronze: raw load + audit columns (ingest_ts, source_file, ingested_by)
- Silver: cleaning, deduplikacja, sanity checks, JSON flattening (from_json, explode)
- Gold: KPI modeling, agregacje (daily/weekly/monthly), star schema vs denormalizacja

**05_optimization_best_practices.ipynb**
- Optymalizacja zapytaÅ„: predicate pushdown, file pruning, column pruning
- Analiza planu: explain()
- Optymalizacja tabel: partitioning keys, ZORDER use cases
- Small files problem
- Auto optimize / auto compaction

#### Warsztaty:

**01_delta_medallion_workshop.ipynb** (90 min)
*Konsoliduje: Delta operations + Medallion architecture*
- Delta CRUD operations (CREATE, INSERT, UPDATE, DELETE, MERGE)
- Time Travel hands-on
- Projektowanie Bronze/Silver/Gold architecture
- OPTIMIZE, ZORDER, VACUUM w praktyce

**02_ingestion_pipeline_workshop.ipynb** (90 min)
*Konsoliduje: COPY INTO + Auto Loader + Streaming*
- COPY INTO batch loads
- Auto Loader setup i konfiguracja
- Schema inference i evolution
- Structured Streaming basics
- Checkpointing setup

**03_end_to_end_bronze_silver_gold_workshop.ipynb** (120 min)
*Konsoliduje: Kompletny pipeline + optymalizacja*
- Raw â†’ Bronze (ingest + audit)
- Bronze â†’ Silver (cleaning + standardization + JSON processing)
- Silver â†’ Gold (business models + aggregations)
- Performance optimization
- Query tuning

---

### ðŸ“… DZIEÅƒ 3 â€” Transformation, Governance & Integrations

#### Notebooki demo:

**01_advanced_pyspark_transformations.ipynb**
- Window Functions: rowsBetween, rangeBetween, partitionBy, orderBy
- Funkcje okienkowe: lag, lead, row_number, dense_rank, rank
- Rolling windows i agregacje ruchome
- Struktury zÅ‚oÅ¼one: explode(), posexplode(), sequence()
- JSON processing: from_json(), to_json(), schema_of_json()
- Funkcje datowe: date_trunc, date_add, add_months, last_day

**02_lakeflow_pipelines.ipynb**
- Koncepcje Lakeflow: deklaratywny sposÃ³b definicji pipeline'Ã³w
- SQL vs Python API
- Materialized views / streaming tables
- Expectations: warn / drop / fail
- Event log i lineage per tabela
- Automatic orchestration

**03_databricks_jobs_orchestration.ipynb**
- Multi-task Jobs
- Task types: notebook, DLT, dbt, SQL task
- Dependencies: depends_on
- Parametryzacja: job parameters, widget parameters (dbutils.widgets)
- Alerting i monitoring wykonania

**04_unity_catalog_governance.ipynb**
- Elementy UC: Metastore, Catalog, Schemas, Tables/Views/Functions, Volumes
- ZarzÄ…dzanie dostÄ™pami: GRANT, REVOKE
- Privileges: SELECT, MODIFY, CREATE TABLE, EXECUTE
- Masking i row-level security
- Securable objects - inheritance
- Lineage & Audit: end-to-end lineage, metadane tabel
- Audit logging i aktywnoÅ›Ä‡ uÅ¼ytkownikÃ³w
- Delta Sharing: secure data sharing protocol

**05_bi_ml_integrations.ipynb**
- Power BI: Direct Lake vs Direct Query, poÅ‚Ä…czenie do Gold Layer
- Modele semantyczne
- SAP Datasphere: Å‚Ä…czenie przez JDBC, ELT flow
- Federated query engines (Dremio, Athena)
- MLflow basics: experiments, metrics, parameters, artifacts
- Feature Store - podstawy
- Spark MLlib - proste modele
- Gold Layer jako ML dataset

#### Warsztaty:

**01_advanced_transformations_workshop.ipynb** (90 min)
*Konsoliduje: Window functions + Complex structures + Temporal*
- Window Functions praktyka (lag/lead, rank, rolling aggregations)
- JSON processing hands-on
- Date/time transformations
- Sequence operations

**02_lakeflow_orchestration_workshop.ipynb** (90 min)
*Konsoliduje: DLT + Databricks Jobs*
- Delta Live Tables pipeline creation
- Expectations setup (warn/drop/fail)
- Multi-task Databricks Jobs
- Dependencies i parametryzacja
- Monitoring i alerting

**03_governance_integrations_workshop.ipynb** (90 min)
*Konsoliduje: Unity Catalog + BI/ML integrations*
- Unity Catalog setup (catalogs, schemas, permissions)
- GRANT/REVOKE privileges hands-on
- Data lineage exploration
- Power BI Direct Lake connection
- MLflow experiment tracking
- Feature Store basics
- Gold layer â†’ ML dataset pipeline

---

## Konsolidacja warsztatÃ³w - uzasadnienie

### DZIEÅƒ 1: Z 5 â†’ 3 warsztaty

âœ… **Warsztat 1** (Workspace + Data + Exploration) - naturalna progresja: setup â†’ load â†’ explore  
âœ… **Warsztat 2** (Transformations + Cleaning) - spÃ³jny workflow: transform â†’ clean â†’ validate  
âœ… **Warsztat 3** (Views + Jobs) - logiczne poÅ‚Ä…czenie: persist results â†’ automate

### DZIEÅƒ 2: Z 5 â†’ 3 warsztaty

âœ… **Warsztat 1** (Delta + Medallion) - fundamenty: storage layer + architecture pattern  
âœ… **Warsztat 2** (Ingestion methods) - wszystkie metody Å‚adowania danych w jednym miejscu  
âœ… **Warsztat 3** (End-to-end pipeline) - kompletny, realistyczny use case

### DZIEÅƒ 3: Z 5 â†’ 3 warsztaty

âœ… **Warsztat 1** (Advanced transformations) - zaawansowane techniki w jednym warsztacie  
âœ… **Warsztat 2** (Lakeflow + Orchestration) - deklaratywne pipeline'y + automatyzacja  
âœ… **Warsztat 3** (Governance + Integrations) - bezpieczeÅ„stwo + downstream consumers

Korzystaj zdanych z folderu dataset w workshop i demo. 
