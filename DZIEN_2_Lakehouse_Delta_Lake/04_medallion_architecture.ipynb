{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "123ab80f",
   "metadata": {},
   "source": [
    "# Medallion Architecture: Bronze ‚Üí Silver ‚Üí Gold Pipeline - Demo\n",
    "\n",
    "**Cel szkoleniowy:** Praktyczna implementacja architektury medalionowej z transformacjami Bronze/Silver/Gold oraz technikami SCD (Slowly Changing Dimensions).\n",
    "\n",
    "**Zakres tematyczny:**\n",
    "- Medallion Architecture - pe≈Çny pipeline\n",
    "- Bronze Layer - raw data landing\n",
    "- Silver Layer - cleansing, deduplication, validation\n",
    "- Gold Layer - business aggregates, dimensional models\n",
    "- SCD Type 1 - overwrite changes\n",
    "- SCD Type 2 - historical tracking\n",
    "- CDC (Change Data Capture) patterns\n",
    "- Data quality checks\n",
    "- Audit & lineage metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f36d0e4",
   "metadata": {},
   "source": [
    "## Kontekst i wymagania\n",
    "\n",
    "- **Dzie≈Ñ szkolenia**: Dzie≈Ñ 2 - Delta Lake & Lakehouse Architecture\n",
    "- **Typ notebooka**: Demo + Implementation\n",
    "- **Wymagania techniczne**:\n",
    "  - Databricks Runtime 13.0+ (zalecane: 14.3 LTS)\n",
    "  - Unity Catalog w≈ÇƒÖczony\n",
    "  - Uprawnienia: CREATE TABLE, CREATE SCHEMA, SELECT, MODIFY\n",
    "  - Klaster: Standard z minimum 2 workers\n",
    "- **Zale≈ºno≈õci**: \n",
    "  - Wykonany notebook 01_delta_lake_operations.ipynb\n",
    "  - Wykonany notebook 02_batch_data_ingestion.ipynb (dla danych Bronze)\n",
    "  - Wykonany notebook 03_streaming_data_ingestion.ipynb (dla danych Bronze)\n",
    "- **Czas realizacji**: ~90 minut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc5afb8",
   "metadata": {},
   "source": [
    "## Wstƒôp teoretyczny - Medallion Architecture\n",
    "\n",
    "**Cel sekcji:** Zrozumienie architektury medalionowej jako fundamentalnego design pattern dla data lakehouse.\n",
    "\n",
    "---\n",
    "\n",
    "### Czym jest Medallion Architecture?\n",
    "\n",
    "**Medallion Architecture** to wielowarstwowy wzorzec organizacji danych w data lakehouse, kt√≥ry dzieli dane na trzy warstwy o rosnƒÖcej jako≈õci i warto≈õci biznesowej:\n",
    "\n",
    "```\n",
    "DATA SOURCES\n",
    "    ‚Üì\n",
    "ü•â BRONZE (Raw)\n",
    "    ‚Üì cleansing\n",
    "ü•à SILVER (Validated)\n",
    "    ‚Üì aggregation\n",
    "ü•á GOLD (Business)\n",
    "    ‚Üì\n",
    "CONSUMPTION\n",
    "```\n",
    "\n",
    "### Warstwy - Szczeg√≥≈Çowy Opis\n",
    "\n",
    "#### ü•â Bronze Layer - Raw / Landing Zone\n",
    "\n",
    "**Charakterystyka:**\n",
    "- Dane \"as-is\" bez transformacji warto≈õci\n",
    "- Append-only, immutable\n",
    "- Audit metadata: `_ingestion_timestamp`, `_source_file`, `_user`\n",
    "- Multi-format: JSON, CSV, Parquet, Avro\n",
    "- Schema-on-read approach\n",
    "\n",
    "**Retention:** 3-7 lat (d≈Çugoterminowa historia)\n",
    "\n",
    "**Use Cases:**\n",
    "- Data recovery (reprocess pipeline)\n",
    "- Audit trail & compliance\n",
    "- Historical analysis\n",
    "- Data science exploration\n",
    "\n",
    "**Przyk≈Çad Bronze Table:**\n",
    "```sql\n",
    "CREATE TABLE bronze.orders_raw (\n",
    "    order_id STRING,\n",
    "    customer_id STRING,\n",
    "    order_date STRING,        -- Raw string, nie parsed\n",
    "    total_amount STRING,      -- Raw string, nie validated\n",
    "    payment_method STRING,\n",
    "    _ingestion_timestamp TIMESTAMP,\n",
    "    _source_file STRING,\n",
    "    _rescued_data STRING      -- Schema evolution\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ü•à Silver Layer - Cleansed / Validated\n",
    "\n",
    "**Charakterystyka:**\n",
    "- **Deduplikacja** po kluczu biznesowym\n",
    "- **Walidacja**: NOT NULL, data types, ranges\n",
    "- **Standaryzacja**: dates, text, formats\n",
    "- **Business rules** enforcement\n",
    "- **Schema enforcement** (strict schema)\n",
    "- **Upsert/Merge** patterns (SCD)\n",
    "\n",
    "**Retention:** 1-2 lata (medium-term history)\n",
    "\n",
    "**Use Cases:**\n",
    "- Foundation for analytics\n",
    "- Joins & enrichment\n",
    "- ML feature engineering\n",
    "- Data quality monitoring\n",
    "\n",
    "**Przyk≈Çad Silver Table:**\n",
    "```sql\n",
    "CREATE TABLE silver.orders_clean (\n",
    "    order_id BIGINT NOT NULL,     -- Validated, parsed\n",
    "    customer_id BIGINT NOT NULL,\n",
    "    order_date DATE NOT NULL,     -- Parsed to DATE\n",
    "    total_amount DECIMAL(10,2),   -- Validated numeric\n",
    "    payment_method STRING,\n",
    "    _quality_score INT,           -- Data quality metric\n",
    "    _processing_timestamp TIMESTAMP,\n",
    "    _is_valid BOOLEAN\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ü•á Gold Layer - Business / Aggregates\n",
    "\n",
    "**Charakterystyka:**\n",
    "- **Pre-aggregated** summaries (daily, monthly, yearly)\n",
    "- **Denormalized** tables (joins pre-computed)\n",
    "- **KPI calculations** & business metrics\n",
    "- **Star schema** / dimensional models\n",
    "- **ML feature stores**\n",
    "- **Query-optimized** (partitioned, indexed)\n",
    "\n",
    "**Retention:** 6-12 miesiƒôcy (short-term, refreshable)\n",
    "\n",
    "**Use Cases:**\n",
    "- BI dashboards (Power BI, Tableau)\n",
    "- Executive reports\n",
    "- ML model training\n",
    "- Self-service analytics\n",
    "\n",
    "**Przyk≈Çad Gold Table:**\n",
    "```sql\n",
    "CREATE TABLE gold.daily_sales_summary (\n",
    "    report_date DATE NOT NULL,\n",
    "    payment_method STRING,\n",
    "    total_orders BIGINT,\n",
    "    total_revenue DECIMAL(15,2),\n",
    "    avg_order_value DECIMAL(10,2),\n",
    "    unique_customers BIGINT,\n",
    "    _computation_timestamp TIMESTAMP\n",
    ")\n",
    "PARTITIONED BY (report_date)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Kluczowe Zasady Medallion Architecture\n",
    "\n",
    "**1. Separation of Concerns**\n",
    "- Bronze: Ingestion\n",
    "- Silver: Data Quality\n",
    "- Gold: Business Logic\n",
    "\n",
    "**2. Incremental Processing**\n",
    "- Process tylko nowe/zmienione dane\n",
    "- Delta Lake MERGE operations\n",
    "- Checkpoint management\n",
    "\n",
    "**3. Idempotency**\n",
    "- Mo≈ºna uruchomiƒá wielokrotnie bez duplikacji\n",
    "- Deterministic transformations\n",
    "- Unique keys & deduplication\n",
    "\n",
    "**4. Schema Evolution**\n",
    "- Bronze: Flexible (rescued data)\n",
    "- Silver: Controlled (addNewColumns)\n",
    "- Gold: Strict (versioned)\n",
    "\n",
    "**5. Data Quality Gates**\n",
    "- Validate before promoting to next layer\n",
    "- Quarantine bad records\n",
    "- Monitoring & alerting\n",
    "\n",
    "---\n",
    "\n",
    "### ETL vs ELT w Medallion\n",
    "\n",
    "**Traditional ETL:**\n",
    "```\n",
    "Extract ‚Üí Transform ‚Üí Load\n",
    "         (outside DB)\n",
    "```\n",
    "\n",
    "**Medallion ELT:**\n",
    "```\n",
    "Extract ‚Üí Load (Bronze) ‚Üí Transform (Silver) ‚Üí Load (Gold)\n",
    "                 ‚Üì                    ‚Üì              ‚Üì\n",
    "             raw data          cleansed data    aggregates\n",
    "```\n",
    "\n",
    "**Dlaczego ELT?**\n",
    "- Zachowanie raw data (compliance)\n",
    "- Flexibility (re-transform later)\n",
    "- Scalability (Spark distributed processing)\n",
    "- Cost-effective (storage cheaper than compute)\n",
    "\n",
    "---\n",
    "\n",
    "### Medallion vs Traditional Data Warehouse\n",
    "\n",
    "| Feature | Traditional DWH | Medallion Lakehouse |\n",
    "|---------|-----------------|---------------------|\n",
    "| **Storage** | Proprietary (expensive) | Cloud object storage (cheap) |\n",
    "| **Schema** | Schema-on-write | Schema-on-read (Bronze) |\n",
    "| **Data Types** | Structured only | Structured + semi-structured |\n",
    "| **Flexibility** | Rigid | Flexible (schema evolution) |\n",
    "| **Raw Data** | Discarded | Preserved (Bronze) |\n",
    "| **Processing** | ETL (batch) | ELT (batch + streaming) |\n",
    "| **Cost** | High (compute + storage) | Lower (decouple compute/storage) |\n",
    "| **Use Cases** | BI & reporting | BI + ML + data science |\n",
    "\n",
    "---\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "**1. Naming Conventions:**\n",
    "```\n",
    "bronze.{source_system}_{entity}_raw\n",
    "silver.{entity}_clean\n",
    "gold.{business_domain}_{aggregation_level}\n",
    "```\n",
    "\n",
    "**2. Partitioning:**\n",
    "- Bronze: Ingestion date (`_ingestion_date`)\n",
    "- Silver: Business date (`order_date`, `transaction_date`)\n",
    "- Gold: Report date (`report_date`)\n",
    "\n",
    "**3. Metadata Columns:**\n",
    "```python\n",
    "# Bronze\n",
    "_ingestion_timestamp, _source_file, _user\n",
    "\n",
    "# Silver\n",
    "_processing_timestamp, _quality_score, _is_valid\n",
    "\n",
    "# Gold\n",
    "_computation_timestamp, _version\n",
    "```\n",
    "\n",
    "**4. Refresh Cadence:**\n",
    "- Bronze: Real-time / hourly\n",
    "- Silver: Hourly / daily\n",
    "- Gold: Daily / on-demand\n",
    "\n",
    "**5. Data Retention:**\n",
    "```python\n",
    "# Bronze: 3-7 years (compliance)\n",
    "spark.sql(\"ALTER TABLE bronze.orders SET TBLPROPERTIES (\n",
    "    'delta.logRetentionDuration' = '2555 days',\n",
    "    'delta.deletedFileRetentionDuration' = '2555 days'\n",
    ")\")\n",
    "\n",
    "# Silver: 1-2 years\n",
    "# Gold: 6-12 months (refreshable from Silver)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Pipeline Architecture Diagram\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                      DATA SOURCES                             ‚îÇ\n",
    "‚îÇ  ‚Ä¢ PostgreSQL  ‚Ä¢ MySQL  ‚Ä¢ APIs  ‚Ä¢ S3 Files  ‚Ä¢ Kafka          ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                         ‚îÇ COPY INTO / Auto Loader\n",
    "                         ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                   ü•â BRONZE LAYER                             ‚îÇ\n",
    "‚îÇ                                                               ‚îÇ\n",
    "‚îÇ  bronze.customers_raw      bronze.orders_raw                 ‚îÇ\n",
    "‚îÇ  bronze.products_raw       bronze.events_raw                 ‚îÇ\n",
    "‚îÇ                                                               ‚îÇ\n",
    "‚îÇ  Features:                                                    ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Raw data (as-is)                                          ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Append-only                                               ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Audit metadata                                            ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Long retention (3-7y)                                     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                         ‚îÇ MERGE (Dedup, Validate)\n",
    "                         ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                   ü•à SILVER LAYER                             ‚îÇ\n",
    "‚îÇ                                                               ‚îÇ\n",
    "‚îÇ  silver.customers_clean    silver.orders_clean               ‚îÇ\n",
    "‚îÇ  silver.products_clean     silver.events_clean               ‚îÇ\n",
    "‚îÇ                                                               ‚îÇ\n",
    "‚îÇ  Features:                                                    ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Deduplicated                                              ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Validated (types, nulls)                                  ‚îÇ\n",
    "‚îÇ  ‚Ä¢ SCD Type 1/2 (history)                                    ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Medium retention (1-2y)                                   ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                         ‚îÇ GROUP BY / JOIN / AGGREGATE\n",
    "                         ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                   ü•á GOLD LAYER                               ‚îÇ\n",
    "‚îÇ                                                               ‚îÇ\n",
    "‚îÇ  gold.daily_sales_summary                                    ‚îÇ\n",
    "‚îÇ  gold.customer_360                                           ‚îÇ\n",
    "‚îÇ  gold.product_performance                                    ‚îÇ\n",
    "‚îÇ                                                               ‚îÇ\n",
    "‚îÇ  Features:                                                    ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Pre-aggregated                                            ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Denormalized (star schema)                                ‚îÇ\n",
    "‚îÇ  ‚Ä¢ KPIs & metrics                                            ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Short retention (6-12m)                                   ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                         ‚îÇ\n",
    "                         ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                  CONSUMPTION LAYER                            ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Power BI  ‚Ä¢ Tableau  ‚Ä¢ SQL Analytics  ‚Ä¢ ML Models         ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf883f8",
   "metadata": {},
   "source": [
    "## Izolacja per u≈ºytkownik\n",
    "\n",
    "Uruchom skrypt inicjalizacyjny dla per-user izolacji katalog√≥w i schemat√≥w:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea85a738",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../00_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8374898b",
   "metadata": {},
   "source": [
    "## Konfiguracja\n",
    "\n",
    "Import bibliotek i ustawienie zmiennych ≈õrodowiskowych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ffa85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Wy≈õwietl kontekst u≈ºytkownika\n",
    "print(\"=== Kontekst u≈ºytkownika ===\")\n",
    "print(f\"Katalog: {CATALOG}\")\n",
    "print(f\"Schema Bronze: {BRONZE_SCHEMA}\")\n",
    "print(f\"Schema Silver: {SILVER_SCHEMA}\")\n",
    "print(f\"Schema Gold: {GOLD_SCHEMA}\")\n",
    "print(f\"U≈ºytkownik: {raw_user}\")\n",
    "\n",
    "# Ustaw katalog i schemat jako domy≈õlne\n",
    "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
    "\n",
    "# ≈öcie≈ºki do danych ≈∫r√≥d≈Çowych (za≈Ço≈ºenie: dane ju≈º w Bronze z poprzednich notebook√≥w)\n",
    "print(f\"\\n=== ≈πr√≥d≈Ça danych ===\")\n",
    "print(f\"Dataset base: {DATASET_BASE_PATH}\")\n",
    "print(f\"Customers: {DATASET_BASE_PATH}/customers\")\n",
    "print(f\"Orders: {DATASET_BASE_PATH}/orders\")\n",
    "print(f\"Products: {DATASET_BASE_PATH}/products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae7e5f2",
   "metadata": {},
   "source": [
    "## Sekcja 1: Bronze Layer - Raw Data Landing\n",
    "\n",
    "**Cel sekcji:** Zrozumienie roli Bronze layer jako landing zone dla raw data.\n",
    "\n",
    "### Bronze Layer - Kluczowe Cechy\n",
    "\n",
    "**1. Raw Data \"As-Is\"**\n",
    "- Dane zapisywane bez transformacji warto≈õci\n",
    "- Zachowanie oryginalnego formatu\n",
    "- Multi-format support (JSON, CSV, Parquet)\n",
    "\n",
    "**2. Append-Only Pattern**\n",
    "- Nigdy nie usuwamy/modyfikujemy danych\n",
    "- Immutable history\n",
    "- Time-travel capability\n",
    "\n",
    "**3. Audit Metadata**\n",
    "```python\n",
    "# Metadane audytowe w Bronze\n",
    "_ingestion_timestamp  # Kiedy za≈Çadowano\n",
    "_source_file         # SkƒÖd pochodzƒÖ dane\n",
    "_user                # Kto za≈Çadowa≈Ç\n",
    "_rescued_data        # Schema evolution (unexpected columns)\n",
    "```\n",
    "\n",
    "**4. Schema-on-Read**\n",
    "- Elastyczny schemat (mo≈ºe siƒô zmieniaƒá)\n",
    "- Rescued data column dla unknown columns\n",
    "- Reprocessing capability\n",
    "\n",
    "### Bronze Tables - Struktura\n",
    "\n",
    "Dla naszego demo u≈ºyjemy danych, kt√≥re zosta≈Çy ju≈º za≈Çadowane w poprzednich notebookach (02_batch_data_ingestion.ipynb i 03_streaming_data_ingestion.ipynb).\n",
    "\n",
    "**Tabele Bronze:**\n",
    "- `bronze.customers_raw` - dane klient√≥w\n",
    "- `bronze.orders_raw` - zam√≥wienia\n",
    "- `bronze.products_raw` - produkty\n",
    "\n",
    "### Dlaczego Bronze jest Wa≈ºny?\n",
    "\n",
    "**1. Data Recovery**\n",
    "```python\n",
    "# Mo≈ºemy reprocessowaƒá pipeline od Bronze\n",
    "bronze_data = spark.table(\"bronze.orders_raw\")\n",
    "# Re-run transformations ‚Üí Silver ‚Üí Gold\n",
    "```\n",
    "\n",
    "**2. Schema Evolution**\n",
    "```python\n",
    "# Nowe kolumny w source nie ≈ÇamiƒÖ pipeline\n",
    "# TrafiajƒÖ do _rescued_data\n",
    "```\n",
    "\n",
    "**3. Compliance & Audit**\n",
    "```python\n",
    "# Pe≈Çna historia: kto, co, kiedy za≈Çadowa≈Ç\n",
    "# Retention: 3-7 lat (regulacje prawne)\n",
    "```\n",
    "\n",
    "**4. Data Science Exploration**\n",
    "```python\n",
    "# Analitycy mogƒÖ eksplorowaƒá raw data\n",
    "# Tworzyƒá nowe features z surowych danych\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2beff1",
   "metadata": {},
   "source": [
    "### Przyk≈Çad 1.1: Inspekcja Bronze Layer\n",
    "\n",
    "**Cel:** Sprawdziƒá dane w Bronze layer i zrozumieƒá ich strukturƒô."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2357eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przyk≈Çad 1.1 - Inspekcja Bronze Layer\n",
    "\n",
    "print(\"=== Inspekcja Bronze Layer ===\\n\")\n",
    "\n",
    "# Sprawd≈∫ czy tabele Bronze istniejƒÖ (z poprzednich notebook√≥w)\n",
    "bronze_tables = [\"customers_raw\", \"orders_raw\", \"products_raw\"]\n",
    "\n",
    "for table in bronze_tables:\n",
    "    full_table = f\"{CATALOG}.{BRONZE_SCHEMA}.{table}\"\n",
    "    \n",
    "    if spark.catalog.tableExists(full_table):\n",
    "        print(f\"‚úÖ {table}\")\n",
    "        \n",
    "        # Podstawowe statystyki\n",
    "        df = spark.table(full_table)\n",
    "        count = df.count()\n",
    "        schema_cols = len(df.columns)\n",
    "        \n",
    "        print(f\"   Liczba rekord√≥w: {count:,}\")\n",
    "        print(f\"   Liczba kolumn: {schema_cols}\")\n",
    "        \n",
    "        # Poka≈º przyk≈Çadowe dane\n",
    "        print(f\"   Przyk≈Çadowy rekord:\")\n",
    "        display(df.limit(1))\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  {table} - nie istnieje\")\n",
    "        print(f\"   Uruchom najpierw notebooki 02 i 03 aby za≈Çadowaƒá dane do Bronze\\n\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(\"\\nüí° Bronze Layer zawiera RAW data bez transformacji\")\n",
    "print(\"üí° Zachowuje pe≈ÇnƒÖ historiƒô (append-only)\")\n",
    "print(\"üí° Foundation dla dalszych transformacji\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f9ff1",
   "metadata": {},
   "source": [
    "## Sekcja 2: Silver Layer - Cleansing & Validation\n",
    "\n",
    "**Cel sekcji:** Transformacja danych z Bronze do Silver z zastosowaniem data quality rules.\n",
    "\n",
    "### Silver Layer - Kluczowe Cechy\n",
    "\n",
    "**1. Data Cleansing**\n",
    "- Parsing: string ‚Üí proper types (INT, DATE, DECIMAL)\n",
    "- Trimming: whitespace, special characters\n",
    "- Standardization: dates, phone numbers, emails\n",
    "- Null handling: replacements, defaults\n",
    "\n",
    "**2. Deduplication**\n",
    "- Identyfikacja unique business key\n",
    "- MERGE operation (upsert pattern)\n",
    "- Keeping latest version based on timestamp\n",
    "\n",
    "**3. Validation Rules**\n",
    "```python\n",
    "# Przyk≈Çadowe validations\n",
    "- NOT NULL constraints\n",
    "- Range checks (amount > 0)\n",
    "- Referential integrity (FK exists)\n",
    "- Business rules (discount <= price)\n",
    "```\n",
    "\n",
    "**4. Schema Enforcement**\n",
    "- Strict schema (vs Bronze flexible)\n",
    "- Explicit data types\n",
    "- Column constraints\n",
    "\n",
    "### Bronze ‚Üí Silver Transformation Pattern\n",
    "\n",
    "**Typical Flow:**\n",
    "```python\n",
    "bronze_df = spark.table(\"bronze.orders_raw\")\n",
    "\n",
    "silver_df = (bronze_df\n",
    "    # 1. Parse & Cast\n",
    "    .withColumn(\"order_id\", col(\"order_id\").cast(\"bigint\"))\n",
    "    .withColumn(\"order_date\", to_date(col(\"order_date\")))\n",
    "    .withColumn(\"total_amount\", col(\"total_amount\").cast(\"decimal(10,2)\"))\n",
    "    \n",
    "    # 2. Validate\n",
    "    .filter(col(\"order_id\").isNotNull())\n",
    "    .filter(col(\"total_amount\") > 0)\n",
    "    \n",
    "    # 3. Standardize\n",
    "    .withColumn(\"payment_method\", upper(trim(col(\"payment_method\"))))\n",
    "    \n",
    "    # 4. Add metadata\n",
    "    .withColumn(\"_processing_timestamp\", current_timestamp())\n",
    "    .withColumn(\"_is_valid\", lit(True))\n",
    ")\n",
    "\n",
    "# 5. MERGE to Silver (deduplication)\n",
    "silver_df.write.format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"mergeSchema\", \"false\") \\\n",
    "    .saveAsTable(\"silver.orders_clean\")\n",
    "```\n",
    "\n",
    "### MERGE Operation - Deduplication Pattern\n",
    "\n",
    "**Problem:** Bronze zawiera duplikaty (append-only)\n",
    "\n",
    "**RozwiƒÖzanie:** MERGE w Silver (upsert)\n",
    "\n",
    "```sql\n",
    "MERGE INTO silver.orders_clean AS target\n",
    "USING (\n",
    "    SELECT DISTINCT *\n",
    "    FROM bronze.orders_raw\n",
    "    WHERE _ingestion_timestamp > (\n",
    "        SELECT MAX(_processing_timestamp)\n",
    "        FROM silver.orders_clean\n",
    "    )\n",
    ") AS source\n",
    "ON target.order_id = source.order_id\n",
    "WHEN MATCHED THEN UPDATE SET *\n",
    "WHEN NOT MATCHED THEN INSERT *\n",
    "```\n",
    "\n",
    "### Data Quality Checks\n",
    "\n",
    "**Levels of Quality:**\n",
    "\n",
    "**Level 1: Schema Validation**\n",
    "- Correct data types\n",
    "- Required columns present\n",
    "- No unexpected nulls\n",
    "\n",
    "**Level 2: Business Rules**\n",
    "- Ranges (amount between 0-1000000)\n",
    "- Referential integrity (customer_id exists)\n",
    "- Logical consistency (order_date <= ship_date)\n",
    "\n",
    "**Level 3: Statistical Checks**\n",
    "- Outlier detection\n",
    "- Distribution monitoring\n",
    "- Anomaly alerts\n",
    "\n",
    "**Quarantine Pattern:**\n",
    "```python\n",
    "# Valid records ‚Üí Silver\n",
    "valid_df = df.filter(col(\"_is_valid\") == True)\n",
    "valid_df.write.saveAsTable(\"silver.orders_clean\")\n",
    "\n",
    "# Invalid records ‚Üí Quarantine\n",
    "invalid_df = df.filter(col(\"_is_valid\") == False)\n",
    "invalid_df.write.saveAsTable(\"silver.orders_quarantine\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740a9835",
   "metadata": {},
   "source": [
    "### Przyk≈Çad 2.1: Bronze ‚Üí Silver Transformation (Orders)\n",
    "\n",
    "**Cel:** Transform orders z Bronze do Silver z cleansing i validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb73e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przyk≈Çad 2.1 - Bronze ‚Üí Silver: Orders\n",
    "\n",
    "print(\"=== Bronze ‚Üí Silver Transformation: Orders ===\\n\")\n",
    "\n",
    "# Krok 1: Read Bronze\n",
    "bronze_orders = spark.table(f\"{BRONZE_SCHEMA}.orders_raw\")\n",
    "print(f\"‚úì Bronze orders: {bronze_orders.count():,} records\")\n",
    "\n",
    "# Krok 2: Transform & Validate\n",
    "silver_orders = (bronze_orders\n",
    "    # Parse & Cast\n",
    "    .withColumn(\"order_id\", F.col(\"order_id\").cast(\"bigint\"))\n",
    "    .withColumn(\"customer_id\", F.col(\"customer_id\").cast(\"bigint\"))\n",
    "    .withColumn(\"order_date\", F.to_timestamp(F.col(\"order_date\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "    .withColumn(\"total_amount\", F.col(\"total_amount\").cast(\"decimal(10,2)\"))\n",
    "    .withColumn(\"payment_method\", F.upper(F.trim(F.col(\"payment_method\"))))\n",
    "    \n",
    "    # Validation rules\n",
    "    .withColumn(\"_is_valid\", \n",
    "        F.when(\n",
    "            (F.col(\"order_id\").isNotNull()) &\n",
    "            (F.col(\"customer_id\").isNotNull()) &\n",
    "            (F.col(\"order_date\").isNotNull()) &\n",
    "            (F.col(\"total_amount\") > 0),\n",
    "            True\n",
    "        ).otherwise(False)\n",
    "    )\n",
    "    \n",
    "    # Add processing metadata\n",
    "    .withColumn(\"_processing_timestamp\", F.current_timestamp())\n",
    "    \n",
    "    # Select & order columns\n",
    "    .select(\n",
    "        \"order_id\", \"customer_id\", \"order_date\", \n",
    "        \"total_amount\", \"payment_method\",\n",
    "        \"_is_valid\", \"_processing_timestamp\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Krok 3: Split valid/invalid\n",
    "valid_orders = silver_orders.filter(F.col(\"_is_valid\") == True)\n",
    "invalid_orders = silver_orders.filter(F.col(\"_is_valid\") == False)\n",
    "\n",
    "print(f\"‚úì Valid orders: {valid_orders.count():,}\")\n",
    "print(f\"‚ö† Invalid orders: {invalid_orders.count():,}\")\n",
    "\n",
    "# Krok 4: Write to Silver (CREATE OR REPLACE for demo simplicity)\n",
    "valid_orders.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(f\"{SILVER_SCHEMA}.orders_clean\")\n",
    "\n",
    "print(f\"\\n‚úÖ Created {SILVER_SCHEMA}.orders_clean\")\n",
    "print(\"\\nüí° W production u≈ºyliby≈õmy MERGE dla deduplication\")\n",
    "display(spark.table(f\"{SILVER_SCHEMA}.orders_clean\").limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9515638f",
   "metadata": {},
   "source": [
    "## Sekcja 3: SCD (Slowly Changing Dimensions)\n",
    "\n",
    "**Cel sekcji:** Implementacja SCD Type 1 i Type 2 dla ≈õledzenia zmian w danych.\n",
    "\n",
    "### Co to jest SCD?\n",
    "\n",
    "**Slowly Changing Dimensions (SCD)** to techniki ≈õledzenia zmian w wymiarach (dimension tables) w hurtowniach danych.\n",
    "\n",
    "**Problem:**\n",
    "```\n",
    "Klient zmienia adres:\n",
    "- Jan Kowalski, Warszawa ‚Üí Krak√≥w\n",
    "\n",
    "Pytanie: Czy zachowaƒá historiƒô?\n",
    "```\n",
    "\n",
    "### SCD Types - Overview\n",
    "\n",
    "| Type | Strategy | History | Use Case |\n",
    "|------|----------|---------|----------|\n",
    "| **Type 0** | No changes allowed | N/A | Reference data (countries) |\n",
    "| **Type 1** | Overwrite | ‚ùå No | Current state only |\n",
    "| **Type 2** | Add new row | ‚úÖ Yes | Full history tracking |\n",
    "| **Type 3** | Add new column | ‚ö†Ô∏è Limited | Previous value only |\n",
    "\n",
    "---\n",
    "\n",
    "### SCD Type 1 - Overwrite\n",
    "\n",
    "**Strategia:** Nadpisz starƒÖ warto≈õƒá nowƒÖ (bez historii)\n",
    "\n",
    "**Implementacja:** Simple UPDATE/MERGE\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Before:\n",
    "customer_id | name        | city\n",
    "1           | Jan Kowalski| Warszawa\n",
    "\n",
    "Change: city ‚Üí Krak√≥w\n",
    "\n",
    "After:\n",
    "customer_id | name        | city\n",
    "1           | Jan Kowalski| Krak√≥w     # Overwritten!\n",
    "```\n",
    "\n",
    "**Kod SQL:**\n",
    "```sql\n",
    "MERGE INTO silver.customers_dim AS target\n",
    "USING updates AS source\n",
    "ON target.customer_id = source.customer_id\n",
    "WHEN MATCHED THEN UPDATE SET\n",
    "    target.city = source.city,\n",
    "    target.updated_at = current_timestamp()\n",
    "```\n",
    "\n",
    "**Pros:**\n",
    "- ‚úÖ Simple implementation\n",
    "- ‚úÖ No history bloat\n",
    "- ‚úÖ Always current values\n",
    "\n",
    "**Cons:**\n",
    "- ‚ùå No historical tracking\n",
    "- ‚ùå Can't analyze \"as of date\"\n",
    "- ‚ùå Lose audit trail\n",
    "\n",
    "**Use Cases:**\n",
    "- Correcting data entry errors\n",
    "- Non-critical attributes (e.g., marketing preferences)\n",
    "- Reference data that shouldn't have history\n",
    "\n",
    "---\n",
    "\n",
    "### SCD Type 2 - Historical Tracking\n",
    "\n",
    "**Strategia:** Dodaj nowy rekord dla ka≈ºdej zmiany (pe≈Çna historia)\n",
    "\n",
    "**Implementacja:** MERGE z version tracking\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Before:\n",
    "customer_id | name        | city    | effective_from | effective_to | is_current\n",
    "1           | Jan Kowalski| Warszawa| 2023-01-01     | 9999-12-31   | true\n",
    "\n",
    "Change: city ‚Üí Krak√≥w (2024-06-15)\n",
    "\n",
    "After:\n",
    "customer_id | name        | city    | effective_from | effective_to | is_current\n",
    "1           | Jan Kowalski| Warszawa| 2023-01-01     | 2024-06-14   | false  # Closed\n",
    "1           | Jan Kowalski| Krak√≥w  | 2024-06-15     | 9999-12-31   | true   # New!\n",
    "```\n",
    "\n",
    "**Kolumny SCD Type 2:**\n",
    "- `effective_from` / `valid_from`: Start date\n",
    "- `effective_to` / `valid_to`: End date (9999-12-31 = current)\n",
    "- `is_current` / `is_active`: Boolean flag\n",
    "- `version`: Optional version number\n",
    "- `surrogate_key`: Technical key (not business key)\n",
    "\n",
    "**Kod SQL (simplified):**\n",
    "```sql\n",
    "-- Step 1: Close old records\n",
    "UPDATE silver.customers_dim\n",
    "SET \n",
    "    effective_to = current_date() - 1,\n",
    "    is_current = false\n",
    "WHERE customer_id IN (SELECT customer_id FROM updates)\n",
    "  AND is_current = true;\n",
    "\n",
    "-- Step 2: Insert new records\n",
    "INSERT INTO silver.customers_dim\n",
    "SELECT \n",
    "    customer_id,\n",
    "    name,\n",
    "    city,\n",
    "    current_date() AS effective_from,\n",
    "    DATE '9999-12-31' AS effective_to,\n",
    "    true AS is_current\n",
    "FROM updates;\n",
    "```\n",
    "\n",
    "**Pros:**\n",
    "- ‚úÖ Full history preserved\n",
    "- ‚úÖ \"As of date\" queries possible\n",
    "- ‚úÖ Audit trail\n",
    "- ‚úÖ Temporal analytics\n",
    "\n",
    "**Cons:**\n",
    "- ‚ùå Table grows (more rows)\n",
    "- ‚ùå More complex queries (need to filter is_current)\n",
    "- ‚ùå Surrogate keys needed\n",
    "\n",
    "**Use Cases:**\n",
    "- Customer dimensions (address, preferences)\n",
    "- Product dimensions (price history)\n",
    "- Employee dimensions (salary, department)\n",
    "- Compliance & audit requirements\n",
    "\n",
    "---\n",
    "\n",
    "### SCD Type 3 - Limited History (rzadziej u≈ºywany)\n",
    "\n",
    "**Strategia:** Dodaj kolumnƒô dla previous value\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "customer_id | name        | city    | previous_city\n",
    "1           | Jan Kowalski| Krak√≥w  | Warszawa\n",
    "```\n",
    "\n",
    "**Pros:**\n",
    "- ‚úÖ Simple (one previous value)\n",
    "- ‚úÖ No row explosion\n",
    "\n",
    "**Cons:**\n",
    "- ‚ùå Only 1 previous value\n",
    "- ‚ùå Limited analytics\n",
    "\n",
    "**Use Case:** Rarely used (SCD Type 2 is better)\n",
    "\n",
    "---\n",
    "\n",
    "### SCD Decision Matrix\n",
    "\n",
    "**Kiedy u≈ºywaƒá kt√≥rego typu?**\n",
    "\n",
    "| Requirement | Recommended Type |\n",
    "|-------------|------------------|\n",
    "| No history needed | Type 1 |\n",
    "| Full history required | Type 2 |\n",
    "| Audit/compliance | Type 2 |\n",
    "| Data corrections | Type 1 |\n",
    "| Current state only | Type 1 |\n",
    "| Temporal analytics | Type 2 |\n",
    "| Growing table OK | Type 2 |\n",
    "| Storage constrained | Type 1 |\n",
    "\n",
    "**üí° Best Practice:** \n",
    "- Use **Type 1** for Silver layer (current state)\n",
    "- Use **Type 2** for Gold dimensional tables (history)\n",
    "\n",
    "---\n",
    "\n",
    "### MERGE Pattern for SCD Type 2 (Advanced)\n",
    "\n",
    "**Complete Implementation:**\n",
    "\n",
    "```sql\n",
    "MERGE INTO silver.customers_dim AS target\n",
    "USING (\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        name,\n",
    "        city,\n",
    "        email,\n",
    "        current_timestamp() AS effective_from,\n",
    "        CAST('9999-12-31' AS DATE) AS effective_to,\n",
    "        true AS is_current\n",
    "    FROM staging.customers_updates\n",
    ") AS source\n",
    "ON target.customer_id = source.customer_id \n",
    "   AND target.is_current = true\n",
    "\n",
    "-- Case 1: No change ‚Üí do nothing\n",
    "WHEN MATCHED AND (\n",
    "    target.city = source.city AND\n",
    "    target.email = source.email\n",
    ") THEN UPDATE SET target.updated_at = current_timestamp()\n",
    "\n",
    "-- Case 2: Change detected ‚Üí close old, insert new\n",
    "WHEN MATCHED AND (\n",
    "    target.city != source.city OR\n",
    "    target.email != source.email\n",
    ") THEN UPDATE SET\n",
    "    target.effective_to = current_date() - 1,\n",
    "    target.is_current = false\n",
    "\n",
    "-- Case 3: New customer ‚Üí insert\n",
    "WHEN NOT MATCHED THEN INSERT (\n",
    "    customer_id, name, city, email,\n",
    "    effective_from, effective_to, is_current\n",
    ") VALUES (\n",
    "    source.customer_id, source.name, source.city, source.email,\n",
    "    source.effective_from, source.effective_to, source.is_current\n",
    ");\n",
    "\n",
    "-- Step 2: Insert new versions for changed records\n",
    "INSERT INTO silver.customers_dim\n",
    "SELECT \n",
    "    source.*\n",
    "FROM staging.customers_updates AS source\n",
    "INNER JOIN silver.customers_dim AS target\n",
    "    ON source.customer_id = target.customer_id\n",
    "WHERE target.is_current = false\n",
    "  AND target.effective_to = current_date() - 1;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c805dc",
   "metadata": {},
   "source": [
    "### Przyk≈Çad 3.1: SCD Type 1 - Customers (Overwrite)\n",
    "\n",
    "**Cel:** Implementacja SCD Type 1 - prosty overwrite bez historii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72a0d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przyk≈Çad 3.1 - SCD Type 1: Customers\n",
    "\n",
    "print(\"=== SCD Type 1: Customers Dimension ===\\n\")\n",
    "\n",
    "# Step 1: Prepare Bronze customers data\n",
    "bronze_customers = spark.table(f\"{BRONZE_SCHEMA}.customers_raw\")\n",
    "\n",
    "# Step 2: Transform to Silver (SCD Type 1 - current state only)\n",
    "customers_type1 = (bronze_customers\n",
    "    .withColumn(\"customer_id\", F.col(\"customer_id\").cast(\"bigint\"))\n",
    "    .withColumn(\"name\", F.trim(F.col(\"name\")))\n",
    "    .withColumn(\"email\", F.lower(F.trim(F.col(\"email\"))))\n",
    "    .withColumn(\"city\", F.initcap(F.trim(F.col(\"city\"))))\n",
    "    .withColumn(\"updated_at\", F.current_timestamp())\n",
    "    .select(\"customer_id\", \"name\", \"email\", \"city\", \"updated_at\")\n",
    ")\n",
    "\n",
    "# Step 3: Create/Replace table (Type 1 = overwrite)\n",
    "customers_type1.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(f\"{SILVER_SCHEMA}.customers_type1\")\n",
    "\n",
    "print(f\"‚úÖ Created {SILVER_SCHEMA}.customers_type1 (SCD Type 1)\")\n",
    "print(f\"   Records: {customers_type1.count():,}\")\n",
    "print(\"\\nüí° SCD Type 1: Zawsze aktualny stan, bez historii\")\n",
    "\n",
    "display(spark.table(f\"{SILVER_SCHEMA}.customers_type1\").limit(5))\n",
    "\n",
    "# Step 4: Simulate update (change city for customer 1)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Symulacja UPDATE - zmiana miasta dla customer_id=1\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Show before\n",
    "print(\"PRZED ZMIANƒÑ:\")\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT * FROM {SILVER_SCHEMA}.customers_type1 \n",
    "    WHERE customer_id = 1\n",
    "\"\"\").show()\n",
    "\n",
    "# Simulate new data (city change)\n",
    "from pyspark.sql.types import StructType, StructField, LongType, StringType\n",
    "updates_schema = StructType([\n",
    "    StructField(\"customer_id\", LongType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"email\", StringType(), True),\n",
    "    StructField(\"city\", StringType(), True)\n",
    "])\n",
    "\n",
    "updates_data = [(1, \"Jan Kowalski\", \"jan@example.com\", \"Krak√≥w\")]  # Changed city!\n",
    "updates_df = spark.createDataFrame(updates_data, updates_schema)\n",
    "\n",
    "# MERGE (SCD Type 1 - overwrite)\n",
    "updates_df.createOrReplaceTempView(\"customer_updates\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    MERGE INTO {SILVER_SCHEMA}.customers_type1 AS target\n",
    "    USING customer_updates AS source\n",
    "    ON target.customer_id = source.customer_id\n",
    "    WHEN MATCHED THEN UPDATE SET\n",
    "        target.city = source.city,\n",
    "        target.updated_at = current_timestamp()\n",
    "    WHEN NOT MATCHED THEN INSERT *\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nPO ZMIANIE (SCD Type 1 - overwrite):\")\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT * FROM {SILVER_SCHEMA}.customers_type1 \n",
    "    WHERE customer_id = 1\n",
    "\"\"\").show()\n",
    "\n",
    "print(\"‚ö†Ô∏è  UWAGA: Historia zmiany zosta≈Ça UTRACONA\")\n",
    "print(\"üí° Stara warto≈õƒá (Warszawa) zosta≈Ça nadpisana (Krak√≥w)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952d19cf",
   "metadata": {},
   "source": [
    "### Przyk≈Çad 3.2: SCD Type 2 - Customers (Historical Tracking)\n",
    "\n",
    "**Cel:** Implementacja SCD Type 2 - pe≈Çne ≈õledzenie historii zmian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23830a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przyk≈Çad 3.2 - SCD Type 2: Customers (Historical)\n",
    "\n",
    "print(\"=== SCD Type 2: Customers Dimension (Historical Tracking) ===\\n\")\n",
    "\n",
    "# Step 1: Prepare initial dimension with SCD Type 2 columns\n",
    "bronze_customers = spark.table(f\"{BRONZE_SCHEMA}.customers_raw\")\n",
    "\n",
    "customers_type2_initial = (bronze_customers\n",
    "    .withColumn(\"customer_id\", F.col(\"customer_id\").cast(\"bigint\"))\n",
    "    .withColumn(\"name\", F.trim(F.col(\"name\")))\n",
    "    .withColumn(\"email\", F.lower(F.trim(F.col(\"email\"))))\n",
    "    .withColumn(\"city\", F.initcap(F.trim(F.col(\"city\"))))\n",
    "    # SCD Type 2 columns\n",
    "    .withColumn(\"effective_from\", F.current_date())\n",
    "    .withColumn(\"effective_to\", F.lit(\"9999-12-31\").cast(\"date\"))\n",
    "    .withColumn(\"is_current\", F.lit(True))\n",
    "    .withColumn(\"version\", F.lit(1))\n",
    "    .select(\n",
    "        \"customer_id\", \"name\", \"email\", \"city\",\n",
    "        \"effective_from\", \"effective_to\", \"is_current\", \"version\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create initial table\n",
    "customers_type2_initial.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(f\"{SILVER_SCHEMA}.customers_type2\")\n",
    "\n",
    "print(f\"‚úÖ Created {SILVER_SCHEMA}.customers_type2 (SCD Type 2)\")\n",
    "print(f\"   Initial records: {customers_type2_initial.count():,}\")\n",
    "print(\"\\nüí° SCD Type 2: effective_from, effective_to, is_current, version\")\n",
    "\n",
    "display(spark.table(f\"{SILVER_SCHEMA}.customers_type2\").limit(5))\n",
    "\n",
    "# Step 2: Simulate change (city change for customer 1)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Symulacja CHANGE - zmiana miasta dla customer_id=1\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "print(\"PRZED ZMIANƒÑ:\")\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT * FROM {SILVER_SCHEMA}.customers_type2 \n",
    "    WHERE customer_id = 1\n",
    "    ORDER BY effective_from\n",
    "\"\"\").show()\n",
    "\n",
    "# New data (city changed)\n",
    "updates_data = [(1, \"Jan Kowalski\", \"jan@example.com\", \"Krak√≥w\")]  # Changed city!\n",
    "updates_df = spark.createDataFrame(updates_data, [\"customer_id\", \"name\", \"email\", \"city\"])\n",
    "updates_df.createOrReplaceTempView(\"customer_updates_type2\")\n",
    "\n",
    "# SCD Type 2 MERGE - Complex!\n",
    "\n",
    "# Step 2a: Close old records (set effective_to, is_current=false)\n",
    "spark.sql(f\"\"\"\n",
    "    MERGE INTO {SILVER_SCHEMA}.customers_type2 AS target\n",
    "    USING (\n",
    "        SELECT DISTINCT u.customer_id\n",
    "        FROM customer_updates_type2 u\n",
    "        INNER JOIN {SILVER_SCHEMA}.customers_type2 t\n",
    "            ON u.customer_id = t.customer_id\n",
    "        WHERE t.is_current = true\n",
    "          AND (u.city != t.city OR u.email != t.email)  -- Detect changes\n",
    "    ) AS changed\n",
    "    ON target.customer_id = changed.customer_id \n",
    "       AND target.is_current = true\n",
    "    WHEN MATCHED THEN UPDATE SET\n",
    "        target.effective_to = current_date() - INTERVAL 1 DAY,\n",
    "        target.is_current = false\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úì Step 1: Closed old records\\n\")\n",
    "\n",
    "# Step 2b: Insert new versions\n",
    "spark.sql(f\"\"\"\n",
    "    INSERT INTO {SILVER_SCHEMA}.customers_type2\n",
    "    SELECT \n",
    "        u.customer_id,\n",
    "        u.name,\n",
    "        u.email,\n",
    "        u.city,\n",
    "        current_date() AS effective_from,\n",
    "        CAST('9999-12-31' AS DATE) AS effective_to,\n",
    "        true AS is_current,\n",
    "        COALESCE(MAX(t.version), 0) + 1 AS version\n",
    "    FROM customer_updates_type2 u\n",
    "    LEFT JOIN {SILVER_SCHEMA}.customers_type2 t\n",
    "        ON u.customer_id = t.customer_id\n",
    "    WHERE NOT EXISTS (\n",
    "        SELECT 1 FROM {SILVER_SCHEMA}.customers_type2 existing\n",
    "        WHERE existing.customer_id = u.customer_id\n",
    "          AND existing.is_current = true\n",
    "          AND existing.city = u.city\n",
    "          AND existing.email = u.email\n",
    "    )\n",
    "    GROUP BY u.customer_id, u.name, u.email, u.city\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úì Step 2: Inserted new versions\\n\")\n",
    "\n",
    "print(\"PO ZMIANIE (SCD Type 2 - historical tracking):\")\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        city,\n",
    "        effective_from,\n",
    "        effective_to,\n",
    "        is_current,\n",
    "        version\n",
    "    FROM {SILVER_SCHEMA}.customers_type2 \n",
    "    WHERE customer_id = 1\n",
    "    ORDER BY effective_from\n",
    "\"\"\").show()\n",
    "\n",
    "print(\"‚úÖ Historia zachowana!\")\n",
    "print(\"üí° Mamy 2 rekordy:\")\n",
    "print(\"   1. Version 1: Warszawa (effective_to = dzisiaj-1, is_current=false)\")\n",
    "print(\"   2. Version 2: Krak√≥w (effective_to = 9999-12-31, is_current=true)\")\n",
    "\n",
    "# Step 3: Query \"as of date\" example\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Przyk≈Çad: Query 'as of date' - Gdzie mieszka≈Ç klient 1 miesiƒÖc temu?\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "one_month_ago = (datetime.now() - timedelta(days=30)).date()\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        name,\n",
    "        city,\n",
    "        effective_from,\n",
    "        effective_to\n",
    "    FROM {SILVER_SCHEMA}.customers_type2\n",
    "    WHERE customer_id = 1\n",
    "      AND '{one_month_ago}' BETWEEN effective_from AND effective_to\n",
    "\"\"\").show()\n",
    "\n",
    "print(f\"üí° SCD Type 2 umo≈ºliwia temporal queries ('as of {one_month_ago}')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b46986",
   "metadata": {},
   "source": [
    "## Sekcja 4: Gold Layer - Business Aggregates & Analytics\n",
    "\n",
    "**Cel sekcji:** Transformacja Silver ‚Üí Gold z agregacjami biznesowymi.\n",
    "\n",
    "### Gold Layer - Kluczowe Cechy\n",
    "\n",
    "**1. Pre-Aggregated Data**\n",
    "- Daily/Monthly/Yearly summaries\n",
    "- Pre-computed KPIs\n",
    "- Reduced data volume (faster queries)\n",
    "\n",
    "**2. Denormalized Tables**\n",
    "- Joins pre-computed (star schema)\n",
    "- Wide tables dla BI tools\n",
    "- No complex joins needed\n",
    "\n",
    "**3. Business Logic**\n",
    "- Revenue calculations\n",
    "- Customer segmentation\n",
    "- Product performance metrics\n",
    "\n",
    "**4. Query Optimization**\n",
    "- Partitioned by report_date\n",
    "- Z-ordered for common filters\n",
    "- Materialized views\n",
    "\n",
    "### Silver ‚Üí Gold Transformation Pattern\n",
    "\n",
    "**Typical Aggregation:**\n",
    "```python\n",
    "# Silver: Detail level (millions of rows)\n",
    "silver_orders = spark.table(\"silver.orders_clean\")\n",
    "\n",
    "# Gold: Aggregated (thousands of rows)\n",
    "gold_daily_sales = (silver_orders\n",
    "    .groupBy(\n",
    "        F.to_date(\"order_date\").alias(\"report_date\"),\n",
    "        \"payment_method\"\n",
    "    )\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"total_orders\"),\n",
    "        F.sum(\"total_amount\").alias(\"total_revenue\"),\n",
    "        F.avg(\"total_amount\").alias(\"avg_order_value\"),\n",
    "        F.countDistinct(\"customer_id\").alias(\"unique_customers\")\n",
    "    )\n",
    ")\n",
    "```\n",
    "\n",
    "### Gold Layer Tables - Examples\n",
    "\n",
    "**1. Daily Sales Summary**\n",
    "```sql\n",
    "gold.daily_sales_summary\n",
    "- report_date, payment_method\n",
    "- total_orders, total_revenue, avg_order_value\n",
    "- PARTITIONED BY (report_date)\n",
    "```\n",
    "\n",
    "**2. Customer 360**\n",
    "```sql\n",
    "gold.customer_360\n",
    "- customer_id, name, email, city\n",
    "- total_lifetime_value, total_orders, first_order_date, last_order_date\n",
    "- customer_segment (VIP, Regular, New)\n",
    "```\n",
    "\n",
    "**3. Product Performance**\n",
    "```sql\n",
    "gold.product_performance\n",
    "- product_id, product_name, category\n",
    "- total_sold, total_revenue, avg_price\n",
    "- PARTITIONED BY (category)\n",
    "```\n",
    "\n",
    "### Star Schema Pattern\n",
    "\n",
    "**Fact Table (Orders):**\n",
    "- order_id, customer_key, product_key, date_key\n",
    "- total_amount, quantity\n",
    "\n",
    "**Dimension Tables:**\n",
    "- dim_customers (SCD Type 2)\n",
    "- dim_products\n",
    "- dim_dates\n",
    "\n",
    "**Benefits:**\n",
    "- Simplified queries\n",
    "- Better performance (pre-joined)\n",
    "- BI tool friendly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae09388d",
   "metadata": {},
   "source": [
    "### Przyk≈Çad 4.1: Gold - Daily Sales Summary\n",
    "\n",
    "**Cel:** Agregacja zam√≥wie≈Ñ do daily sales summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73dcac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przyk≈Çad 4.1 - Gold: Daily Sales Summary\n",
    "\n",
    "print(\"=== Gold Layer: Daily Sales Summary ===\\n\")\n",
    "\n",
    "# Read Silver orders\n",
    "silver_orders = spark.table(f\"{SILVER_SCHEMA}.orders_clean\")\n",
    "\n",
    "# Aggregate to daily summary\n",
    "daily_sales = (silver_orders\n",
    "    .withColumn(\"report_date\", F.to_date(\"order_date\"))\n",
    "    .groupBy(\"report_date\", \"payment_method\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"total_orders\"),\n",
    "        F.sum(\"total_amount\").alias(\"total_revenue\"),\n",
    "        F.avg(\"total_amount\").alias(\"avg_order_value\"),\n",
    "        F.countDistinct(\"customer_id\").alias(\"unique_customers\"),\n",
    "        F.min(\"total_amount\").alias(\"min_order\"),\n",
    "        F.max(\"total_amount\").alias(\"max_order\")\n",
    "    )\n",
    "    .withColumn(\"_computation_timestamp\", F.current_timestamp())\n",
    "    .orderBy(\"report_date\", \"payment_method\")\n",
    ")\n",
    "\n",
    "# Write to Gold\n",
    "daily_sales.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"report_date\") \\\n",
    "    .saveAsTable(f\"{GOLD_SCHEMA}.daily_sales_summary\")\n",
    "\n",
    "print(f\"‚úÖ Created {GOLD_SCHEMA}.daily_sales_summary\")\n",
    "print(f\"   Aggregated rows: {daily_sales.count():,}\")\n",
    "print(f\"   Partitioned by: report_date\")\n",
    "\n",
    "# Show summary\n",
    "print(\"\\nüìä Daily Sales Summary (Top 10 days):\")\n",
    "display(\n",
    "    spark.table(f\"{GOLD_SCHEMA}.daily_sales_summary\")\n",
    "    .orderBy(F.desc(\"total_revenue\"))\n",
    "    .limit(10)\n",
    ")\n",
    "\n",
    "# Data reduction metrics\n",
    "silver_count = silver_orders.count()\n",
    "gold_count = daily_sales.count()\n",
    "reduction_pct = ((silver_count - gold_count) / silver_count) * 100\n",
    "\n",
    "print(f\"\\n=== Data Reduction ===\")\n",
    "print(f\"Silver (detail): {silver_count:,} rows\")\n",
    "print(f\"Gold (summary): {gold_count:,} rows\")\n",
    "print(f\"Reduction: {reduction_pct:.1f}% fewer rows\")\n",
    "print(f\"\\nüí° Gold tables sƒÖ znacznie mniejsze ‚Üí szybsze queries!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b4da5",
   "metadata": {},
   "source": [
    "### Przyk≈Çad 4.2: Gold - Customer 360 (Denormalized)\n",
    "\n",
    "**Cel:** Stworzenie denormalized customer view z KPIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c66438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przyk≈Çad 4.2 - Gold: Customer 360\n",
    "\n",
    "print(\"=== Gold Layer: Customer 360 View ===\\n\")\n",
    "\n",
    "# Join customers + orders for 360 view\n",
    "customers = spark.table(f\"{SILVER_SCHEMA}.customers_type1\")\n",
    "orders = spark.table(f\"{SILVER_SCHEMA}.orders_clean\")\n",
    "\n",
    "customer_360 = (customers\n",
    "    .join(\n",
    "        orders.groupBy(\"customer_id\").agg(\n",
    "            F.count(\"*\").alias(\"total_orders\"),\n",
    "            F.sum(\"total_amount\").alias(\"lifetime_value\"),\n",
    "            F.avg(\"total_amount\").alias(\"avg_order_value\"),\n",
    "            F.min(\"order_date\").alias(\"first_order_date\"),\n",
    "            F.max(\"order_date\").alias(\"last_order_date\")\n",
    "        ),\n",
    "        \"customer_id\",\n",
    "        \"left\"\n",
    "    )\n",
    "    # Customer segmentation logic\n",
    "    .withColumn(\"customer_segment\",\n",
    "        F.when(F.col(\"lifetime_value\") > 1000, \"VIP\")\n",
    "        .when(F.col(\"lifetime_value\") > 500, \"Regular\")\n",
    "        .otherwise(\"New\")\n",
    "    )\n",
    "    .withColumn(\"_computation_timestamp\", F.current_timestamp())\n",
    "    .select(\n",
    "        \"customer_id\", \"name\", \"email\", \"city\",\n",
    "        \"total_orders\", \"lifetime_value\", \"avg_order_value\",\n",
    "        \"first_order_date\", \"last_order_date\", \"customer_segment\",\n",
    "        \"_computation_timestamp\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Write to Gold\n",
    "customer_360.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(f\"{GOLD_SCHEMA}.customer_360\")\n",
    "\n",
    "print(f\"‚úÖ Created {GOLD_SCHEMA}.customer_360\")\n",
    "print(f\"   Customers: {customer_360.count():,}\")\n",
    "\n",
    "# Show top customers\n",
    "print(\"\\nüìä Top 10 Customers by Lifetime Value:\")\n",
    "display(\n",
    "    spark.table(f\"{GOLD_SCHEMA}.customer_360\")\n",
    "    .orderBy(F.desc(\"lifetime_value\"))\n",
    "    .limit(10)\n",
    ")\n",
    "\n",
    "# Segment distribution\n",
    "print(\"\\n=== Customer Segmentation ===\")\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        customer_segment,\n",
    "        COUNT(*) as customer_count,\n",
    "        SUM(lifetime_value) as total_value,\n",
    "        AVG(lifetime_value) as avg_value\n",
    "    FROM {GOLD_SCHEMA}.customer_360\n",
    "    GROUP BY customer_segment\n",
    "    ORDER BY total_value DESC\n",
    "\"\"\").show()\n",
    "\n",
    "print(\"üí° Customer 360: Denormalized view dla BI dashboards\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225f55a0",
   "metadata": {},
   "source": [
    "## Sekcja 5: Podsumowanie & Best Practices\n",
    "\n",
    "### Co zosta≈Ço osiƒÖgniƒôte?\n",
    "\n",
    "‚úÖ **1. Medallion Architecture Implementation**\n",
    "- ü•â Bronze: Raw data landing (append-only, immutable)\n",
    "- ü•à Silver: Cleansed & validated data (deduplicated)\n",
    "- ü•á Gold: Business aggregates & KPIs (pre-computed)\n",
    "\n",
    "‚úÖ **2. SCD (Slowly Changing Dimensions)**\n",
    "- **Type 1**: Overwrite (no history) - dla current state\n",
    "- **Type 2**: Historical tracking (full history) - dla temporal analytics\n",
    "\n",
    "‚úÖ **3. Data Quality Patterns**\n",
    "- Validation rules (NOT NULL, ranges, types)\n",
    "- Quarantine pattern (valid/invalid split)\n",
    "- Metadata tracking (_processing_timestamp, _is_valid)\n",
    "\n",
    "‚úÖ **4. Business Logic Implementations**\n",
    "- Daily sales aggregations\n",
    "- Customer 360 view (denormalized)\n",
    "- Customer segmentation (VIP/Regular/New)\n",
    "\n",
    "### Kluczowe Wnioski\n",
    "\n",
    "üí° **1. Separation of Concerns**\n",
    "```\n",
    "Bronze = Ingestion (raw data)\n",
    "Silver = Data Quality (cleansing, dedup)\n",
    "Gold = Business Logic (aggregates, KPIs)\n",
    "```\n",
    "\n",
    "üí° **2. ELT > ETL**\n",
    "```\n",
    "Traditional ETL: Transform outside DB\n",
    "Medallion ELT: Load first, transform in-place\n",
    "- Preserve raw data (Bronze)\n",
    "- Re-process capability\n",
    "- Scalable (Spark distributed)\n",
    "```\n",
    "\n",
    "üí° **3. SCD Strategy**\n",
    "```\n",
    "Silver: Type 1 (current state)\n",
    "Gold: Type 2 (history for dimensions)\n",
    "Fact tables: Immutable (no SCD needed)\n",
    "```\n",
    "\n",
    "üí° **4. Incremental Processing**\n",
    "```\n",
    "Bronze ‚Üí Silver: MERGE (deduplication)\n",
    "Silver ‚Üí Gold: Overwrite or MERGE (depends on use case)\n",
    "Always use checkpoints for streaming\n",
    "```\n",
    "\n",
    "üí° **5. Partitioning Strategy**\n",
    "```\n",
    "Bronze: _ingestion_date\n",
    "Silver: Business date (order_date, transaction_date)\n",
    "Gold: Report date (report_date)\n",
    "```\n",
    "\n",
    "### Medallion Architecture - Decision Matrix\n",
    "\n",
    "| Layer | Purpose | Schema | Updates | Retention | Use Case |\n",
    "|-------|---------|--------|---------|-----------|----------|\n",
    "| **Bronze** | Raw landing | Flexible | Append-only | 3-7 years | Recovery, audit |\n",
    "| **Silver** | Validated | Strict | MERGE (dedup) | 1-2 years | Analytics prep |\n",
    "| **Gold** | Business | Optimized | Overwrite/MERGE | 6-12 months | BI, reports |\n",
    "\n",
    "### Production Checklist\n",
    "\n",
    "**Bronze Layer:**\n",
    "- [ ] Audit metadata (_ingestion_timestamp, _source_file)\n",
    "- [ ] Schema evolution enabled (rescued_data)\n",
    "- [ ] Long retention (compliance)\n",
    "- [ ] Partition by _ingestion_date\n",
    "\n",
    "**Silver Layer:**\n",
    "- [ ] Data quality rules implemented\n",
    "- [ ] Deduplication logic (MERGE)\n",
    "- [ ] SCD Type 1 for dimension tables\n",
    "- [ ] Quarantine pattern for bad data\n",
    "- [ ] Partition by business date\n",
    "\n",
    "**Gold Layer:**\n",
    "- [ ] Pre-aggregated summaries\n",
    "- [ ] Denormalized tables (star schema)\n",
    "- [ ] SCD Type 2 for dimensions (optional)\n",
    "- [ ] Partition by report_date\n",
    "- [ ] Z-ordering for common filters\n",
    "\n",
    "### Nastƒôpne Kroki\n",
    "\n",
    "**üìö Kolejne Notebooki:**\n",
    "- **05_optimization_best_practices.ipynb** - Performance tuning\n",
    "- **Warsztaty praktyczne** - End-to-end pipeline implementation\n",
    "\n",
    "**üõ†Ô∏è Zadanie Domowe:**\n",
    "1. Zaimplementuj complete Bronze‚ÜíSilver‚ÜíGold pipeline\n",
    "2. Dodaj SCD Type 2 dla products dimension\n",
    "3. Stw√≥rz Gold table: monthly_product_performance\n",
    "4. Zaimplementuj data quality monitoring\n",
    "\n",
    "### Useful SQL Queries\n",
    "\n",
    "**Query current customers only (SCD Type 2):**\n",
    "```sql\n",
    "SELECT * FROM silver.customers_type2\n",
    "WHERE is_current = true\n",
    "```\n",
    "\n",
    "**Query historical data (as of date):**\n",
    "```sql\n",
    "SELECT * FROM silver.customers_type2\n",
    "WHERE '2024-01-15' BETWEEN effective_from AND effective_to\n",
    "```\n",
    "\n",
    "**Gold aggregation refresh:**\n",
    "```sql\n",
    "INSERT OVERWRITE gold.daily_sales_summary\n",
    "SELECT \n",
    "    CAST(order_date AS DATE) as report_date,\n",
    "    payment_method,\n",
    "    COUNT(*) as total_orders,\n",
    "    SUM(total_amount) as total_revenue,\n",
    "    AVG(total_amount) as avg_order_value\n",
    "FROM silver.orders_clean\n",
    "GROUP BY 1, 2\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Gratulacje!** üéâ \n",
    "Uko≈Ñczy≈Çe≈õ implementacjƒô Medallion Architecture z SCD Type 1/2!\n",
    "Jeste≈õ gotowy do budowania production-grade data lakehouse pipelines!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bffd95",
   "metadata": {},
   "source": [
    "## Sekcja 6: Czyszczenie Zasob√≥w\n",
    "\n",
    "**Uwaga:** Ta sekcja jest opcjonalna. Uruchom tylko je≈õli chcesz usunƒÖƒá wszystkie dane utworzone w tym notebooku.\n",
    "\n",
    "### Opcja 1: Sprawd≈∫ utworzone zasoby (zalecane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1610b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opcja 1: Sprawd≈∫ utworzone zasoby\n",
    "\n",
    "print(\"=== Tabele utworzone w tym notebooku ===\\n\")\n",
    "\n",
    "medallion_tables = {\n",
    "    \"Silver\": [\n",
    "        f\"{SILVER_SCHEMA}.orders_clean\",\n",
    "        f\"{SILVER_SCHEMA}.customers_type1\",\n",
    "        f\"{SILVER_SCHEMA}.customers_type2\"\n",
    "    ],\n",
    "    \"Gold\": [\n",
    "        f\"{GOLD_SCHEMA}.daily_sales_summary\",\n",
    "        f\"{GOLD_SCHEMA}.customer_360\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for layer, tables in medallion_tables.items():\n",
    "    print(f\"=== {layer} Layer ===\")\n",
    "    for table in tables:\n",
    "        full_table = f\"{CATALOG}.{table}\"\n",
    "        if spark.catalog.tableExists(full_table):\n",
    "            count = spark.table(full_table).count()\n",
    "            detail = spark.sql(f\"DESCRIBE DETAIL {full_table}\").collect()[0]\n",
    "            size_mb = detail['sizeInBytes'] / (1024 * 1024)\n",
    "            \n",
    "            print(f\"‚úÖ {table}\")\n",
    "            print(f\"   Rekordy: {count:,}\")\n",
    "            print(f\"   Rozmiar: {size_mb:.2f} MB\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  {table} - nie istnieje\")\n",
    "    print()\n",
    "\n",
    "print(\"üí° Dane sƒÖ zachowane dla dalszego u≈ºytku\")\n",
    "print(\"üí° Aby usunƒÖƒá, uruchom kom√≥rkƒô poni≈ºej\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4956ba",
   "metadata": {},
   "source": [
    "### Opcja 2: Usu≈Ñ wszystkie zasoby (tylko je≈õli naprawdƒô chcesz)\n",
    "\n",
    "**UWAGA:** To usunie wszystkie tabele Silver i Gold utworzone w tym notebooku!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada7b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opcja 2: Usu≈Ñ wszystkie zasoby (TYLKO JE≈öLI JESTE≈ö PEWIEN!)\n",
    "\n",
    "# ‚ö†Ô∏è  UWAGA: Odkomentuj poni≈ºszy kod tylko je≈õli chcesz usunƒÖƒá wszystko!\n",
    "\n",
    "\"\"\"\n",
    "print(\"=== üóëÔ∏è  USUWANIE ZASOB√ìW MEDALLION ===\\n\")\n",
    "\n",
    "# Lista tabel do usuniƒôcia\n",
    "tables_to_drop = [\n",
    "    f\"{SILVER_SCHEMA}.orders_clean\",\n",
    "    f\"{SILVER_SCHEMA}.customers_type1\",\n",
    "    f\"{SILVER_SCHEMA}.customers_type2\",\n",
    "    f\"{GOLD_SCHEMA}.daily_sales_summary\",\n",
    "    f\"{GOLD_SCHEMA}.customer_360\"\n",
    "]\n",
    "\n",
    "print(\"Usuwanie tabel...\\n\")\n",
    "for table in tables_to_drop:\n",
    "    full_table = f\"{CATALOG}.{table}\"\n",
    "    try:\n",
    "        spark.sql(f\"DROP TABLE IF EXISTS {full_table}\")\n",
    "        print(f\"  ‚úì Usuniƒôto: {table}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è  B≈ÇƒÖd przy {table}: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Czyszczenie zako≈Ñczone!\")\n",
    "print(\"üí° Wszystkie tabele Medallion zosta≈Çy usuniƒôte\")\n",
    "print(\"üí° Mo≈ºesz uruchomiƒá notebook od nowa\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚ö†Ô∏è  KOD CZYSZCZENIA JEST ZAKOMENTOWANY\")\n",
    "print(\"‚ö†Ô∏è  Odkomentuj powy≈ºszy kod tylko je≈õli chcesz usunƒÖƒá wszystkie zasoby\")\n",
    "print(\"\\nüí° Zalecenie: Zostaw dane dla kolejnych notebook√≥w i warsztat√≥w!\")\n",
    "print(\"üí° Nastƒôpny notebook: 05_optimization_best_practices.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
