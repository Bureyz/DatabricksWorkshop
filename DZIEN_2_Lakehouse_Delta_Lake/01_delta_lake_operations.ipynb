{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2399a946-d3b0-4e05-9eee-0e6803d13246",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Delta Lake Operations\n",
    "\n",
    "**Cel szkoleniowy:** Zrozumienie fundamentów Delta Lake i praktyczne zastosowanie operacji CRUD, Time Travel, optymalizacji i Change Data Feed\n",
    "\n",
    "**Zakres tematyczny:**\n",
    "- Delta Lake core features: ACID, Delta Log, Schema enforcement\n",
    "- Schema evolution (additive, automatic)\n",
    "- Time Travel i Copy-on-write\n",
    "- CRUD operations: CREATE TABLE, INSERT, UPDATE, DELETE, MERGE INTO\n",
    "- Optymalizacja: OPTIMIZE, ZORDER BY, VACUUM\n",
    "- Change Data Feed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47092836-2e35-43c3-90dc-a4fc8aac0974",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Kontekst i wymagania\n",
    "\n",
    "- **Dzień szkolenia**: Dzień 2 - Lakehouse & Delta Lake\n",
    "- **Typ notebooka**: Demo\n",
    "- **Wymagania techniczne**:\n",
    "  - Databricks Runtime 16.4 LTS lub 17.3 LTS (Spark 4.0)\n",
    "  - Unity Catalog włączony\n",
    "  - Uprawnienia: CREATE TABLE, CREATE SCHEMA, SELECT, MODIFY\n",
    "  - Klaster: Standard z 2-4 workers (lub Serverless Compute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cc52d93-9548-447f-8dab-f27a5c8c2e53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Wstęp teoretyczny\n",
    "\n",
    "**Cel sekcji:** Wprowadzenie do Delta Lake jako transakcyjnej warstwy storage nad Data Lake\n",
    "\n",
    "**Podstawowe pojęcia:**\n",
    "- **Delta Lake**: Open-source storage layer zapewniający ACID transactions dla Apache Spark\n",
    "- **Delta Log**: Transakcyjny log przechowujący metadane o wszystkich zmianach w tabeli\n",
    "- **Schema Enforcement**: Automatyczna walidacja zgodności schematów przy zapisie\n",
    "- **Time Travel**: Możliwość dostępu do poprzednich wersji danych\n",
    "\n",
    "**Dlaczego to ważne?**\n",
    "Delta Lake rozwiązuje fundamentalne problemy Data Lake: brak transakcji, schema drift, trudności z aktualizacjami i quality assurance. Zapewnia niezawodność Data Warehouse z elastycznością Data Lake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a0b4b70-aae4-4747-8785-bafd0dc63143",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Izolacja per użytkownik\n",
    "\n",
    "Uruchom skrypt inicjalizacyjny dla per-user izolacji katalogów i schematów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b62fe846-46a6-48d7-a324-f40d8a22295f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../00_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4710c49-0275-4ffb-9e16-23204c742948",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Konfiguracja\n",
    "\n",
    "Import bibliotek i ustawienie zmiennych środowiskowych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10cd956a-79c5-45b9-8164-c2f42e0d0266",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Wyświetl kontekst użytkownika\n",
    "display(\n",
    "    spark.createDataFrame([\n",
    "        (CATALOG, BRONZE_SCHEMA, SILVER_SCHEMA, GOLD_SCHEMA)\n",
    "    ], ['catalog', 'bronze_schema', 'silver_schema', 'gold_schema'])\n",
    ")\n",
    "\n",
    "# Ustaw katalog i schemat jako domyślne\n",
    "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
    "spark.sql(f\"USE SCHEMA {BRONZE_SCHEMA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b0e248d-2ca8-460c-8ff0-7c7867b82062",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sekcja 1: Delta Lake Core Features\n",
    "\n",
    "**Wprowadzenie teoretyczne:**\n",
    "\n",
    "Delta Lake to warstwa transakcyjna nad Parquet, która zapewnia ACID properties (Atomicity, Consistency, Isolation, Durability). Każda operacja na tabeli Delta jest rejestrowana w Delta Log - JSON pliku zawierającym metadane o zmianach.\n",
    "\n",
    "**Kluczowe pojęcia:**\n",
    "- **ACID Transactions**: Wszystkie operacje są atomowe i spójne\n",
    "- **Delta Log**: `_delta_log/` folder z JSON plikami opisującymi każdą transakcję\n",
    "- **Schema Enforcement**: Automatyczna walidacja zgodności schematów\n",
    "- **Unified Batch and Streaming**: Jedna tabela obsługuje zarówno batch jak i streaming\n",
    "\n",
    "**Zastosowanie praktyczne:**\n",
    "- Transakcyjne aktualizacje w Data Lake\n",
    "- Zapewnienie jakości danych poprzez schema validation\n",
    "- Jednolity dostęp do danych dla batch i streaming workloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72717cea-7a0e-4e4a-86b5-e8fb77f1c92f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przykład 1.1: Utworzenie pierwszej tabeli Delta\n",
    "\n",
    "**Cel:** Demonstracja tworzenia tabeli Delta i podstawowych właściwości\n",
    "\n",
    "**Podejście:**\n",
    "1. Wczytanie danych z Unity Catalog Volume\n",
    "2. Utworzenie managed table w formacie Delta\n",
    "3. Eksploracja Delta Log i metadanych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31cee2c9-543f-4d8d-a0fe-ca8d0e1961ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Wczytaj dane klientów z Unity Catalog Volume\n",
    "customers_df = (spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .csv(f\"{DATASET_BASE_PATH}/customers/customers.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adb4f7fe-8c01-47f9-aa6c-08a5ad5a41db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Utwórz managed Delta table:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31ca80d2-937b-4641-a991-b5304dbe089c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Utwórz managed Delta table\n",
    "customers_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(f\"{CATALOG}.{BRONZE_SCHEMA}.customers_delta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b70f208-811a-4771-842b-0efe24393911",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Wyświetl wynik:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "571c8136-e46f-470c-b07a-defa9853fd36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.table(f\"{CATALOG}.{BRONZE_SCHEMA}.customers_delta\").limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe3cc9b1-49cd-4a29-b4a6-167e2066ccfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Wyjaśnienie:**\n",
    "\n",
    "Utworzono managed Delta table w Unity Catalog. Format Delta automatycznie:\n",
    "- Stworzył `_delta_log/` folder z metadanymi transakcji\n",
    "- Zarejestrował schemat tabeli w Unity Catalog\n",
    "- Zastosował kompresję Parquet z dodatkowymi Delta features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f68e66d-3c39-45a9-867d-04faf98c7993",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przykład 1.2: Schema Enforcement w akcji\n",
    "\n",
    "**Cel:** Demonstracja automatycznej walidacji schematów przy wstawianiu danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f15f1cb0-1881-43a9-b3b5-66fe572eab24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sprawdź aktualny schemat tabeli\n",
    "spark.table(f\"{CATALOG}.{BRONZE_SCHEMA}.customers_delta\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "979038ab-96fc-46fe-a329-04f1421a627d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Próba wstawienia danych z niepoprawnym schematem (brakuje kolumn)\n",
    "invalid_data = spark.createDataFrame([\n",
    "    (\"CUST999999\", \"Test\", \"Customer\", \"invalid_email\", \"+48 123 456 789\")  # Brakuje city, state, country, registration_date, customer_segment\n",
    "], [\"customer_id\", \"first_name\", \"last_name\", \"email\", \"phone\"])\n",
    "\n",
    "try:\n",
    "    invalid_data.write \\\n",
    "        .format(\"delta\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .saveAsTable(f\"{CATALOG}.{BRONZE_SCHEMA}.customers_delta\")\n",
    "except Exception as e:\n",
    "    display(\n",
    "        spark.createDataFrame([\n",
    "            (\"Schema enforcement w działaniu\", str(e)[:200] + \"...\")\n",
    "        ], [\"message\", \"error\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96866648-1cba-4918-b69f-ed26f44d9cba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Wyjaśnienie:**\n",
    "\n",
    "Schema enforcement automatycznie odrzucił dane z niepoprawnym typem. Delta Lake porównuje schemat nowych danych ze schematem tabeli i blokuje niezgodne wstawienia, zapewniając consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20a4edd0-0bcf-4633-9e01-9219dd52beff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Utwórz tabelę z Identity Column i Generated Column\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {CATALOG}.{BRONZE_SCHEMA}.orders_modern (\n",
    "    order_sk BIGINT GENERATED ALWAYS AS IDENTITY,  -- Surrogate Key\n",
    "    order_id STRING,\n",
    "    total_amount DOUBLE,\n",
    "    order_timestamp TIMESTAMP,\n",
    "    order_date DATE GENERATED ALWAYS AS (CAST(order_timestamp AS DATE)) -- Auto-calculated\n",
    ") USING DELTA\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1b489be-2c56-4d77-a0fa-6e5ddf0a6710",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.table(f\"{CATALOG}.{BRONZE_SCHEMA}.orders_modern\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "060e0435-54a0-4e9d-b736-a5a080c25518",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Sprawdźmy wynik. Zwróć uwagę na automatycznie wypełnione kolumny.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd1ebce2-0e87-4cd6-900d-84300b219ee2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Wstaw dane bez podawania kolumn generowanych\n",
    "spark.sql(f\"\"\"\n",
    "INSERT INTO {CATALOG}.{BRONZE_SCHEMA}.orders_modern (order_id, total_amount, order_timestamp)\n",
    "VALUES \n",
    "    ('ORD-001', 150.50, current_timestamp()),\n",
    "    ('ORD-002', 200.00, current_timestamp())\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efda8bd2-4df9-4e97-bc7a-6c32e712db98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Teraz wstawimy dane. Zauważ, że w zapytaniu `INSERT` pomijamy kolumny `order_sk` oraz `order_date`.\n",
    "- `order_sk`: zostanie wygenerowane automatycznie (unikalny numer).\n",
    "- `order_date`: zostanie wyliczone na podstawie `order_timestamp`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sekcja 1.5: Managed vs External Tables (Demo)\n",
    "\n",
    "**Cel**: Pokazanie różnicy w zachowaniu `DROP TABLE` dla tabel zarządzanych (Managed) i zewnętrznych (External).\n",
    "\n",
    "- **Managed Table**: Databricks zarządza metadanymi ORAZ plikami. `DROP TABLE` usuwa wszystko.\n",
    "- **External Table**: Databricks zarządza tylko metadanymi. `DROP TABLE` usuwa wpis w katalogu, ale pliki zostają.\n",
    "\n",
    "> **Tip**: Nie potrzebujesz `EXTERNAL LOCATION` do tego demo! Możesz użyć ścieżki w **Unity Catalog Volume** lub nawet DBFS, aby zasymulować \"zewnętrzną\" lokalizację.\n",
    "\n",
    "### 1.5.1 Managed Table - Pełne usunięcie\n",
    "Tworzymy tabelę bez podawania `LOCATION`. Pliki trafią do domyślnej lokalizacji schematu (Managed Storage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Tworzymy Managed Table\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {CATALOG}.{BRONZE_SCHEMA}.demo_managed\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE {CATALOG}.{BRONZE_SCHEMA}.demo_managed\n",
    "    AS SELECT 1 as id, 'Managed Data' as info\n",
    "\"\"\")\n",
    "\n",
    "# Pobieramy lokalizację plików\n",
    "managed_path = spark.sql(f\"DESCRIBE DETAIL {CATALOG}.{BRONZE_SCHEMA}.demo_managed\").select(\"location\").first()[0]\n",
    "print(f\"Managed Table Path: {managed_path}\")\n",
    "\n",
    "# Sprawdzamy czy pliki istnieją\n",
    "print(f\"Files exist before DROP: {len(dbutils.fs.ls(managed_path)) > 0}\")\n",
    "\n",
    "# Usuwamy tabelę\n",
    "spark.sql(f\"DROP TABLE {CATALOG}.{BRONZE_SCHEMA}.demo_managed\")\n",
    "\n",
    "# Sprawdzamy czy pliki nadal istnieją (powinno rzucić błąd lub zwrócić False)\n",
    "try:\n",
    "    dbutils.fs.ls(managed_path)\n",
    "    print(\"Files exist after DROP: TRUE (Unexpected!)\")\n",
    "except:\n",
    "    print(\"Files exist after DROP: FALSE (Expected - Managed Table removed files)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.2 External Table (Unmanaged) - Zachowanie plików\n",
    "Tworzymy tabelę podając `LOCATION`. Użyjemy ścieżki w Volume (lub tymczasowej), aby symulować zewnętrzny storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_path = f\"{DATASET_BASE_PATH}/{raw_user}/demo_external_table\"\n",
    "dbutils.fs.rm(external_path, True) # Reset environment\n",
    "\n",
    "# 1. Create External Table\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE {CATALOG}.{BRONZE_SCHEMA}.demo_external\n",
    "    LOCATION '{external_path}'\n",
    "    AS SELECT 1 as id, 'External Data' as info\n",
    "\"\"\")\n",
    "\n",
    "# 2. Drop Table (Metadata only)\n",
    "spark.sql(f\"DROP TABLE {CATALOG}.{BRONZE_SCHEMA}.demo_external\")\n",
    "\n",
    "# 3. Verify Files Persist\n",
    "files_exist = len(dbutils.fs.ls(external_path)) > 0\n",
    "print(f\"External Path: {external_path}\")\n",
    "print(f\"Files persist after DROP: {'✅ YES' if files_exist else '❌ NO'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6b1148d-fea4-4f81-adfb-e25e3d7c5515",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przykład 1.3: Modern Modeling - Identity & Generated Columns\n",
    "\n",
    "**Cel:** Wykorzystanie nowoczesnych funkcji Delta Lake do automatyzacji modelu danych.\n",
    "\n",
    "**Funkcje:**\n",
    "- **Identity Columns**: Automatyczne generowanie unikalnych kluczy (Surrogate Keys).\n",
    "- **Generated Columns**: Automatyczne wyliczanie wartości kolumn na podstawie innych (np. data z timestamp).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81ce2558-42e7-4604-a1b6-f93099b3dec5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sekcja 2: Schema Evolution\n",
    "\n",
    "**Wprowadzenie teoretyczne:**\n",
    "\n",
    "Schema Evolution pozwala na kontrolowane dodawanie nowych kolumn do istniejących tabel Delta bez przerywania działania aplikacji. Delta Lake wspiera additive schema changes automatycznie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1646c21e-2c91-4c5b-a292-1769fcb28454",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przykład 2.1: Automatyczne dodawanie kolumn\n",
    "\n",
    "**Cel:** Demonstracja automatycznej ewolucji schematu przy dodawaniu nowych kolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcd016ab-6033-450c-993c-736a543c1091",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dane z dodatkową kolumną (customer_tier)\n",
    "extended_customers = spark.createDataFrame([\n",
    "    (\"CUST010001\", \"New\", \"Customer\", \"new@example.com\", \"+48 111 222 333\", \"Warsaw\", \"MZ\", \"Poland\", \"2023-12-01\", \"Basic\", \"Premium\"),\n",
    "    (\"CUST010002\", \"Another\", \"Customer\", \"another@example.com\", \"+48 444 555 666\", \"Krakow\", \"MP\", \"Poland\", \"2023-12-02\", \"Premium\", \"Standard\")\n",
    "], [\"customer_id\", \"first_name\", \"last_name\", \"email\", \"phone\", \"city\", \"state\", \"country\", \"registration_date\", \"customer_segment\", \"customer_tier\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2507581-ded5-4a20-b5b9-e97e43a34547",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Włącz automatic schema evolution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf7e76ad-b678-4153-89d7-90554c61a3a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import DateType\n",
    "\n",
    "extended_customers = extended_customers.withColumn(\"registration_date\", col(\"registration_date\").cast(DateType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5fdf80c-f30d-47fe-b1a2-9f68a3729fce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Włącz automatic schema evolution\n",
    "extended_customers.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{CATALOG}.{BRONZE_SCHEMA}.customers_delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1518e23a-8363-4877-b893-4e8e07ca6cc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sprawdź nowy schemat\n",
    "spark.table(f\"{CATALOG}.{BRONZE_SCHEMA}.customers_delta\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f94c7709-7cef-44df-8c40-50f38317a32f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Weryfikuj dane - nowa kolumna ma NULL dla starych rekordów\n",
    "display(\n",
    "    spark.table(f\"{CATALOG}.{BRONZE_SCHEMA}.customers_delta\")\n",
    "    .select(\"customer_id\", \"first_name\", \"last_name\", \"customer_tier\")\n",
    "    .orderBy(\"customer_id\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73521e5b-62b4-488f-b058-82830bff3b7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dodaj CHECK constraint: customer_id musi zaczynać się od CUST\n",
    "try:\n",
    "    spark.sql(f\"\"\"\n",
    "        ALTER TABLE {CATALOG}.{BRONZE_SCHEMA}.customers_delta\n",
    "        ADD CONSTRAINT valid_customer_id CHECK (customer_id LIKE 'CUST%')\n",
    "    \"\"\")\n",
    "    print(\"Constraint 'valid_customer_id' dodany pomyślnie.\")\n",
    "except Exception as e:\n",
    "    print(f\"Informacja: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4dcb6ad5-e056-4f4f-b806-bd2ccfa4e244",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Próba wstawienia błędnych danych (customer_id nie zaczyna się od CUST)\n",
    "try:\n",
    "    spark.sql(f\"\"\"\n",
    "        INSERT INTO {CATALOG}.{BRONZE_SCHEMA}.customers_delta (customer_id, first_name, last_name, email, phone, city, state, country, registration_date, customer_segment)\n",
    "        VALUES ('INVALID123', 'Bad', 'Customer', 'bad@example.com', '+48 000 000 000', 'Test', 'TS', 'Poland', '2023-01-01', 'Basic')\n",
    "    \"\"\")\n",
    "except Exception as e:\n",
    "    print(f\"Oczekiwany błąd Data Quality:\\n{str(e)[:300]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e00d2222-3618-4527-ac91-d7ecfa5e6f77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Constraint został dodany. Teraz spróbujmy wstawić dane, które go naruszają (customer_id nie zaczyna się od 'CUST'). \n",
    "Oczekujemy, że Delta Lake zablokuje tę operację i zwróci błąd `CheckConstraintViolation`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bf1163c-58cf-4f79-8d58-ef63042079ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sekcja 2.5: Data Quality & Constraints\n",
    "\n",
    "**Wprowadzenie teoretyczne:**\n",
    "\n",
    "Delta Lake pozwala na definiowanie **Constraints** (ograniczeń), które gwarantują jakość danych na poziomie tabeli. Działa to podobnie jak w tradycyjnych bazach danych SQL.\n",
    "\n",
    "**Typy Constraints:**\n",
    "- `NOT NULL`: Wymusza obecność wartości.\n",
    "- `CHECK`: Wymusza spełnienie dowolnego warunku logicznego (np. `age > 0`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a734b47f-5831-4600-a773-6aa00773cc74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sekcja 3: Time Travel i Disaster Recovery\n",
    "\n",
    "**Wprowadzenie teoretyczne:**\n",
    "\n",
    "Time Travel to kluczowa funkcjonalność Delta Lake umożliwiająca dostęp do poprzednich wersji danych. Bazuje na Copy-on-Write mechanizmie - każda zmiana tworzy nową wersję plików, a stare wersje pozostają dostępne.\n",
    "\n",
    "**Disaster Recovery:**\n",
    "Dzięki Time Travel możemy nie tylko czytać stare dane, ale także **przywracać** tabelę do poprzedniego stanu za pomocą polecenia `RESTORE`. To kluczowe w przypadku przypadkowego usunięcia danych lub błędnych aktualizacji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c2cb29b-8e7f-4658-a721-708509eac8a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przykład 3.1: Eksploracja historii tabeli\n",
    "\n",
    "**Cel:** Użycie DESCRIBE HISTORY do analizy wszystkich operacji na tabeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c04fc3c8-9ee7-46ba-b006-7720c6e9425f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Pokaż historię wszystkich operacji na tabeli\n",
    "display(\n",
    "    spark.sql(f\"DESCRIBE HISTORY {CATALOG}.{BRONZE_SCHEMA}.customers_delta\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4be441c5-adca-457c-946e-aa82c24652e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przykład 3.2: Time Travel queries\n",
    "\n",
    "**Cel:** Dostęp do poprzednich wersji danych używając VERSION AS OF i TIMESTAMP AS OF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77275765-d45f-4f0e-8dae-5960bf89778b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dostęp do danych z wersji 0 (przed schema evolution)\n",
    "version_0_data = spark.sql(f\"\"\"\n",
    "    SELECT *\n",
    "    FROM {CATALOG}.{BRONZE_SCHEMA}.customers_delta VERSION AS OF 1\n",
    "    ORDER BY customer_id\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "728bbf49-cde3-48aa-a194-e8adda94b464",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(version_0_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8590607e-9be2-4538-b801-7af362dee42d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Porównaj liczbę rekordów między wersjami\n",
    "current_count = spark.table(f\"{CATALOG}.{BRONZE_SCHEMA}.customers_delta\").count()\n",
    "version_0_count = spark.sql(f\"SELECT * FROM {CATALOG}.{BRONZE_SCHEMA}.customers_delta VERSION AS OF 0\").count()\n",
    "\n",
    "display(\n",
    "    spark.createDataFrame([\n",
    "        (\"Current version\", current_count),\n",
    "        (\"Version 0\", version_0_count)\n",
    "    ], [\"version\", \"record_count\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfc5ee0d-ad03-49dc-b057-53ee4fac01cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Symulacja błędu: Przypadkowe usunięcie wszystkich danych\n",
    "spark.sql(f\"DELETE FROM {CATALOG}.{BRONZE_SCHEMA}.customers_delta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56cdf368-2fdf-4fcb-8b72-dd9d85fb0408",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Liczba rekordów po RESTORE:\", spark.table(f\"{CATALOG}.{BRONZE_SCHEMA}.customers_delta\").count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8f1771d-6b35-456c-a185-63d700989479",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Tabela została przywrócona. Zweryfikujmy liczbę rekordów.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "162295f9-8a08-4b56-8d8c-1ebad5bad7f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. Naprawa: RESTORE do wersji sprzed usunięcia\n",
    "# Pobieramy ostatnią dobrą wersję (przed DELETE)\n",
    "last_good_version = spark.sql(f\"DESCRIBE HISTORY {CATALOG}.{BRONZE_SCHEMA}.customers_delta\").select(\"version\").limit(2).collect()[1][0]\n",
    "\n",
    "print(f\"Przywracanie do wersji: {last_good_version}\")\n",
    "\n",
    "spark.sql(f\"RESTORE TABLE {CATALOG}.{BRONZE_SCHEMA}.customers_delta TO VERSION AS OF {last_good_version}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a8a28c9-7013-47ee-94ce-28a811168d9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Teraz użyjemy **Time Travel**, aby znaleźć ostatnią poprawną wersję (sprzed usunięcia) i przywrócić tabelę poleceniem `RESTORE`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2a11cbe-8f7b-4f58-9455-2e1d3592a0d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Liczba rekordów po awarii:\", spark.table(f\"{CATALOG}.{BRONZE_SCHEMA}.customers_delta\").count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "477375f5-c3fd-463d-8628-2942eee51726",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Ups! Usunęliśmy wszystkie dane. Sprawdźmy, czy tabela jest faktycznie pusta.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e060050-02c3-438e-a225-624ad45d416a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przykład 3.3: Disaster Recovery - RESTORE TABLE\n",
    "\n",
    "**Cel:** Przywrócenie tabeli do stanu sprzed błędnej operacji (symulacja awarii).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "309db8fd-2525-427b-b331-f0d7d67b34ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sekcja 4: CRUD Operations\n",
    "\n",
    "**Wprowadzenie teoretyczne:**\n",
    "\n",
    "Delta Lake wspiera pełen zakres operacji CRUD (Create, Read, Update, Delete), co czyni go idealnym dla transakcyjnych workloadów w Data Lake. Wszystkie operacje są atomowe i ACID-compliant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad370348-1447-49a3-bb42-4781ec23d3c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przykład 4.1: INSERT operation\n",
    "\n",
    "**Cel:** Dodawanie nowych rekordów do istniejącej tabeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d3c3c31-4fc1-47d9-9ed7-a60b34af2a8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# INSERT nowych klientów\n",
    "spark.sql(f\"\"\"\n",
    "    INSERT INTO {CATALOG}.{BRONZE_SCHEMA}.customers_delta\n",
    "    (customer_id, first_name, last_name, email, phone, city, state, country, registration_date, customer_segment, customer_tier)\n",
    "    VALUES \n",
    "        ('CUST020001', 'Insert', 'Customer1', 'insert1@example.com', '+48 111 111 111', 'Warsaw', 'MZ', 'Poland', '2023-12-10', 'Premium', 'Gold'),\n",
    "        ('CUST020002', 'Insert', 'Customer2', 'insert2@example.com', '+48 222 222 222', 'Gdansk', 'PM', 'Poland', '2023-12-11', 'Basic', 'Silver')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6677e39a-5cf7-4598-9c79-e2315710ed6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Weryfikuj wstawienie:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "deb5c2e9-3ca5-4703-9d99-3b6c984f0969",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Weryfikuj wstawienie\n",
    "display(\n",
    "    spark.table(f\"{CATALOG}.{BRONZE_SCHEMA}.customers_delta\")\n",
    "    .filter(F.col(\"customer_id\").like(\"CUST02%\"))\n",
    "    .orderBy(\"customer_id\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85c568b0-f0df-4071-a780-ff62f1d8592c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przykład 4.2: UPDATE operation\n",
    "\n",
    "**Cel:** Aktualizacja istniejących rekordów w tabeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc7aa31b-8acb-4a8e-aa37-816718b42bd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# UPDATE customer tier dla specific customers\n",
    "spark.sql(f\"\"\"\n",
    "    UPDATE {CATALOG}.{BRONZE_SCHEMA}.customers_delta\n",
    "    SET customer_tier = 'Platinum'\n",
    "    WHERE customer_id IN ('CUST010001', 'CUST020001')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89f68659-9863-4720-bd49-11b39379fd50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Weryfikuj aktualizację:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15980065-806c-4a45-a358-28f8a3e8db30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Weryfikuj aktualizację\n",
    "display(\n",
    "    spark.table(f\"{CATALOG}.{BRONZE_SCHEMA}.customers_delta\")\n",
    "    .filter(F.col(\"customer_tier\") == \"Platinum\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1563ba09-e4f7-48ef-b495-ab3cead61fe7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przykład 4.3: DELETE operation\n",
    "\n",
    "**Cel:** Usuwanie rekordów z tabeli Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07f9d3db-5d08-4180-b68a-bf843d78ec03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# DELETE specific customer\n",
    "spark.sql(f\"\"\"\n",
    "    DELETE FROM {CATALOG}.{BRONZE_SCHEMA}.customers_delta\n",
    "    WHERE customer_id = 'CUST020002'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33503d56-53c3-49fa-bf44-1793ae2530bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Weryfikuj usunięcie:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "775563ff-3a28-4a9c-9254-22fc4b8b521f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Weryfikuj usunięcie\n",
    "deleted_check = spark.table(f\"{CATALOG}.{BRONZE_SCHEMA}.customers_delta\") \\\n",
    "    .filter(F.col(\"customer_id\") == \"CUST020002\") \\\n",
    "    .count()\n",
    "\n",
    "display(\n",
    "    spark.createDataFrame([\n",
    "        (\"Records with customer_id CUST020002\", deleted_check)\n",
    "    ], [\"description\", \"count\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a119d3c-01af-4e99-97cf-02893bdd1e08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sekcja 5: MERGE INTO Operations\n",
    "\n",
    "**Wprowadzenie teoretyczne:**\n",
    "\n",
    "MERGE INTO to potężna operacja umożliwiająca upsert (update + insert) w jednej transakcji. Szczególnie przydatna przy przetwarzaniu zmian z systemów transakcyjnych (CDC - Change Data Capture)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c107079-d995-447e-94d4-8447ec753f32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przykład 5.1: Podstawowy MERGE INTO\n",
    "\n",
    "**Cel:** Demonstracja upsert operation - update istniejących i insert nowych rekordów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc93805f-ae93-4add-8239-9bd51e690821",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Przygotuj dane do merge (mix updates i nowych rekordów)\n",
    "merge_data = spark.createDataFrame([\n",
    "    (\"CUST010001\", \"Updated\", \"Name\", \"updated@example.com\", \"+48 999 999 999\", \"Poznan\", \"WP\", \"Poland\", \"2023-12-01\", \"VIP\", \"Diamond\"),  # Update\n",
    "    (\"CUST030001\", \"Brand\", \"New\", \"brand.new@example.com\", \"+48 777 777 777\", \"Wroclaw\", \"DS\", \"Poland\", \"2023-12-15\", \"Basic\", \"Bronze\"),   # Insert\n",
    "    (\"CUST030002\", \"Another\", \"New\", \"another.new@example.com\", \"+48 888 888 888\", \"Lodz\", \"LD\", \"Poland\", \"2023-12-16\", \"Premium\", \"Silver\") # Insert\n",
    "], [\"customer_id\", \"first_name\", \"last_name\", \"email\", \"phone\", \"city\", \"state\", \"country\", \"registration_date\", \"customer_segment\", \"customer_tier\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ff59cc6-4daf-4de8-be63-b9751f34f721",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Utwórz temporary view dla merge operation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5347719a-eebd-419f-a7ea-8edd83438a56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Utwórz temporary view dla merge operation\n",
    "merge_data.createOrReplaceTempView(\"customer_updates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42e0a7ba-52dc-4100-b8e0-881c1b07a4a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Wykonaj operację MERGE (Upsert):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ae1e75a-cef0-4932-b7c5-fddcb41d03df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# MERGE INTO operation\n",
    "spark.sql(f\"\"\"\n",
    "    MERGE INTO {CATALOG}.{BRONZE_SCHEMA}.customers_delta AS target\n",
    "    USING customer_updates AS source\n",
    "    ON target.customer_id = source.customer_id\n",
    "    \n",
    "    WHEN MATCHED THEN\n",
    "        UPDATE SET\n",
    "            first_name = source.first_name,\n",
    "            last_name = source.last_name,\n",
    "            email = source.email,\n",
    "            phone = source.phone,\n",
    "            city = source.city,\n",
    "            state = source.state,\n",
    "            country = source.country,\n",
    "            customer_segment = source.customer_segment,\n",
    "            customer_tier = source.customer_tier\n",
    "    \n",
    "    WHEN NOT MATCHED THEN\n",
    "        INSERT (customer_id, first_name, last_name, email, phone, city, state, country, registration_date, customer_segment, customer_tier)\n",
    "        VALUES (source.customer_id, source.first_name, source.last_name, source.email, source.phone, source.city, source.state, source.country, source.registration_date, source.customer_segment, source.customer_tier)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edb3ffeb-9131-4d83-b20c-21bc538c3965",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Zweryfikuj wyniki MERGE:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cb851ea-582e-46cf-918e-44bd88a3f61b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Weryfikuj wyniki MERGE\n",
    "display(\n",
    "    spark.table(f\"{CATALOG}.{BRONZE_SCHEMA}.customers_delta\")\n",
    "    .filter(F.col(\"customer_id\").isin([\"CUST010001\", \"CUST030001\", \"CUST030002\"]))\n",
    "    .orderBy(\"customer_id\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d83043cd-1b3d-4b1f-9c44-7c56c49579ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sekcja 6: Metadane i Analytics\n",
    "\n",
    "**Wprowadzenie teoretyczne:**\n",
    "\n",
    "Delta Lake oferuje bogate metadane o tabelach i operacjach. DESCRIBE DETAIL dostarcza informacji o strukturze plików, partitioning, i właściwościach tabeli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b41b54e-e42f-4574-91d6-8f59a9c82491",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przykład 6.1: DESCRIBE DETAIL\n",
    "\n",
    "**Cel:** Analiza metadanych tabeli Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1fea90d-f3d2-461c-8bdd-963eedf8363a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Szczegółowe informacje o tabeli\n",
    "display(\n",
    "    spark.sql(f\"DESCRIBE DETAIL {CATALOG}.{BRONZE_SCHEMA}.customers_delta\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7f1f123-d733-4f02-8889-d5115fd8117f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przykład 6.2: Analiza historii operacji\n",
    "\n",
    "**Cel:** Głębsza analiza historii i metryk operacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83a5161d-4a4d-4595-958b-97ceab526b18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Historia z dodatkowymi metrykami\n",
    "history_df = spark.sql(f\"DESCRIBE HISTORY {CATALOG}.{BRONZE_SCHEMA}.customers_delta\")\n",
    "\n",
    "display(\n",
    "    history_df.select(\n",
    "        \"version\", \n",
    "        \"timestamp\", \n",
    "        \"operation\", \n",
    "        \"operationMetrics.numTargetRowsInserted\",\n",
    "        \"operationMetrics.numTargetRowsUpdated\",\n",
    "        \"operationMetrics.numTargetRowsDeleted\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aeb4ea8e-c231-4d53-ac61-0270295df465",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przykład 6.3: Delta Log Internals (Deep Dive)\n",
    "\n",
    "**Cel:** Zrozumienie jak Delta Lake zapewnia ACID, zaglądając \"pod maskę\" do plików JSON w `_delta_log`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fe0293e-ae4d-4227-80d8-e1c6feb05563",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Pobierz ścieżkę do tabeli i _delta_log:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cccb6f31-7937-48f9-915f-9aab0aac1ab7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Pobierz ścieżkę do tabeli\n",
    "table_path = spark.sql(f\"DESCRIBE DETAIL {CATALOG}.{BRONZE_SCHEMA}.customers_delta\")\n",
    "delta_log_path = f\"{table_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddf8e731-d94f-4529-bf9d-9424957324a1",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"location\":1500},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1764068621478}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dbf4f1f-fe60-4368-892c-28b7412a3320",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Wyświetl pliki w _delta_log:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b571a7c8-9a39-45ec-afb0-70e41304cdb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Poniżej podgląd zawartości ostatniego pliku transakcyjnego JSON. \n",
    "Zawiera on metadane o operacjach, takich jak:\n",
    "- `add`: dodanie nowego pliku Parquet z danymi.\n",
    "- `remove`: logiczne usunięcie pliku (np. przy operacji DELETE lub OPTIMIZE).\n",
    "- `commitInfo`: metadane o samej transakcji (kto, kiedy, jaka operacja).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbe25cc7-562d-4e34-bb80-c90076b52e28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# View Delta table history using SQL\n",
    "display(spark.sql(f\"DESCRIBE HISTORY {CATALOG}.{BRONZE_SCHEMA}.customers_delta\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43df1ad8-f00a-4cd7-9523-19ab5fe37b08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Analiza ostatniego pliku transakcji (JSON):**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdcc63dc-5ddb-43bc-a6c9-d66bd06a3e9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sekcja 7: Optymalizacja (Wstęp)\n",
    "\n",
    "**Wprowadzenie teoretyczne:**\n",
    "\n",
    "Delta Lake oferuje szereg mechanizmów optymalizacyjnych. W tym notebooku skupimy się na podstawowej operacji **OPTIMIZE** (kompaktowanie plików) oraz **VACUUM** (czyszczenie).\n",
    "\n",
    "> **Deep Dive:** Zaawansowane techniki takie jak **ZORDER BY**, **Partycjonowanie** oraz **Liquid Clustering** są szczegółowo omówione w notebooku **05_optimization_best_practices.ipynb**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f9c4f15-246d-45c6-a0bc-1e30045a1480",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przykład 7.1: OPTIMIZE (File Compaction)\n",
    "\n",
    "**Cel:** Kompaktowanie małych plików (small files problem) w większe, co poprawia wydajność odczytu.\n",
    "Możemy opcjonalnie dodać klauzulę `ZORDER BY` (omówioną w notebooku 05), aby dodatkowo posortować dane.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1174aa1f-f82a-41ef-b546-03926982229b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Wykonaj kompaktowanie plików:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc6a4dca-4276-4b31-8204-b32d76b8f008",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# OPTIMIZE tabeli\n",
    "optimize_result = spark.sql(f\"\"\"\n",
    "    OPTIMIZE {CATALOG}.{BRONZE_SCHEMA}.customers_delta\n",
    "\"\"\")\n",
    "\n",
    "display(optimize_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc7cccdb-5e2c-4660-873c-350dcb6a7e5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przykład 7.3: Liquid Clustering (Wzmianka)\n",
    "\n",
    "**Nowoczesna alternatywa:**\n",
    "Databricks wprowadził **Liquid Clustering** - nową technikę, która zastępuje tradycyjne partycjonowanie i ZORDER. \n",
    "Liquid Clustering automatycznie zarządza układem danych, dostosowując się do wzorców zapytań.\n",
    "\n",
    "> **Deep Dive:** Szczegółowe omówienie i przykłady Liquid Clustering znajdują się w notebooku **05_optimization_best_practices.ipynb**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a90350c3-592c-4c03-9bb7-92ba92bb9619",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przykład 7.2: VACUUM operation\n",
    "\n",
    "**Cel:** Usunięcie starych plików (starszych niż retention period), które nie są już potrzebne do Time Travel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bac9e7c-da95-4f09-ab92-e02fb4688889",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Wyłącz sprawdzenie retencji (tylko dla demo):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11f438fa-d6ee-451c-b027-1f00e59a663e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# VACUUM - usuń pliki starsze niż 0 godzin (tylko dla demo!)\n",
    "# W produkcji: domyślnie 7 dni, minimum 0 godzin z flagą\n",
    "spark.sql(\"SET spark.databricks.delta.retentionDurationCheck.enabled = false\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c2c177c-7137-417b-b9bc-699ac095e39c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Uruchom VACUUM (usuń stare pliki):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd0c5a27-f19a-4dcf-b4ec-b42bc4fefcdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "vacuum_result = spark.sql(f\"\"\"\n",
    "    VACUUM {CATALOG}.{BRONZE_SCHEMA}.customers_delta RETAIN 0 HOURS\n",
    "\"\"\")\n",
    "\n",
    "display(vacuum_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d500c2a-b140-4774-8fd8-f6a8f72a61b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sekcja 8: Change Data Feed\n",
    "\n",
    "**Wprowadzenie teoretyczne:**\n",
    "\n",
    "Change Data Feed (CDF) to feature Delta Lake umożliwiający tracking wszystkich zmian w tabeli. Każda operacja INSERT, UPDATE, DELETE jest rejestrowana z dodatkowymi metadanymi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e75dfe2b-5e95-40ec-a93e-4877d0aa8bde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przykład 8.1: Włączenie Change Data Feed\n",
    "\n",
    "**Cel:** Aktywacja CDF dla istniejącej tabeli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "639ae751-8b2f-4b3b-a095-7ab6b2a93aa4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Włącz Change Data Feed:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c751f7dd-54c7-4b24-9e5a-7fc3f832e94b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Włącz Change Data Feed\n",
    "spark.sql(f\"\"\"\n",
    "    ALTER TABLE {CATALOG}.{BRONZE_SCHEMA}.customers_delta \n",
    "    SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96151b57-02c5-4570-ad7e-fb8c34e54a13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przykład 8.2: Generowanie zmian dla CDF\n",
    "\n",
    "**Cel:** Wykonanie operacji które będą śledzzone przez CDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4960a15-1701-4643-9d18-cfc296f18be1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Wstaw nowy rekord (INSERT):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "224323c5-701f-46c8-b900-7037e6362131",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Wykonaj więcej zmian po włączeniu CDF\n",
    "spark.sql(f\"\"\"\n",
    "    INSERT INTO {CATALOG}.{BRONZE_SCHEMA}.customers_delta\n",
    "    (customer_id, first_name, last_name, email, phone, city, state, country, registration_date, customer_segment, customer_tier)\n",
    "    VALUES ('CUST040001', 'CDF', 'TestCustomer', 'cdf@example.com', '+48 555 555 555', 'Szczecin', 'ZP', 'Poland', '2023-12-20', 'Basic', 'Bronze')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bf311b0-bc4a-448a-ab77-7304902cfc10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Zaktualizuj rekord (UPDATE):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46fa0519-a710-4a32-926b-21abf892d711",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "    UPDATE {CATALOG}.{BRONZE_SCHEMA}.customers_delta\n",
    "    SET customer_tier = 'Gold'\n",
    "    WHERE customer_id = 'CUST040001'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43687b9b-6070-4ea4-9e45-29e3dcf4990e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przykład 8.3: Odczyt Change Data Feed\n",
    "\n",
    "**Cel:** Analiza wszystkich zmian zarejestrowanych przez CDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57d10350-d356-4a9e-8528-43dc4f5d6fde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sprawdź CDF properties\n",
    "table_properties = spark.sql(f\"SHOW TBLPROPERTIES {CATALOG}.{BRONZE_SCHEMA}.customers_delta\")\n",
    "cdf_enabled = table_properties.filter(F.col(\"key\") == \"delta.enableChangeDataFeed\").count() > 0\n",
    "\n",
    "display(\n",
    "    spark.createDataFrame([\n",
    "        (\"Change Data Feed enabled\", cdf_enabled)\n",
    "    ], [\"property\", \"status\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97e4f5d7-e05e-4add-98f3-82b949e78d68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Odczytaj zmiany (CDF):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa382740-a553-4a6c-b279-d7486d9d11ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Batch read change data feed od określonej wersji\n",
    "# Najpierw sprawdźmy aktualną wersję\n",
    "current_version = spark.sql(f\"DESCRIBE HISTORY {CATALOG}.{BRONZE_SCHEMA}.customers_delta\").select(\"version\").first()[0]\n",
    "cdf_start_version = max(0, current_version - 3)  # Ostatnie 3 wersje\n",
    "\n",
    "display(current_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccada4af-f023-443e-b317-f4ed7774cdcf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "changes_batch = spark.read \\\n",
    "    .format(\"delta\") \\\n",
    "    .option(\"readChangeFeed\", \"true\") \\\n",
    "    .option(\"startingVersion\", cdf_start_version) \\\n",
    "    .table(f\"{CATALOG}.{BRONZE_SCHEMA}.customers_delta\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "242df922-463b-4450-9fef-4af54d0536ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(changes_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0689ff28-d0a9-4932-8774-1bcdb63386c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(\n",
    "    changes_batch.select(\n",
    "        \"customer_id\", \"first_name\", \"last_name\", \"customer_tier\", \n",
    "        \"_change_type\", \"_commit_version\", \"_commit_timestamp\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25cedf63-fba6-41bf-a116-fce3b82622ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sekcja 9: Zero-Copy Cloning\n",
    "\n",
    "**Wprowadzenie teoretyczne:**\n",
    "\n",
    "Delta Lake umożliwia tworzenie kopii tabel (Clones).\n",
    "- **SHALLOW CLONE**: Kopiuje tylko metadane (Delta Log), a dane fizyczne pozostają te same. Idealne do testów, QA, eksperymentów. Koszt storage = prawie zero.\n",
    "- **DEEP CLONE**: Kopiuje metadane i dane fizyczne. Idealne do archiwizacji lub migracji.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6059d07f-a64d-45e3-9451-c415816d5c3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Utwórz SHALLOW CLONE:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cecf35d-0973-4fe6-b86b-c568319005a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "spark.sql(f\"\"\"DROP TABLE IF EXISTS {CATALOG}.{BRONZE_SCHEMA}.customers_test_clone\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e2129d6-50c1-4478-a9ec-3c9ad36cb9d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Utwórz SHALLOW CLONE do testów\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE {CATALOG}.{BRONZE_SCHEMA}.customers_test_clone\n",
    "SHALLOW CLONE {CATALOG}.{BRONZE_SCHEMA}.customers_delta\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13a57562-d073-43c6-9afc-8d7cc7962370",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Wykonaj operację DELETE na klonie:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64d06a05-12b0-40e3-8d0b-c9cc5c687bdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Wykonaj destrukcyjną operację na klonie (nie wpływa na oryginał!)\n",
    "spark.sql(f\"DELETE FROM {CATALOG}.{BRONZE_SCHEMA}.customers_test_clone WHERE customer_tier = 'Premium'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "294011c9-3def-440a-b1d7-996d9e0ed6d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Porównaj liczniki (izolacja):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d869c5f-52dd-40b8-8b3e-0878d179afab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Porównaj liczniki\n",
    "orig_count = spark.table(f\"{CATALOG}.{BRONZE_SCHEMA}.customers_delta\").count()\n",
    "clone_count = spark.table(f\"{CATALOG}.{BRONZE_SCHEMA}.customers_test_clone\").count()\n",
    "\n",
    "print(f\"Oryginał: {orig_count}\")\n",
    "print(f\"Klon (po delete): {clone_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa251450-6d0e-42d4-aaeb-6d18b723e8b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Porównanie liczby rekordów potwierdza izolację. Oryginał powinien mieć więcej rekordów niż klon po usunięciu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9ddce78-57ba-4fcd-8a8f-7b819576c67d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(delta_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc55a400-75fc-4ce1-b7d0-a6c895ad7369",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**SQL Equivalent:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ce9b6cc-f0d9-454a-be14-8fdd2c679a75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SQL approach\n",
    "spark.sql(f\"\"\"\n",
    "    MERGE INTO {CATALOG}.{BRONZE_SCHEMA}.customers_delta AS target\n",
    "    USING (SELECT 'CUST050002' as customer_id, 'SQL' as first_name, 'Customer' as last_name,\n",
    "                  'sql@example.com' as email, '+48 333 333 333' as phone,\n",
    "                  'Lublin' as city, 'LB' as state, 'Poland' as country,\n",
    "                  '2023-12-26' as registration_date, 'Basic' as customer_segment,\n",
    "                  'Gold' as customer_tier) AS source\n",
    "    ON target.customer_id = source.customer_id\n",
    "    WHEN MATCHED THEN UPDATE SET *\n",
    "    WHEN NOT MATCHED THEN INSERT *\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02153e59-424b-4ab8-a95b-4f2f9968f758",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(f\"SELECT * FROM {CATALOG}.{BRONZE_SCHEMA}.customers_delta WHERE customer_id = 'CUST050003'\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e71caea6-dbb1-4e0b-9938-efb59a083341",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Porównanie:**\n",
    "- **Wydajność**: Identyczna - obydwa używają Catalyst optimizer\n",
    "- **Kiedy używać PySpark**: Programatic ETL, complex business logic, integration z ML pipelines\n",
    "- **Kiedy używać SQL**: Ad-hoc analysis, reporting, BI tools integration, łatwiejsze dla analityków"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7cabe0a-017c-48e4-9c6d-3bed9928c6fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Weryfikacja podstawowych metryk:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8a87116-854f-4790-89c3-87f817f3f737",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Weryfikacja wyników\n",
    "final_count = spark.table(f\"{CATALOG}.{BRONZE_SCHEMA}.customers_delta\").count()\n",
    "final_schema_cols = len(spark.table(f\"{CATALOG}.{BRONZE_SCHEMA}.customers_delta\").columns)\n",
    "history_count = spark.sql(f\"DESCRIBE HISTORY {CATALOG}.{BRONZE_SCHEMA}.customers_delta\").count()\n",
    "\n",
    "print(\n",
    "    (\"Total records\", final_count),\n",
    "    (\"Schema columns\", final_schema_cols),\n",
    "    (\"History versions\", history_count)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a666f44b-a6a5-4638-b9e1-58ece1a432d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Walidacja i weryfikacja\n",
    "\n",
    "### Checklist - Co powinieneś uzyskać:\n",
    "- [ ] Tabela Delta utworzona z automatycznym schema enforcement\n",
    "- [ ] Schema evolution - dodana kolumna customer_tier\n",
    "- [ ] Time Travel queries działają dla poprzednich wersji\n",
    "- [ ] CRUD operations (INSERT, UPDATE, DELETE) wykonane poprawnie\n",
    "- [ ] MERGE INTO zaimplementowane z upsert logic\n",
    "- [ ] Optymalizacja OPTIMIZE i ZORDER zastosowana\n",
    "- [ ] Change Data Feed włączony i rejestruje zmiany\n",
    "\n",
    "### Komendy weryfikacyjne:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9abaf3af-9908-419b-b1b5-c3600a0877b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Best Practices\n",
    "\n",
    "### Wydajność:\n",
    "- Używaj ZORDER BY dla kolumn często występujących w WHERE clauses\n",
    "- Regularnie uruchamiaj OPTIMIZE dla kompaktowania small files\n",
    "- Partitioning tylko dla bardzo dużych tabel (TB+) ze skewed data\n",
    "\n",
    "### Jakość kodu:\n",
    "- Zawsze używaj explicit schema zamiast inferSchema w production\n",
    "- Implementuj schema evolution strategy dla backward compatibility\n",
    "- Używaj MERGE INTO zamiast separate DELETE + INSERT operations\n",
    "\n",
    "### Data Quality:\n",
    "- Włącz Change Data Feed dla audit trails i compliance\n",
    "- Regularne backup przez Time Travel snapshots\n",
    "- Implement data validation rules w Delta constraints\n",
    "\n",
    "### Governance:\n",
    "- Ustaw odpowiednie retention periods dla compliance requirements\n",
    "- Używaj Unity Catalog permissions dla row/column level security\n",
    "- Dokumentuj schema changes i business logic w table comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b73ca7f6-db6e-4976-995a-aba8499e7337",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Problem 1: Schema enforcement błąd\n",
    "**Objawy:**\n",
    "- AnalysisException przy INSERT/MERGE z incompatible schema\n",
    "- \"Cannot write incompatible datatype\" message\n",
    "\n",
    "**Rozwiązanie:**\n",
    "```python\n",
    "# Użyj mergeSchema option dla schema evolution\n",
    "df.write.format(\"delta\").option(\"mergeSchema\", \"true\").mode(\"append\")\n",
    "```\n",
    "\n",
    "### Problem 2: Time Travel - version not found\n",
    "**Objawy:** \n",
    "File not found dla określonej wersji po VACUUM\n",
    "\n",
    "**Rozwiązanie:** \n",
    "Sprawdź retention period i dostępne wersje przez DESCRIBE HISTORY\n",
    "\n",
    "### Problem 3: VACUUM usuwa zbyt dużo plików\n",
    "**Objawy:** Time Travel queries failują po VACUUM\n",
    "\n",
    "**Rozwiązanie:** \n",
    "Ustaw odpowiedni retention period (domyślnie 7 dni minimum)\n",
    "\n",
    "### Debugging tips:\n",
    "- Użyj `DESCRIBE HISTORY` aby zrozumieć operacje na tabeli\n",
    "- Sprawdź `DESCRIBE DETAIL` dla metadanych o plikach\n",
    "- Weryfikuj table properties przez `SHOW TBLPROPERTIES`\n",
    "- Monitoruj `_delta_log/` folder dla troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8c2ffac-8f8c-4971-8de8-7f49727847b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Podsumowanie\n",
    "\n",
    "### Co zostało osiągnięte:\n",
    "- Demonstracja Delta Lake ACID properties i schema enforcement\n",
    "- Hands-on Schema Evolution z automatic column addition\n",
    "- Time Travel queries dla historical data access\n",
    "- Kompletne CRUD operations (CREATE, READ, UPDATE, DELETE)\n",
    "- Advanced MERGE INTO dla upsert scenarios\n",
    "- Performance optimization z OPTIMIZE, ZORDER, VACUUM\n",
    "- Change Data Feed dla comprehensive audit trails\n",
    "\n",
    "### Kluczowe wnioski:\n",
    "1. **Delta Lake = Data Lake + ACID**: Łączy elastyczność Data Lake z niezawodnością transakcyjną\n",
    "2. **Schema Evolution bezpiecznie**: Additive changes są automatyczne, breaking changes wymagają planowania\n",
    "3. **Time Travel + Copy-on-Write**: Każda wersja jest preserved, umożliwiając rollback i audit\n",
    "\n",
    "### Quick Reference - Najważniejsze komendy:\n",
    "\n",
    "| Operacja | PySpark | SQL |\n",
    "|----------|---------|-----|\n",
    "| Create Delta Table | `df.write.format(\"delta\").saveAsTable()` | `CREATE TABLE USING DELTA` |\n",
    "| Time Travel | `spark.read.format(\"delta\").option(\"versionAsOf\", 1)` | `SELECT * FROM table VERSION AS OF 1` |\n",
    "| MERGE | `DeltaTable.forName().merge().execute()` | `MERGE INTO target USING source` |\n",
    "| Optimize | N/A | `OPTIMIZE table ZORDER BY col` |\n",
    "| History | N/A | `DESCRIBE HISTORY table` |\n",
    "\n",
    "### Następne kroki:\n",
    "- **Kolejny notebook**: 02_medallion_architecture.ipynb\n",
    "- **Warsztat praktyczny**: 01_delta_medallion_workshop.ipynb\n",
    "- **Materiały dodatkowe**: Delta Lake documentation, best practices guides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "033141e2-8e5d-4719-9736-457b8b626118",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Czyszczenie zasobów\n",
    "\n",
    "Posprzątaj zasoby utworzone podczas notebooka:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e44c0a94-4fc6-4db6-8401-70759423a3c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Opcjonalne czyszczenie zasobów testowych\n",
    "# UWAGA: Uruchom tylko jeśli chcesz usunąć wszystkie utworzone dane\n",
    "\n",
    "# spark.sql(f\"DROP TABLE IF EXISTS {CATALOG}.{BRONZE_SCHEMA}.customers_delta\")\n",
    "# spark.sql(\"DROP VIEW IF EXISTS customer_updates\")\n",
    "# spark.catalog.clearCache()\n",
    "\n",
    "# display(spark.createDataFrame([(\"Zasoby zostały wyczyszczone\", \"✓\")], [\"status\", \"result\"]))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_delta_lake_operations",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
