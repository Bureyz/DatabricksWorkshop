{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce0f19c5",
   "metadata": {},
   "source": [
    "# Bronze â†’ Silver â†’ Gold Pipeline - Demo\n",
    "\n",
    "**Cel szkoleniowy:** Implementacja kompletnego end-to-end pipeline z Bronze przez Silver do Gold.\n",
    "\n",
    "**Zakres tematyczny:**\n",
    "- Bronze: raw load + audit columns (ingest_ts, source_file, ingested_by)\n",
    "- Silver: cleaning, deduplikacja, sanity checks, JSON flattening (from_json, explode)\n",
    "- Gold: KPI modeling, agregacje (daily/weekly/monthly), star schema vs denormalizacja\n",
    "- End-to-end data lineage\n",
    "- Performance monitoring per warstwa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0f949e",
   "metadata": {},
   "source": [
    "## Kontekst i wymagania\n",
    "\n",
    "- **DzieÅ„ szkolenia**: DzieÅ„ 2 - Lakehouse & Delta Lake\n",
    "- **Typ notebooka**: Demo\n",
    "- **Wymagania techniczne**:\n",
    "  - Databricks Runtime 13.0+ (zalecane: 14.3 LTS)\n",
    "  - Unity Catalog wÅ‚Ä…czony\n",
    "  - Uprawnienia: CREATE TABLE, CREATE SCHEMA, SELECT, MODIFY\n",
    "  - Klaster: Standard z minimum 2 workers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7ccd9a",
   "metadata": {},
   "source": [
    "## WstÄ™p teoretyczny\n",
    "\n",
    "**Cel sekcji:** Zrozumienie kompletnego data pipeline implementujÄ…cego Medallion Architecture (Bronze â†’ Silver â†’ Gold).\n",
    "\n",
    "---\n",
    "\n",
    "### Medallion Architecture - Metodologia\n",
    "\n",
    "**Medallion Architecture** to design pattern dla lakehouse architecture, ktÃ³ry organizuje dane w trzy warstwy jakoÅ›ci:\n",
    "\n",
    "```\n",
    "Raw Data Sources â†’ [BRONZE] â†’ [SILVER] â†’ [GOLD] â†’ BI/ML Consumers\n",
    "```\n",
    "\n",
    "#### ğŸ¥‰ **BRONZE LAYER (Raw/Landing Zone)**\n",
    "\n",
    "**Cel:** Immutable landing zone dla surowych danych\n",
    "\n",
    "**Charakterystyka:**\n",
    "- **1:1 kopia ÅºrÃ³dÅ‚a** - Å¼adne transformacje biznesowe\n",
    "- **Multi-format support** - JSON, CSV, Parquet, Avro, XML\n",
    "- **Audit metadata** - kto, kiedy, skÄ…d zaÅ‚adowaÅ‚ dane\n",
    "- **Append-only** - historia wszystkich load'Ã³w\n",
    "\n",
    "**Kluczowe kolumny:**\n",
    "- `_bronze_ingest_timestamp` - kiedy dane trafiÅ‚y do lakehouse\n",
    "- `_bronze_source_file` - z jakiego pliku pochodzÄ… dane\n",
    "- `_bronze_ingested_by` - kto/co zaÅ‚adowaÅ‚o dane\n",
    "- `_bronze_version` - wersja schematu/procesu\n",
    "\n",
    "**Zastosowanie:**\n",
    "- Data recovery - moÅ¼liwoÅ›Ä‡ reprocessingu\n",
    "- Audit trail dla compliance (GDPR, SOX)\n",
    "- Schema evolution bez utraty historii\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ¥ˆ **SILVER LAYER (Validated/Cleansed)**\n",
    "\n",
    "**Cel:** Czyste, zwalidowane dane gotowe do analiz\n",
    "\n",
    "**Charakterystyka:**\n",
    "- **Data quality enforcement** - reject/flag invalid records\n",
    "- **Deduplikacja** - unique business keys\n",
    "- **Standaryzacja** - formaty dat, case sensitivity, trimming\n",
    "- **Business rules** - walidacje biznesowe\n",
    "- **Type casting** - poprawne typy danych\n",
    "\n",
    "**Typowe transformacje:**\n",
    "- Deduplikacja: `dropDuplicates([\"business_key\"])`\n",
    "- Walidacja NOT NULL: `filter(col(\"key\").isNotNull())`\n",
    "- Standaryzacja: `withColumn(\"email\", lower(trim(col(\"email\"))))`\n",
    "- Type casting: `withColumn(\"date\", to_date(col(\"date_str\")))`\n",
    "\n",
    "**Data Quality Gates:**\n",
    "- Rejection rate monitoring (alert jeÅ›li > threshold)\n",
    "- Quality flags dla suspicious records\n",
    "- Logging invalid records dla investigation\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ¥‡ **GOLD LAYER (Business/Aggregates)**\n",
    "\n",
    "**Cel:** Business-level tables zoptymalizowane dla consumption\n",
    "\n",
    "**Charakterystyka:**\n",
    "- **Denormalizacja** - pre-computed joins dla performance\n",
    "- **Pre-agregacje** - daily, weekly, monthly summaries\n",
    "- **KPI tables** - business metrics i calculations\n",
    "- **Star schema** - fact tables + dimension tables\n",
    "\n",
    "**Design Patterns:**\n",
    "\n",
    "**A) Star Schema (Dimensional Model):**\n",
    "```\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚   DIM_DATE  â”‚\n",
    "         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜\n",
    "                â”‚\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚                       â”‚\n",
    "â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”\n",
    "â”‚ DIM_CUSTOMERâ”‚â—„â”€â”€â”€â”€â”€â”€â”¤ FACT_ORDERâ”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜\n",
    "                            â”‚\n",
    "                      â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”\n",
    "                      â”‚ DIM_PRODUCTâ”‚\n",
    "                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**B) Denormalized Wide Tables:**\n",
    "- Wszystkie dimensions zmergowane do fact table\n",
    "- Eliminuje joiny w query time â†’ performance\n",
    "- Trade-off: wiÄ™kszy storage vs faster queries\n",
    "\n",
    "---\n",
    "\n",
    "### Data Flow & Lineage\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    SOURCE SYSTEMS                            â”‚\n",
    "â”‚  â€¢ Transactional DBs  â€¢ APIs  â€¢ Files  â€¢ Streaming          â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                        â”‚\n",
    "                        â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    BRONZE LAYER                              â”‚\n",
    "â”‚  â€¢ Raw ingestion (COPY INTO, Auto Loader)                   â”‚\n",
    "â”‚  â€¢ Multi-format: JSON, CSV, Parquet                          â”‚\n",
    "â”‚  â€¢ Audit columns: _bronze_ingest_timestamp, _source_file     â”‚\n",
    "â”‚  â€¢ Immutable: append-only                                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                        â”‚\n",
    "                        â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    SILVER LAYER                              â”‚\n",
    "â”‚  â€¢ Data quality checks & validation                          â”‚\n",
    "â”‚  â€¢ Deduplikacja per business key                             â”‚\n",
    "â”‚  â€¢ Standaryzacja: dates, text, formats                       â”‚\n",
    "â”‚  â€¢ Type casting & business rules                             â”‚\n",
    "â”‚  â€¢ Rejection rate monitoring                                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                        â”‚\n",
    "                        â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    GOLD LAYER                                â”‚\n",
    "â”‚  â€¢ Star schema: Fact + Dimensions                            â”‚\n",
    "â”‚  â€¢ Denormalized tables (pre-computed joins)                  â”‚\n",
    "â”‚  â€¢ Pre-aggregated summaries (daily, monthly)                 â”‚\n",
    "â”‚  â€¢ KPI calculations & business metrics                       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                        â”‚\n",
    "                        â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    CONSUMPTION                               â”‚\n",
    "â”‚  â€¢ BI Dashboards (Power BI, Tableau)                         â”‚\n",
    "â”‚  â€¢ ML Models (Feature Store)                                 â”‚\n",
    "â”‚  â€¢ Ad-hoc Analytics (SQL)                                    â”‚\n",
    "â”‚  â€¢ Data Apps                                                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Star Schema - PrzykÅ‚ad dla e-commerce\n",
    "\n",
    "W tym notebooku zbudujemy nastÄ™pujÄ…cy star schema:\n",
    "\n",
    "```\n",
    "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                    â”‚   DIM_TIME       â”‚\n",
    "                    â”‚                  â”‚\n",
    "                    â”‚ â€¢ order_date     â”‚\n",
    "                    â”‚ â€¢ order_year     â”‚\n",
    "                    â”‚ â€¢ order_month    â”‚\n",
    "                    â”‚ â€¢ order_quarter  â”‚\n",
    "                    â”‚ â€¢ day_of_week    â”‚\n",
    "                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                             â”‚\n",
    "                             â”‚ 1:N\n",
    "                             â”‚\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚                        â”‚                        â”‚\n",
    "    â”‚                        â–¼                        â”‚\n",
    "â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  DIM_CUSTOMER   â”‚   â”‚  FACT_ORDER     â”‚    â”‚ DIM_PRODUCT   â”‚\n",
    "â”‚                 â”‚   â”‚  (Central)      â”‚    â”‚               â”‚\n",
    "â”‚ â€¢ customer_id   â”‚â—„â”€â”€â”¤                 â”œâ”€â”€â”€â–ºâ”‚ â€¢ product_id  â”‚\n",
    "â”‚ â€¢ customer_name â”‚ N:1â”‚ â€¢ order_id (PK) â”‚1:N â”‚ â€¢ product_nameâ”‚\n",
    "â”‚ â€¢ country       â”‚   â”‚ â€¢ customer_id   â”‚    â”‚ â€¢ category    â”‚\n",
    "â”‚ â€¢ email         â”‚   â”‚ â€¢ product_id    â”‚    â”‚ â€¢ price       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â€¢ order_date    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                      â”‚ â€¢ total_amount  â”‚\n",
    "                      â”‚ â€¢ payment_methodâ”‚\n",
    "                      â”‚ â€¢ is_high_value â”‚\n",
    "                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Relacje:**\n",
    "- **FACT_ORDER** (central fact table) - kaÅ¼dy rzÄ…d = jedna transakcja\n",
    "- **DIM_CUSTOMER** â†’ FACT_ORDER: 1:N (jeden klient, wiele zamÃ³wieÅ„)\n",
    "- **DIM_PRODUCT** â†’ FACT_ORDER: 1:N (jeden produkt, wiele zamÃ³wieÅ„)  \n",
    "- **DIM_TIME** â†’ FACT_ORDER: 1:N (jedna data, wiele zamÃ³wieÅ„)\n",
    "\n",
    "**Dlaczego Star Schema?**\n",
    "1. **Performance**: Proste joiny, Å‚atwa optymalizacja dla BI tools\n",
    "2. **CzytelnoÅ›Ä‡**: Intuicyjna struktura (fact = zdarzenie, dim = kontekst)\n",
    "3. **FlexibilnoÅ›Ä‡**: Åatwe dodawanie nowych dimensions bez zmiany fact table\n",
    "4. **Agregacje**: BI tools mogÄ… Å‚atwo grupowaÄ‡ po dimensions\n",
    "\n",
    "---\n",
    "\n",
    "### Dlaczego to waÅ¼ne?\n",
    "\n",
    "Production data pipeline musi:\n",
    "1. **ObsÅ‚ugiwaÄ‡ rÃ³Å¼ne ÅºrÃ³dÅ‚a** - JSON API, CSV exports, Parquet dumps\n",
    "2. **ZapewniaÄ‡ data quality** - validations, rejections, monitoring\n",
    "3. **OptymalizowaÄ‡ dla consumption** - denormalizacja, pre-agregacje\n",
    "4. **UmoÅ¼liwiaÄ‡ audyt** - data lineage od ÅºrÃ³dÅ‚a do dashboard\n",
    "5. **SkalowaÄ‡ siÄ™** - od MB do PB danych\n",
    "\n",
    "**W tym notebooku nauczymy siÄ™:**\n",
    "- BudowaÄ‡ kompletny Bronze â†’ Silver â†’ Gold pipeline\n",
    "- ImplementowaÄ‡ data quality gates w Silver\n",
    "- ProjektowaÄ‡ star schema w Gold\n",
    "- MonitorowaÄ‡ health pipeline'u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a75cdd9",
   "metadata": {},
   "source": [
    "## Izolacja per uÅ¼ytkownik\n",
    "\n",
    "Uruchom skrypt inicjalizacyjny dla per-user izolacji katalogÃ³w i schematÃ³w:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53ac219",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../00_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b9bae6",
   "metadata": {},
   "source": [
    "## Konfiguracja\n",
    "\n",
    "Import bibliotek i ustawienie zmiennych Å›rodowiskowych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155b614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# WyÅ›wietl kontekst uÅ¼ytkownika\n",
    "print(\"=== Kontekst uÅ¼ytkownika ===\")\n",
    "print(f\"Katalog: {CATALOG}\")\n",
    "print(f\"Schema Bronze: {BRONZE_SCHEMA}\")\n",
    "print(f\"Schema Silver: {SILVER_SCHEMA}\")\n",
    "print(f\"Schema Gold: {GOLD_SCHEMA}\")\n",
    "print(f\"UÅ¼ytkownik: {raw_user}\")\n",
    "\n",
    "# Ustaw katalog jako domyÅ›lny\n",
    "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
    "\n",
    "# ÅšcieÅ¼ki do danych ÅºrÃ³dÅ‚owych\n",
    "ORDERS_JSON = f\"{DATASET_BASE_PATH}/orders/orders_batch.json\"\n",
    "CUSTOMERS_CSV = f\"{DATASET_BASE_PATH}/customers/customers.csv\"\n",
    "PRODUCTS_PARQUET = f\"{DATASET_BASE_PATH}/products/products.parquet\"\n",
    "\n",
    "print(f\"\\n=== ÅšcieÅ¼ki do danych ===\")\n",
    "print(f\"Orders: {ORDERS_JSON}\")\n",
    "print(f\"Customers: {CUSTOMERS_CSV}\")\n",
    "print(f\"Products: {PRODUCTS_PARQUET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe6a927",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Sekcja 1: Bronze Layer - Raw Data Ingestion\n",
    "\n",
    "**Wprowadzenie teoretyczne:**\n",
    "\n",
    "Bronze layer przyjmuje surowe dane z rÃ³Å¼nych ÅºrÃ³deÅ‚ i formatÃ³w. Kluczowe jest dodanie audit metadata dla data lineage i troubleshooting.\n",
    "\n",
    "**Kluczowe operacje:**\n",
    "- Wczytanie z rÃ³Å¼nych formatÃ³w (JSON, CSV, Parquet)\n",
    "- Dodanie audit columns: ingest_timestamp, source_file, ingested_by\n",
    "- Zapis do Delta bez transformacji wartoÅ›ci biznesowych\n",
    "- Versioning dla incremental loads\n",
    "\n",
    "**Zastosowanie praktyczne:**\n",
    "- Immutable landing zone - moÅ¼liwoÅ›Ä‡ reprocessingu\n",
    "- Audit trail dla compliance\n",
    "- Multiple source formats w jednym pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01418fe",
   "metadata": {},
   "source": [
    "### PrzykÅ‚ad 1.1: Bronze - Orders (JSON)\n",
    "\n",
    "**Cel:** Ingest zamÃ³wieÅ„ z JSON do Bronze z audit metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468ba955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 1.1 - Bronze Orders (czÄ™Å›Ä‡ 1: wczytanie)\n",
    "\n",
    "spark.sql(f\"USE SCHEMA {BRONZE_SCHEMA}\")\n",
    "\n",
    "# Ustaw zmiennÄ… tabeli\n",
    "bronze_orders_table = f\"{BRONZE_SCHEMA}.orders_bronze\"\n",
    "\n",
    "# Wczytaj surowe orders z JSON\n",
    "orders_raw = (\n",
    "    spark.read\n",
    "    .format(\"json\")\n",
    "    .option(\"multiLine\", \"true\")\n",
    "    .load(ORDERS_JSON)\n",
    ")\n",
    "\n",
    "print(\"=== Raw Orders Schema ===\")\n",
    "orders_raw.printSchema()\n",
    "print(f\"\\nâœ“ Wczytano {orders_raw.count()} rekordÃ³w z JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b48817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 1.1 - Bronze Orders (czÄ™Å›Ä‡ 2: audit metadata)\n",
    "\n",
    "# Dodaj Bronze audit metadata\n",
    "orders_bronze = (\n",
    "    orders_raw\n",
    "    .withColumn(\"_bronze_ingest_timestamp\", F.current_timestamp())\n",
    "    .withColumn(\"_bronze_source_file\", F.input_file_name())\n",
    "    .withColumn(\"_bronze_ingested_by\", F.lit(raw_user))\n",
    "    .withColumn(\"_bronze_version\", F.lit(1))\n",
    ")\n",
    "\n",
    "print(\"=== Bronze Orders Schema (z audit columns) ===\")\n",
    "orders_bronze.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9bf106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 1.1 - Bronze Orders (czÄ™Å›Ä‡ 3: zapis do Delta)\n",
    "\n",
    "# Zapisz do Bronze table\n",
    "(\n",
    "    orders_bronze\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(bronze_orders_table)\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Bronze Orders zapisane: {bronze_orders_table}\")\n",
    "print(f\"Liczba rekordÃ³w: {spark.table(bronze_orders_table).count()}\")\n",
    "\n",
    "# PodglÄ…d danych\n",
    "display(spark.table(bronze_orders_table).limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805ea9ff",
   "metadata": {},
   "source": [
    "### PrzykÅ‚ad 1.2: Bronze - Customers (CSV) i Products (Parquet)\n",
    "\n",
    "**Cel:** Ingest danych klientÃ³w i produktÃ³w z rÃ³Å¼nych formatÃ³w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb355d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 1.2 - Bronze Customers (czÄ™Å›Ä‡ 1: wczytanie z CSV)\n",
    "\n",
    "bronze_customers_table = f\"{BRONZE_SCHEMA}.customers_bronze\"\n",
    "\n",
    "# Wczytaj Customers z CSV\n",
    "customers_raw = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(CUSTOMERS_CSV)\n",
    ")\n",
    "\n",
    "print(\"=== Raw Customers Schema ===\")\n",
    "customers_raw.printSchema()\n",
    "print(f\"\\nâœ“ Wczytano {customers_raw.count()} rekordÃ³w z CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9ee63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 1.2 - Bronze Customers (czÄ™Å›Ä‡ 2: audit metadata)\n",
    "\n",
    "# Dodaj Bronze audit metadata\n",
    "customers_bronze = (\n",
    "    customers_raw\n",
    "    .withColumn(\"_bronze_ingest_timestamp\", F.current_timestamp())\n",
    "    .withColumn(\"_bronze_source_file\", F.input_file_name())\n",
    "    .withColumn(\"_bronze_ingested_by\", F.lit(raw_user))\n",
    "    .withColumn(\"_bronze_version\", F.lit(1))\n",
    ")\n",
    "\n",
    "print(\"=== Bronze Customers Schema (z audit columns) ===\")\n",
    "customers_bronze.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb771dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 1.2 - Bronze Customers (czÄ™Å›Ä‡ 3: zapis do Delta)\n",
    "\n",
    "# Zapisz do Bronze table\n",
    "(\n",
    "    customers_bronze\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(bronze_customers_table)\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Bronze Customers zapisane: {bronze_customers_table}\")\n",
    "print(f\"Liczba rekordÃ³w: {spark.table(bronze_customers_table).count()}\")\n",
    "display(spark.table(bronze_customers_table).limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0e9ea1",
   "metadata": {},
   "source": [
    "### PrzykÅ‚ad 1.3: Bronze - Products (Parquet)\n",
    "\n",
    "**Cel:** Ingest produktÃ³w z Parquet do Bronze z audit metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 1.3 - Bronze Products (czÄ™Å›Ä‡ 1: wczytanie z Parquet)\n",
    "\n",
    "bronze_products_table = f\"{BRONZE_SCHEMA}.products_bronze\"\n",
    "\n",
    "# Wczytaj Products z Parquet\n",
    "products_raw = (\n",
    "    spark.read\n",
    "    .format(\"parquet\")\n",
    "    .load(PRODUCTS_PARQUET)\n",
    ")\n",
    "\n",
    "print(\"=== Raw Products Schema ===\")\n",
    "products_raw.printSchema()\n",
    "print(f\"\\nâœ“ Wczytano {products_raw.count()} rekordÃ³w z Parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febd0fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 1.3 - Bronze Products (czÄ™Å›Ä‡ 2: audit metadata)\n",
    "\n",
    "# Dodaj Bronze audit metadata\n",
    "products_bronze = (\n",
    "    products_raw\n",
    "    .withColumn(\"_bronze_ingest_timestamp\", F.current_timestamp())\n",
    "    .withColumn(\"_bronze_source_file\", F.input_file_name())\n",
    "    .withColumn(\"_bronze_ingested_by\", F.lit(raw_user))\n",
    "    .withColumn(\"_bronze_version\", F.lit(1))\n",
    ")\n",
    "\n",
    "print(\"=== Bronze Products Schema (z audit columns) ===\")\n",
    "products_bronze.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b5dde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 1.3 - Bronze Products (czÄ™Å›Ä‡ 3: zapis do Delta)\n",
    "\n",
    "# Zapisz do Bronze table\n",
    "(\n",
    "    products_bronze\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(bronze_products_table)\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Bronze Products zapisane: {bronze_products_table}\")\n",
    "print(f\"Liczba rekordÃ³w: {spark.table(bronze_products_table).count()}\")\n",
    "display(spark.table(bronze_products_table).limit(5))\n",
    "\n",
    "# Bronze Layer Summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"BRONZE LAYER SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"âœ“ Orders:    {spark.table(bronze_orders_table).count():,} records\")\n",
    "print(f\"âœ“ Customers: {spark.table(bronze_customers_table).count():,} records\")\n",
    "print(f\"âœ“ Products:  {spark.table(bronze_products_table).count():,} records\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bac51dd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Sekcja 2: Silver Layer - Cleansing & Validation\n",
    "\n",
    "**Wprowadzenie teoretyczne:**\n",
    "\n",
    "Silver layer wykonuje data quality checks, deduplikacjÄ™, standaryzacjÄ™ i flattening nested structures. To warstwa gdzie enforcement business rules.\n",
    "\n",
    "**Kluczowe transformacje:**\n",
    "- Deduplikacja po kluczu biznesowym\n",
    "- Walidacja NOT NULL, data types, ranges\n",
    "- Standaryzacja: dates, case sensitivity, formats\n",
    "- JSON flattening dla nested structures\n",
    "\n",
    "**Data Quality Gates:**\n",
    "- Reject invalid records (lub flaguj)\n",
    "- Log data quality metrics\n",
    "- Monitor rejection rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867f375f",
   "metadata": {},
   "source": [
    "### PrzykÅ‚ad 2.1: Silver Orders - Cleansing & Validation\n",
    "\n",
    "**Cel:** Transformacja Bronze Orders â†’ Silver z quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8498d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 2.1 - Silver Orders (czÄ™Å›Ä‡ 1: deduplikacja i walidacja NOT NULL)\n",
    "\n",
    "spark.sql(f\"USE SCHEMA {SILVER_SCHEMA}\")\n",
    "\n",
    "# Wczytaj z Bronze\n",
    "orders_bronze_df = spark.table(bronze_orders_table)\n",
    "\n",
    "print(f\"=== Bronze Orders - Input ===\")\n",
    "print(f\"Liczba rekordÃ³w: {orders_bronze_df.count()}\")\n",
    "\n",
    "# Deduplikacja po kluczu biznesowym\n",
    "orders_deduped = orders_bronze_df.dropDuplicates([\"order_id\"])\n",
    "print(f\"\\nâœ“ Po deduplikacji: {orders_deduped.count()} rekordÃ³w\")\n",
    "\n",
    "# Walidacja NOT NULL\n",
    "orders_validated = (\n",
    "    orders_deduped\n",
    "    .filter(F.col(\"order_id\").isNotNull())\n",
    "    .filter(F.col(\"customer_id\").isNotNull())\n",
    "    .filter(F.col(\"product_id\").isNotNull())\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Po walidacji NOT NULL: {orders_validated.count()} rekordÃ³w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a5f7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 2.1 - Silver Orders (czÄ™Å›Ä‡ 2: walidacja biznesowa i type casting)\n",
    "\n",
    "# Walidacja biznesowa: kwota musi byÄ‡ > 0\n",
    "orders_business_validated = (\n",
    "    orders_validated\n",
    "    .filter(F.col(\"total_amount\") > 0)\n",
    ")\n",
    "\n",
    "print(f\"=== Walidacja biznesowa ===\")\n",
    "print(f\"âœ“ Po walidacji total_amount > 0: {orders_business_validated.count()} rekordÃ³w\")\n",
    "\n",
    "# Rzutowanie typÃ³w i standaryzacja\n",
    "orders_typed = (\n",
    "    orders_business_validated\n",
    "    \n",
    "    # Parsowanie daty z order_datetime\n",
    "    .withColumn(\"order_date\", F.to_date(F.col(\"order_datetime\")))\n",
    "    .withColumn(\"order_timestamp\", F.to_timestamp(F.col(\"order_datetime\")))\n",
    "    \n",
    "    # Standaryzacja payment_method (uppercase, trim)\n",
    "    .withColumn(\"payment_method\", F.upper(F.trim(F.col(\"payment_method\"))))\n",
    "    \n",
    "    # Type casting dla consistency\n",
    "    .withColumn(\"total_amount\", F.col(\"total_amount\").cast(\"decimal(10,2)\"))\n",
    "    .withColumn(\"quantity\", F.col(\"quantity\").cast(\"integer\"))\n",
    ")\n",
    "\n",
    "print(\"\\n=== Silver Orders Schema (po type casting) ===\")\n",
    "orders_typed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c71bbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 2.1 - Silver Orders (czÄ™Å›Ä‡ 3: business logic i kategorie)\n",
    "\n",
    "# Dodaj business logic\n",
    "orders_silver = (\n",
    "    orders_typed\n",
    "    \n",
    "    # Kategorizacja kwot (biznes logic)\n",
    "    .withColumn(\n",
    "        \"order_value_category\",\n",
    "        F.when(F.col(\"total_amount\") < 100, \"LOW\")\n",
    "         .when(F.col(\"total_amount\") < 500, \"MEDIUM\")\n",
    "         .otherwise(\"HIGH\")\n",
    "    )\n",
    "    \n",
    "    # Oblicz wartoÅ›Ä‡ jednostkowÄ…\n",
    "    .withColumn(\n",
    "        \"unit_price\",\n",
    "        F.when(F.col(\"quantity\") > 0, F.col(\"total_amount\") / F.col(\"quantity\"))\n",
    "         .otherwise(F.lit(None))\n",
    "    )\n",
    "    \n",
    "    # Silver metadata\n",
    "    .withColumn(\"_silver_processed_timestamp\", F.current_timestamp())\n",
    "    .withColumn(\"_data_quality_flag\", F.lit(\"VALID\"))\n",
    ")\n",
    "\n",
    "print(\"=== Silver Orders - Final Schema ===\")\n",
    "orders_silver.printSchema()\n",
    "print(f\"\\nâœ“ Silver Orders gotowe do zapisu: {orders_silver.count()} rekordÃ³w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e221ca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 2.1 - Silver Orders (czÄ™Å›Ä‡ 4: quality metrics i zapis)\n",
    "\n",
    "# Quality metrics\n",
    "bronze_count = orders_bronze_df.count()\n",
    "silver_count = orders_silver.count()\n",
    "rejected_count = bronze_count - silver_count\n",
    "rejection_rate = (rejected_count / bronze_count * 100) if bronze_count > 0 else 0\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SILVER ORDERS - DATA QUALITY METRICS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Bronze input:  {bronze_count:,} records\")\n",
    "print(f\"Silver output: {silver_count:,} records\")\n",
    "print(f\"Rejected:      {rejected_count:,} records ({rejection_rate:.2f}%)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Zapisz do Silver\n",
    "silver_orders_table = f\"{SILVER_SCHEMA}.orders_silver\"\n",
    "\n",
    "(\n",
    "    orders_silver\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(silver_orders_table)\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Silver Orders zapisane: {silver_orders_table}\")\n",
    "display(spark.table(silver_orders_table).limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0e3734",
   "metadata": {},
   "source": [
    "### PrzykÅ‚ad 2.2: Silver Customers & Products\n",
    "\n",
    "**Cel:** Cleansing dimension tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f90e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 2.2 - Silver Customers (czÄ™Å›Ä‡ 1: deduplikacja i walidacja)\n",
    "\n",
    "customers_bronze_df = spark.table(bronze_customers_table)\n",
    "silver_customers_table = f\"{SILVER_SCHEMA}.customers_silver\"\n",
    "\n",
    "print(f\"=== Bronze Customers - Input ===\")\n",
    "print(f\"Liczba rekordÃ³w: {customers_bronze_df.count()}\")\n",
    "\n",
    "# Deduplikacja i walidacja\n",
    "customers_clean = (\n",
    "    customers_bronze_df\n",
    "    .dropDuplicates([\"customer_id\"])\n",
    "    .filter(F.col(\"customer_id\").isNotNull())\n",
    "    .filter(F.col(\"customer_name\").isNotNull())\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Po deduplikacji i walidacji: {customers_clean.count()} rekordÃ³w\")\n",
    "\n",
    "# Products (minimal cleaning - juÅ¼ dobre jakoÅ›ci)\n",
    "products_bronze_df = spark.table(bronze_products_table)\n",
    "\n",
    "products_silver = (\n",
    "    products_bronze_df\n",
    "    .dropDuplicates([\"product_id\"])\n",
    "    .filter(F.col(\"product_id\").isNotNull())\n",
    "    .withColumn(\"_silver_processed_timestamp\", F.current_timestamp())\n",
    ")\n",
    "\n",
    "silver_products_table = f\"{SILVER_SCHEMA}.products_silver\"\n",
    "\n",
    "(\n",
    "    products_silver\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(silver_products_table)\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Silver Products: {silver_products_table}\")\n",
    "print(f\"Liczba rekordÃ³w: {spark.table(silver_products_table).count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec0721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 2.2 - Silver Customers (czÄ™Å›Ä‡ 2: standaryzacja i walidacja email)\n",
    "\n",
    "# Standaryzacja\n",
    "customers_standardized = (\n",
    "    customers_clean\n",
    "    \n",
    "    # Standaryzacja text fields\n",
    "    .withColumn(\"customer_name\", F.trim(F.col(\"customer_name\")))\n",
    "    .withColumn(\"email\", F.lower(F.trim(F.col(\"email\"))))\n",
    "    .withColumn(\"country\", F.upper(F.trim(F.col(\"country\"))))\n",
    "    \n",
    "    # Walidacja email (basic regex pattern)\n",
    "    .withColumn(\n",
    "        \"email_valid\",\n",
    "        F.when(\n",
    "            F.col(\"email\").rlike(r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\"),\n",
    "            True\n",
    "        ).otherwise(False)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"=== Silver Customers - Po standaryzacji ===\")\n",
    "print(f\"Liczba rekordÃ³w: {customers_standardized.count()}\")\n",
    "print(\"\\nPrzykÅ‚adowe dane:\")\n",
    "display(customers_standardized.select(\"customer_id\", \"customer_name\", \"email\", \"email_valid\", \"country\").limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aa0eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 2.2 - Silver Customers (czÄ™Å›Ä‡ 3: metadata i zapis)\n",
    "\n",
    "# Dodaj Silver metadata\n",
    "customers_silver = (\n",
    "    customers_standardized\n",
    "    .withColumn(\"_silver_processed_timestamp\", F.current_timestamp())\n",
    "    .withColumn(\"_data_quality_flag\", F.lit(\"VALID\"))\n",
    ")\n",
    "\n",
    "# Zapisz do Silver\n",
    "(\n",
    "    customers_silver\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(silver_customers_table)\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Silver Customers zapisane: {silver_customers_table}\")\n",
    "print(f\"Liczba rekordÃ³w: {spark.table(silver_customers_table).count()}\")\n",
    "\n",
    "# Email validation stats\n",
    "email_stats = spark.table(silver_customers_table).groupBy(\"email_valid\").count()\n",
    "print(\"\\n=== Email Validation Stats ===\")\n",
    "display(email_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beba51f2",
   "metadata": {},
   "source": [
    "### PrzykÅ‚ad 2.3: Silver Products - Minimal Cleaning\n",
    "\n",
    "**Cel:** Cleansing produktÃ³w (dane juÅ¼ dobrej jakoÅ›ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a8dce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 2.3 - Silver Products\n",
    "\n",
    "products_bronze_df = spark.table(bronze_products_table)\n",
    "silver_products_table = f\"{SILVER_SCHEMA}.products_silver\"\n",
    "\n",
    "print(f\"=== Bronze Products - Input ===\")\n",
    "print(f\"Liczba rekordÃ³w: {products_bronze_df.count()}\")\n",
    "\n",
    "# Minimal cleaning (dane juÅ¼ dobrej jakoÅ›ci z Parquet)\n",
    "products_silver = (\n",
    "    products_bronze_df\n",
    "    .dropDuplicates([\"product_id\"])\n",
    "    .filter(F.col(\"product_id\").isNotNull())\n",
    "    .filter(F.col(\"product_name\").isNotNull())\n",
    "    \n",
    "    # Standaryzacja category\n",
    "    .withColumn(\"category\", F.upper(F.trim(F.col(\"category\"))))\n",
    "    \n",
    "    # Type casting dla price\n",
    "    .withColumn(\"price\", F.col(\"price\").cast(\"decimal(10,2)\"))\n",
    "    \n",
    "    # Silver metadata\n",
    "    .withColumn(\"_silver_processed_timestamp\", F.current_timestamp())\n",
    "    .withColumn(\"_data_quality_flag\", F.lit(\"VALID\"))\n",
    ")\n",
    "\n",
    "# Zapisz do Silver\n",
    "(\n",
    "    products_silver\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(silver_products_table)\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Silver Products zapisane: {silver_products_table}\")\n",
    "print(f\"Liczba rekordÃ³w: {spark.table(silver_products_table).count()}\")\n",
    "display(spark.table(silver_products_table).limit(5))\n",
    "\n",
    "# Silver Layer Summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SILVER LAYER SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"âœ“ Orders:    {spark.table(silver_orders_table).count():,} records\")\n",
    "print(f\"âœ“ Customers: {spark.table(silver_customers_table).count():,} records\")\n",
    "print(f\"âœ“ Products:  {spark.table(silver_products_table).count():,} records\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1961943a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Sekcja 3: Gold Layer - Business Modeling & Star Schema\n",
    "\n",
    "**Wprowadzenie teoretyczne:**\n",
    "\n",
    "Gold layer tworzy business-level aggregates i KPI tables zoptymalizowane dla consumption przez BI tools, dashboardy i ML models.\n",
    "\n",
    "---\n",
    "\n",
    "### Star Schema - Dimensional Modeling\n",
    "\n",
    "**Star Schema** to najpopularniejszy design pattern dla data warehousing, ktÃ³ry organizuje dane w:\n",
    "- **Fact Tables** (tabele faktÃ³w) - zdarzenia biznesowe, transakcje, pomiary\n",
    "- **Dimension Tables** (tabele wymiarÃ³w) - kontekst biznesowy dla faktÃ³w\n",
    "\n",
    "**Dlaczego \"Star\" (Gwiazda)?**\n",
    "Graficzne przedstawienie przypomina gwiazdÄ™: fact table w centrum, dimension tables dookoÅ‚a.\n",
    "\n",
    "```\n",
    "         DIM_TIME\n",
    "             â”‚\n",
    "             â”‚ 1:N\n",
    "             â”‚\n",
    "DIM_CUSTOMERâ”€â”¼â”€FACT_ORDERâ”€DIM_PRODUCT\n",
    "             â”‚\n",
    "             â”‚ 1:N\n",
    "             â”‚\n",
    "         DIM_REGION\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Nasza implementacja Star Schema dla e-commerce\n",
    "\n",
    "W tym notebooku zbudujemy nastÄ™pujÄ…cy model:\n",
    "\n",
    "#### **FACT_ORDER** (Central Fact Table)\n",
    "**Typ:** Transaction fact table (kaÅ¼dy rzÄ…d = jedna transakcja)\n",
    "\n",
    "**Kolumny:**\n",
    "- **Keys:** `order_id` (PK), `customer_id` (FK), `product_id` (FK)\n",
    "- **Measures (metryki):** `total_amount`, `quantity`, `unit_price`\n",
    "- **Time dimensions:** `order_date`, `order_year`, `order_month`, `order_quarter`, `day_of_week`\n",
    "- **Flags:** `is_high_value`, `order_value_category`, `payment_method`\n",
    "- **Denormalized dimensions:** `customer_name`, `country` (z DIM_CUSTOMER)\n",
    "\n",
    "**Grain (granularnoÅ›Ä‡):** Jedna transakcja = jeden produkt w jednym zamÃ³wieniu\n",
    "\n",
    "---\n",
    "\n",
    "#### **DIM_CUSTOMER** (Dimension Table)\n",
    "**Typ:** Slowly Changing Dimension (SCD Type 1 - overwrite)\n",
    "\n",
    "**Kolumny:**\n",
    "- `customer_id` (PK)\n",
    "- `customer_name`\n",
    "- `email`, `email_valid`\n",
    "- `country`\n",
    "- `_silver_processed_timestamp`\n",
    "\n",
    "**Relacja do FACT_ORDER:** 1:N (jeden klient, wiele zamÃ³wieÅ„)\n",
    "\n",
    "---\n",
    "\n",
    "#### **DIM_PRODUCT** (Dimension Table)\n",
    "**Typ:** Slowly Changing Dimension (SCD Type 1)\n",
    "\n",
    "**Kolumny:**\n",
    "- `product_id` (PK)\n",
    "- `product_name`\n",
    "- `category`\n",
    "- `price`\n",
    "- `_silver_processed_timestamp`\n",
    "\n",
    "**Relacja do FACT_ORDER:** 1:N (jeden produkt, wiele zamÃ³wieÅ„)\n",
    "\n",
    "---\n",
    "\n",
    "#### **DIM_TIME** (Dimension Table - implicit)\n",
    "W naszym przypadku time dimensions sÄ… denormalizowane w FACT_ORDER:\n",
    "- `order_date` (date)\n",
    "- `order_year`, `order_month`, `order_quarter` (partitioning keys)\n",
    "- `order_day_of_week` (dla weekly patterns)\n",
    "\n",
    "**Relacja do FACT_ORDER:** 1:N (jedna data, wiele zamÃ³wieÅ„)\n",
    "\n",
    "---\n",
    "\n",
    "### Denormalizacja vs Normalizacja\n",
    "\n",
    "**W tym notebooku uÅ¼ywamy denormalizacji:**\n",
    "\n",
    "âœ… **Denormalizacja (nasz approach):**\n",
    "```\n",
    "FACT_ORDER (denormalized):\n",
    "- order_id, customer_id, customer_name, country, product_id, \n",
    "  order_date, total_amount, payment_method, ...\n",
    "```\n",
    "\n",
    "**Zalety:**\n",
    "- âœ… Szybkie queries (bez joinÃ³w)\n",
    "- âœ… BI tools performance\n",
    "- âœ… Prostsze SQL dla analitykÃ³w\n",
    "\n",
    "**Wady:**\n",
    "- âš ï¸ WiÄ™kszy storage (duplikacja customer_name, country)\n",
    "- âš ï¸ Update complexity (trzeba update w wielu miejscach)\n",
    "\n",
    "---\n",
    "\n",
    "**Normalizacja (klasyczny star schema):**\n",
    "```\n",
    "FACT_ORDER (normalized):\n",
    "- order_id, customer_id, product_id, order_date, total_amount, ...\n",
    "\n",
    "DIM_CUSTOMER:\n",
    "- customer_id, customer_name, country, ...\n",
    "\n",
    "DIM_PRODUCT:\n",
    "- product_id, product_name, category, price, ...\n",
    "```\n",
    "\n",
    "**Zalety:**\n",
    "- âœ… Mniejszy storage\n",
    "- âœ… Åatwiejszy update dimensions\n",
    "\n",
    "**Wady:**\n",
    "- âš ï¸ Wymaga joinÃ³w w query time\n",
    "\n",
    "---\n",
    "\n",
    "### Pre-agregowane Summary Tables\n",
    "\n",
    "OprÃ³cz fact table tworzymy pre-aggregated summaries:\n",
    "\n",
    "**1. DAILY_SALES_SUMMARY**\n",
    "- **Grain:** dzieÅ„ + kraj + payment_method\n",
    "- **Measures:** total_orders, total_revenue, avg_order_value, unique_customers\n",
    "- **Use case:** Daily sales dashboards\n",
    "\n",
    "**2. MONTHLY_SALES_SUMMARY**\n",
    "- **Grain:** miesiÄ…c + kraj\n",
    "- **Measures:** total_orders, total_revenue, avg_order_value\n",
    "- **Use case:** Monthly business reviews\n",
    "\n",
    "**3. CUSTOMER_ANALYTICS**\n",
    "- **Grain:** customer_id\n",
    "- **Measures:** lifetime_value, total_orders, customer_segment\n",
    "- **Use case:** Customer segmentation, retention analysis\n",
    "\n",
    "---\n",
    "\n",
    "### Relacje miÄ™dzy tabelami\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                     GOLD LAYER SCHEMA                        â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   DIM_CUSTOMER       â”‚ 1:N Relationship\n",
    "â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ â€¢ customer_id (PK)   â”‚            â”‚\n",
    "â”‚ â€¢ customer_name      â”‚            â”‚\n",
    "â”‚ â€¢ email              â”‚            â–¼\n",
    "â”‚ â€¢ country            â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   FACT_ORDER         â”‚\n",
    "                             â”‚   (Central)          â”‚\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚                      â”‚\n",
    "â”‚   DIM_PRODUCT        â”‚     â”‚ â€¢ order_id (PK)      â”‚\n",
    "â”‚                      â”‚     â”‚ â€¢ customer_id (FK)   â”‚â—„â”€â”€â”€ Foreign Key\n",
    "â”‚ â€¢ product_id (PK)    â”‚â—„â”€â”€â”€â”€â”‚ â€¢ product_id (FK)    â”‚â—„â”€â”€â”€ Foreign Key\n",
    "â”‚ â€¢ product_name       â”‚ 1:N â”‚ â€¢ order_date         â”‚\n",
    "â”‚ â€¢ category           â”‚     â”‚ â€¢ total_amount       â”‚\n",
    "â”‚ â€¢ price              â”‚     â”‚ â€¢ payment_method     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ â€¢ is_high_value      â”‚\n",
    "                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                      â”‚\n",
    "                                      â”‚ Source for\n",
    "                                      â”‚ aggregations\n",
    "                                      â–¼\n",
    "            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "            â”‚     PRE-AGGREGATED SUMMARY TABLES           â”‚\n",
    "            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "            â”‚ â€¢ DAILY_SALES_SUMMARY                       â”‚\n",
    "            â”‚ â€¢ MONTHLY_SALES_SUMMARY                     â”‚\n",
    "            â”‚ â€¢ CUSTOMER_ANALYTICS                        â”‚\n",
    "            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Kluczowe zasady relacji:**\n",
    "1. **FACT_ORDER.customer_id** â†’ **DIM_CUSTOMER.customer_id** (1:N)\n",
    "2. **FACT_ORDER.product_id** â†’ **DIM_PRODUCT.product_id** (1:N)\n",
    "3. **FACT_ORDER** jest ÅºrÃ³dÅ‚em dla wszystkich summary tables\n",
    "\n",
    "---\n",
    "\n",
    "### Kluczowe operacje w Gold Layer\n",
    "\n",
    "**Kluczowe transformacje:**\n",
    "- **Joins** miÄ™dzy fact i dimension tables\n",
    "- **Denormalizacja** (pre-compute joins dla performance)\n",
    "- **Agregacje:** daily, weekly, monthly summaries\n",
    "- **KPI calculations:** lifetime value, customer segments\n",
    "- **Time dimensions:** year, month, quarter, day_of_week\n",
    "\n",
    "**Design patterns:**\n",
    "- âœ… Denormalized fact tables dla BI performance\n",
    "- âœ… Pre-aggregated summary tables na rÃ³Å¼nych granulacjach\n",
    "- âœ… Customer-level analytics dla segmentacji\n",
    "- âœ… Partitioning po date dla query performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4a5801",
   "metadata": {},
   "source": [
    "### PrzykÅ‚ad 3.1: Gold - Order Fact Table (Denormalized)\n",
    "\n",
    "**Cel:** Utworzenie denormalized fact table z joinami do dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b19da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 3.1 - Gold Order Fact Table (czÄ™Å›Ä‡ 1: wczytanie Silver tables)\n",
    "\n",
    "spark.sql(f\"USE SCHEMA {GOLD_SCHEMA}\")\n",
    "\n",
    "gold_order_fact_table = f\"{GOLD_SCHEMA}.order_fact\"\n",
    "\n",
    "# Wczytaj Silver tables\n",
    "orders_silver_df = spark.table(silver_orders_table)\n",
    "customers_silver_df = spark.table(silver_customers_table)\n",
    "products_silver_df = spark.table(silver_products_table)\n",
    "\n",
    "print(\"=== Silver Tables Loaded ===\")\n",
    "print(f\"Orders:    {orders_silver_df.count():,} records\")\n",
    "print(f\"Customers: {customers_silver_df.count():,} records\")\n",
    "print(f\"Products:  {products_silver_df.count():,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3333cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 3.1 - Gold Order Fact Table (czÄ™Å›Ä‡ 2: join z Customer dimension)\n",
    "\n",
    "# Przygotuj Customer dimension (wybierz tylko potrzebne kolumny)\n",
    "dim_customer = customers_silver_df.select(\n",
    "    F.col(\"customer_id\").alias(\"cust_id\"),\n",
    "    F.col(\"customer_name\"),\n",
    "    F.col(\"country\"),\n",
    "    F.col(\"email_valid\")\n",
    ")\n",
    "\n",
    "# Join Orders z Customer dimension (denormalization)\n",
    "order_with_customer = (\n",
    "    orders_silver_df\n",
    "    .join(\n",
    "        dim_customer,\n",
    "        orders_silver_df.customer_id == F.col(\"cust_id\"),\n",
    "        \"left\"  # LEFT JOIN - zachowaj wszystkie orders nawet bez customer match\n",
    "    )\n",
    "    .drop(\"cust_id\")  # UsuÅ„ alias column\n",
    ")\n",
    "\n",
    "print(\"=== After Customer Join ===\")\n",
    "print(f\"Liczba rekordÃ³w: {order_with_customer.count():,}\")\n",
    "\n",
    "# SprawdÅº czy sÄ… unmatched orders\n",
    "unmatched = order_with_customer.filter(F.col(\"customer_name\").isNull())\n",
    "print(f\"âš ï¸  Unmatched orders (no customer): {unmatched.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524777b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 3.1 - Gold Order Fact Table (czÄ™Å›Ä‡ 3: join z Product dimension)\n",
    "\n",
    "# Przygotuj Product dimension (wybierz tylko potrzebne kolumny)\n",
    "dim_product = products_silver_df.select(\n",
    "    F.col(\"product_id\").alias(\"prod_id\"),\n",
    "    F.col(\"product_name\"),\n",
    "    F.col(\"category\"),\n",
    "    F.col(\"price\")\n",
    ")\n",
    "\n",
    "# Join z Product dimension (denormalization)\n",
    "order_with_dimensions = (\n",
    "    order_with_customer\n",
    "    .join(\n",
    "        dim_product,\n",
    "        order_with_customer.product_id == F.col(\"prod_id\"),\n",
    "        \"left\"  # LEFT JOIN - zachowaj wszystkie orders nawet bez product match\n",
    "    )\n",
    "    .drop(\"prod_id\")  # UsuÅ„ alias column\n",
    ")\n",
    "\n",
    "print(\"=== After Product Join ===\")\n",
    "print(f\"Liczba rekordÃ³w: {order_with_dimensions.count():,}\")\n",
    "\n",
    "# SprawdÅº czy sÄ… unmatched products\n",
    "unmatched_products = order_with_dimensions.filter(F.col(\"product_name\").isNull())\n",
    "print(f\"âš ï¸  Unmatched orders (no product): {unmatched_products.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdc3be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 3.1 - Gold Order Fact Table (czÄ™Å›Ä‡ 4: time dimensions)\n",
    "\n",
    "# Dodaj time dimensions (dla partitioning i time-based analytics)\n",
    "order_with_time = (\n",
    "    order_with_dimensions\n",
    "    \n",
    "    # Time dimensions z order_date\n",
    "    .withColumn(\"order_year\", F.year(\"order_date\"))\n",
    "    .withColumn(\"order_month\", F.month(\"order_date\"))\n",
    "    .withColumn(\"order_quarter\", F.quarter(\"order_date\"))\n",
    "    .withColumn(\"order_day_of_week\", F.dayofweek(\"order_date\"))  # 1 = Sunday, 7 = Saturday\n",
    "    \n",
    "    # Dodaj month_name dla czytelnoÅ›ci\n",
    "    .withColumn(\"order_month_name\", F.date_format(\"order_date\", \"MMMM\"))\n",
    "    .withColumn(\"order_day_name\", F.date_format(\"order_date\", \"EEEE\"))\n",
    ")\n",
    "\n",
    "print(\"=== Time Dimensions Added ===\")\n",
    "print(\"\\nPrzykÅ‚adowe time dimensions:\")\n",
    "display(\n",
    "    order_with_time\n",
    "    .select(\"order_date\", \"order_year\", \"order_month\", \"order_month_name\", \n",
    "            \"order_quarter\", \"order_day_name\", \"order_day_of_week\")\n",
    "    .limit(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86d7036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 3.1 - Gold Order Fact Table (czÄ™Å›Ä‡ 5: KPI calculations)\n",
    "\n",
    "# Dodaj business KPIs i calculated fields\n",
    "order_fact = (\n",
    "    order_with_time\n",
    "    \n",
    "    # KPI: High value flag (zamÃ³wienia >= 500)\n",
    "    .withColumn(\n",
    "        \"is_high_value\",\n",
    "        F.when(F.col(\"total_amount\") >= 500, True).otherwise(False)\n",
    "    )\n",
    "    \n",
    "    # KPI: Revenue contribution (vs product price)\n",
    "    .withColumn(\n",
    "        \"revenue_vs_price_ratio\",\n",
    "        F.when(F.col(\"price\").isNotNull(), F.col(\"total_amount\") / F.col(\"price\"))\n",
    "         .otherwise(F.lit(None))\n",
    "    )\n",
    "    \n",
    "    # Gold metadata\n",
    "    .withColumn(\"_gold_created_timestamp\", F.current_timestamp())\n",
    "    .withColumn(\"_gold_table_name\", F.lit(\"order_fact\"))\n",
    ")\n",
    "\n",
    "print(\"=== KPI Calculations Complete ===\")\n",
    "print(f\"Liczba rekordÃ³w: {order_fact.count():,}\")\n",
    "print(\"\\nKPI distribution:\")\n",
    "display(\n",
    "    order_fact\n",
    "    .groupBy(\"is_high_value\", \"order_value_category\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"order_count\"),\n",
    "        F.sum(\"total_amount\").alias(\"total_revenue\")\n",
    "    )\n",
    "    .orderBy(F.col(\"total_revenue\").desc())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551bad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 3.1 - Gold Order Fact Table (czÄ™Å›Ä‡ 6: final selection i zapis)\n",
    "\n",
    "# Select final columns dla Fact Table\n",
    "order_fact_final = order_fact.select(\n",
    "    # Primary Key\n",
    "    \"order_id\",\n",
    "    \n",
    "    # Foreign Keys (relacje do dimensions)\n",
    "    \"customer_id\",\n",
    "    \"product_id\",\n",
    "    \n",
    "    # Denormalized Customer dimension\n",
    "    \"customer_name\",\n",
    "    \"country\",\n",
    "    \"email_valid\",\n",
    "    \n",
    "    # Denormalized Product dimension\n",
    "    \"product_name\",\n",
    "    \"category\",\n",
    "    \"price\",\n",
    "    \n",
    "    # Time dimensions\n",
    "    \"order_date\",\n",
    "    \"order_timestamp\",\n",
    "    \"order_year\",\n",
    "    \"order_month\",\n",
    "    \"order_month_name\",\n",
    "    \"order_quarter\",\n",
    "    \"order_day_of_week\",\n",
    "    \"order_day_name\",\n",
    "    \n",
    "    # Measures (metryki)\n",
    "    \"total_amount\",\n",
    "    \"quantity\",\n",
    "    \"unit_price\",\n",
    "    \n",
    "    # Flags & Categories\n",
    "    \"payment_method\",\n",
    "    \"order_value_category\",\n",
    "    \"is_high_value\",\n",
    "    \"revenue_vs_price_ratio\",\n",
    "    \n",
    "    # Metadata\n",
    "    \"_gold_created_timestamp\",\n",
    "    \"_gold_table_name\"\n",
    ")\n",
    "\n",
    "print(\"=== Gold Order Fact - Final Schema ===\")\n",
    "order_fact_final.printSchema()\n",
    "\n",
    "# Zapisz do Gold\n",
    "(\n",
    "    order_fact_final\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(gold_order_fact_table)\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Gold Order Fact zapisane: {gold_order_fact_table}\")\n",
    "print(f\"Liczba rekordÃ³w: {spark.table(gold_order_fact_table).count():,}\")\n",
    "display(spark.table(gold_order_fact_table).limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1f9880",
   "metadata": {},
   "source": [
    "### PrzykÅ‚ad 3.2: Gold - Aggregated Summary Tables\n",
    "\n",
    "**Cel:** Pre-aggregowane tabele dla dashboardÃ³w i raportÃ³w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf944e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 3.2 - Gold Daily Sales Summary (czÄ™Å›Ä‡ 1: agregacja)\n",
    "\n",
    "order_fact_df = spark.table(gold_order_fact_table)\n",
    "gold_daily_summary_table = f\"{GOLD_SCHEMA}.daily_sales_summary\"\n",
    "\n",
    "print(\"=== Daily Sales Summary - Agregacja ===\")\n",
    "\n",
    "# Daily aggregation: dzieÅ„ + kraj + payment_method\n",
    "daily_sales_summary = (\n",
    "    order_fact_df\n",
    "    .groupBy(\"order_date\", \"country\", \"payment_method\")\n",
    "    .agg(\n",
    "        # Order metrics\n",
    "        F.count(\"order_id\").alias(\"total_orders\"),\n",
    "        F.countDistinct(\"customer_id\").alias(\"unique_customers\"),\n",
    "        \n",
    "        # Revenue metrics\n",
    "        F.sum(\"total_amount\").alias(\"total_revenue\"),\n",
    "        F.avg(\"total_amount\").alias(\"avg_order_value\"),\n",
    "        F.min(\"total_amount\").alias(\"min_order_value\"),\n",
    "        F.max(\"total_amount\").alias(\"max_order_value\"),\n",
    "        \n",
    "        # Product metrics\n",
    "        F.sum(\"quantity\").alias(\"total_quantity\"),\n",
    "        F.countDistinct(\"product_id\").alias(\"unique_products\"),\n",
    "        \n",
    "        # High value orders\n",
    "        F.sum(\n",
    "            F.when(F.col(\"is_high_value\") == True, 1).otherwise(0)\n",
    "        ).alias(\"high_value_orders_count\"),\n",
    "        \n",
    "        F.sum(\n",
    "            F.when(F.col(\"is_high_value\") == True, F.col(\"total_amount\")).otherwise(0)\n",
    "        ).alias(\"high_value_revenue\")\n",
    "    )\n",
    "    .withColumn(\"_gold_created_timestamp\", F.current_timestamp())\n",
    "    .orderBy(\"order_date\", \"country\", \"payment_method\")\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Daily summary zagregowany: {daily_sales_summary.count():,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfad556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 3.2 - Gold Daily Sales Summary (czÄ™Å›Ä‡ 2: zapis)\n",
    "\n",
    "# Zapisz do Gold\n",
    "(\n",
    "    daily_sales_summary\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(gold_daily_summary_table)\n",
    ")\n",
    "\n",
    "print(f\"âœ… Gold Daily Sales Summary zapisane: {gold_daily_summary_table}\")\n",
    "print(f\"Liczba rekordÃ³w: {spark.table(gold_daily_summary_table).count():,}\")\n",
    "\n",
    "print(\"\\n=== Top 10 dni po revenue ===\")\n",
    "display(\n",
    "    spark.table(gold_daily_summary_table)\n",
    "    .orderBy(F.col(\"total_revenue\").desc())\n",
    "    .limit(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cef0bec",
   "metadata": {},
   "source": [
    "### PrzykÅ‚ad 3.3: Gold - Monthly Sales Summary\n",
    "\n",
    "**Cel:** Pre-agregacja miesiÄ™czna dla business reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6135a1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 3.3 - Gold Monthly Sales Summary\n",
    "\n",
    "gold_monthly_summary_table = f\"{GOLD_SCHEMA}.monthly_sales_summary\"\n",
    "\n",
    "# Monthly aggregation: rok + miesiÄ…c + kraj\n",
    "monthly_sales_summary = (\n",
    "    order_fact_df\n",
    "    .groupBy(\"order_year\", \"order_month\", \"order_month_name\", \"country\")\n",
    "    .agg(\n",
    "        # Order metrics\n",
    "        F.count(\"order_id\").alias(\"total_orders\"),\n",
    "        F.countDistinct(\"customer_id\").alias(\"unique_customers\"),\n",
    "        \n",
    "        # Revenue metrics\n",
    "        F.sum(\"total_amount\").alias(\"total_revenue\"),\n",
    "        F.avg(\"total_amount\").alias(\"avg_order_value\"),\n",
    "        \n",
    "        # Product metrics\n",
    "        F.sum(\"quantity\").alias(\"total_quantity\"),\n",
    "        F.countDistinct(\"product_id\").alias(\"unique_products\"),\n",
    "        \n",
    "        # Category breakdown\n",
    "        F.countDistinct(\"category\").alias(\"unique_categories\")\n",
    "    )\n",
    "    .withColumn(\"_gold_created_timestamp\", F.current_timestamp())\n",
    "    .orderBy(\"order_year\", \"order_month\", \"country\")\n",
    ")\n",
    "\n",
    "# Zapisz do Gold\n",
    "(\n",
    "    monthly_sales_summary\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(gold_monthly_summary_table)\n",
    ")\n",
    "\n",
    "print(f\"âœ… Gold Monthly Sales Summary zapisane: {gold_monthly_summary_table}\")\n",
    "print(f\"Liczba rekordÃ³w: {spark.table(gold_monthly_summary_table).count():,}\")\n",
    "display(spark.table(gold_monthly_summary_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51dc209",
   "metadata": {},
   "source": [
    "### PrzykÅ‚ad 3.4: Gold - Customer Analytics & Segmentation\n",
    "\n",
    "**Cel:** Customer lifetime value, tenure i segmentacja dla retention analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0813bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 3.4 - Gold Customer Analytics & Segmentation\n",
    "\n",
    "gold_customer_analytics_table = f\"{GOLD_SCHEMA}.customer_analytics\"\n",
    "\n",
    "# Customer-level aggregation\n",
    "customer_analytics = (\n",
    "    order_fact_df\n",
    "    .groupBy(\"customer_id\", \"customer_name\", \"country\", \"email_valid\")\n",
    "    .agg(\n",
    "        # Order metrics\n",
    "        F.count(\"order_id\").alias(\"total_orders\"),\n",
    "        F.min(\"order_date\").alias(\"first_order_date\"),\n",
    "        F.max(\"order_date\").alias(\"last_order_date\"),\n",
    "        \n",
    "        # Revenue metrics\n",
    "        F.sum(\"total_amount\").alias(\"lifetime_value\"),\n",
    "        F.avg(\"total_amount\").alias(\"avg_order_value\"),\n",
    "        F.max(\"total_amount\").alias(\"max_order_value\"),\n",
    "        \n",
    "        # Product diversity\n",
    "        F.countDistinct(\"product_id\").alias(\"unique_products_purchased\"),\n",
    "        F.countDistinct(\"category\").alias(\"unique_categories_purchased\"),\n",
    "        \n",
    "        # High value behavior\n",
    "        F.sum(\n",
    "            F.when(F.col(\"is_high_value\") == True, 1).otherwise(0)\n",
    "        ).alias(\"high_value_orders_count\"),\n",
    "        \n",
    "        # Payment method preferences\n",
    "        F.collect_set(\"payment_method\").alias(\"payment_methods_used\")\n",
    "    )\n",
    "    \n",
    "    # Customer tenure (days between first and last order)\n",
    "    .withColumn(\n",
    "        \"customer_tenure_days\",\n",
    "        F.datediff(F.col(\"last_order_date\"), F.col(\"first_order_date\"))\n",
    "    )\n",
    "    \n",
    "    # Order frequency (orders per day)\n",
    "    .withColumn(\n",
    "        \"order_frequency\",\n",
    "        F.when(\n",
    "            F.col(\"customer_tenure_days\") > 0,\n",
    "            F.col(\"total_orders\") / F.col(\"customer_tenure_days\")\n",
    "        ).otherwise(F.lit(None))\n",
    "    )\n",
    "    \n",
    "    # RFM-inspired segmentation\n",
    "    .withColumn(\n",
    "        \"customer_segment\",\n",
    "        F.when(F.col(\"lifetime_value\") >= 1000, \"PREMIUM\")\n",
    "         .when(F.col(\"lifetime_value\") >= 500, \"GOLD\")\n",
    "         .when(F.col(\"lifetime_value\") >= 200, \"SILVER\")\n",
    "         .otherwise(\"BRONZE\")\n",
    "    )\n",
    "    \n",
    "    # Customer tier based on order count\n",
    "    .withColumn(\n",
    "        \"customer_tier\",\n",
    "        F.when(F.col(\"total_orders\") >= 10, \"FREQUENT\")\n",
    "         .when(F.col(\"total_orders\") >= 5, \"REGULAR\")\n",
    "         .when(F.col(\"total_orders\") >= 2, \"OCCASIONAL\")\n",
    "         .otherwise(\"ONE_TIME\")\n",
    "    )\n",
    "    \n",
    "    .withColumn(\"_gold_created_timestamp\", F.current_timestamp())\n",
    "    .orderBy(F.col(\"lifetime_value\").desc())\n",
    ")\n",
    "\n",
    "# Zapisz do Gold\n",
    "(\n",
    "    customer_analytics\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(gold_customer_analytics_table)\n",
    ")\n",
    "\n",
    "print(f\"âœ… Gold Customer Analytics zapisane: {gold_customer_analytics_table}\")\n",
    "print(f\"Liczba klientÃ³w: {spark.table(gold_customer_analytics_table).count():,}\")\n",
    "\n",
    "print(\"\\n=== Top 10 Customers by Lifetime Value ===\")\n",
    "display(spark.table(gold_customer_analytics_table).limit(10))\n",
    "\n",
    "print(\"\\n=== Customer Segmentation Distribution ===\")\n",
    "display(\n",
    "    spark.table(gold_customer_analytics_table)\n",
    "    .groupBy(\"customer_segment\", \"customer_tier\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"customer_count\"),\n",
    "        F.sum(\"lifetime_value\").alias(\"total_revenue\"),\n",
    "        F.avg(\"lifetime_value\").alias(\"avg_lifetime_value\")\n",
    "    )\n",
    "    .orderBy(F.col(\"total_revenue\").desc())\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"GOLD LAYER SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"âœ“ Order Fact:         {spark.table(gold_order_fact_table).count():,} records\")\n",
    "print(f\"âœ“ Daily Summary:      {spark.table(gold_daily_summary_table).count():,} aggregates\")\n",
    "print(f\"âœ“ Monthly Summary:    {spark.table(gold_monthly_summary_table).count():,} aggregates\")\n",
    "print(f\"âœ“ Customer Analytics: {spark.table(gold_customer_analytics_table).count():,} customers\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe212bf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Sekcja 3.5: Star Schema - Relacje i Queries\n",
    "\n",
    "**Cel:** Zrozumienie relacji miÄ™dzy tabelami i przykÅ‚adowe queries wykorzystujÄ…ce star schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed788c66",
   "metadata": {},
   "source": [
    "### PrzykÅ‚ad 3.5.1: Weryfikacja relacji Star Schema\n",
    "\n",
    "**Cel:** Sprawdzenie integralnoÅ›ci referential integrity miÄ™dzy tabelami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e056b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 3.5.1 - Weryfikacja relacji Star Schema\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STAR SCHEMA - WERYFIKACJA RELACJI\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load tables\n",
    "fact_orders = spark.table(gold_order_fact_table)\n",
    "dim_customers = spark.table(silver_customers_table)\n",
    "dim_products = spark.table(silver_products_table)\n",
    "\n",
    "print(\"\\n[1] FACT_ORDER â†’ DIM_CUSTOMER Relationship (1:N)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# SprawdÅº czy wszystkie customer_id w FACT majÄ… match w DIM_CUSTOMER\n",
    "unmatched_customers = (\n",
    "    fact_orders\n",
    "    .select(\"customer_id\")\n",
    "    .distinct()\n",
    "    .join(\n",
    "        dim_customers.select(\"customer_id\"),\n",
    "        [\"customer_id\"],\n",
    "        \"left_anti\"  # Orders bez matching customer\n",
    "    )\n",
    ")\n",
    "\n",
    "unmatched_count = unmatched_customers.count()\n",
    "total_customers_in_fact = fact_orders.select(\"customer_id\").distinct().count()\n",
    "\n",
    "print(f\"Unique customers w FACT_ORDER: {total_customers_in_fact}\")\n",
    "print(f\"Unmatched customers (orphans): {unmatched_count}\")\n",
    "print(f\"âœ“ Referential integrity: {'OK' if unmatched_count == 0 else 'FAILED'}\")\n",
    "\n",
    "print(\"\\n[2] FACT_ORDER â†’ DIM_PRODUCT Relationship (1:N)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# SprawdÅº czy wszystkie product_id w FACT majÄ… match w DIM_PRODUCT\n",
    "unmatched_products = (\n",
    "    fact_orders\n",
    "    .select(\"product_id\")\n",
    "    .distinct()\n",
    "    .join(\n",
    "        dim_products.select(\"product_id\"),\n",
    "        [\"product_id\"],\n",
    "        \"left_anti\"  # Orders bez matching product\n",
    "    )\n",
    ")\n",
    "\n",
    "unmatched_products_count = unmatched_products.count()\n",
    "total_products_in_fact = fact_orders.select(\"product_id\").distinct().count()\n",
    "\n",
    "print(f\"Unique products w FACT_ORDER: {total_products_in_fact}\")\n",
    "print(f\"Unmatched products (orphans): {unmatched_products_count}\")\n",
    "print(f\"âœ“ Referential integrity: {'OK' if unmatched_products_count == 0 else 'FAILED'}\")\n",
    "\n",
    "print(\"\\n[3] Cardinality Analysis\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Customer â†’ Orders (1:N)\n",
    "customer_orders_stats = (\n",
    "    fact_orders\n",
    "    .groupBy(\"customer_id\")\n",
    "    .agg(F.count(\"order_id\").alias(\"order_count\"))\n",
    "    .agg(\n",
    "        F.min(\"order_count\").alias(\"min_orders_per_customer\"),\n",
    "        F.avg(\"order_count\").alias(\"avg_orders_per_customer\"),\n",
    "        F.max(\"order_count\").alias(\"max_orders_per_customer\")\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Customer â†’ Orders cardinality:\")\n",
    "display(customer_orders_stats)\n",
    "\n",
    "# Product â†’ Orders (1:N)\n",
    "product_orders_stats = (\n",
    "    fact_orders\n",
    "    .groupBy(\"product_id\")\n",
    "    .agg(F.count(\"order_id\").alias(\"order_count\"))\n",
    "    .agg(\n",
    "        F.min(\"order_count\").alias(\"min_orders_per_product\"),\n",
    "        F.avg(\"order_count\").alias(\"avg_orders_per_product\"),\n",
    "        F.max(\"order_count\").alias(\"max_orders_per_product\")\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\nProduct â†’ Orders cardinality:\")\n",
    "display(product_orders_stats)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ… Star Schema Relationships Validated\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a5ff7f",
   "metadata": {},
   "source": [
    "### PrzykÅ‚ad 3.5.2: Business Queries wykorzystujÄ…ce Star Schema\n",
    "\n",
    "**Cel:** PrzykÅ‚adowe analytical queries na Gold Layer (denormalized fact table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ca9d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 3.5.2 - Business Queries na Star Schema\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"BUSINESS QUERIES - STAR SCHEMA W PRAKTYCE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Query 1: Revenue by Country and Quarter (Time + Geographic dimension)\n",
    "print(\"\\n[Query 1] Revenue by Country and Quarter\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "revenue_by_country_quarter = (\n",
    "    spark.table(gold_order_fact_table)\n",
    "    .groupBy(\"country\", \"order_year\", \"order_quarter\")\n",
    "    .agg(\n",
    "        F.sum(\"total_amount\").alias(\"total_revenue\"),\n",
    "        F.count(\"order_id\").alias(\"total_orders\"),\n",
    "        F.countDistinct(\"customer_id\").alias(\"unique_customers\")\n",
    "    )\n",
    "    .orderBy(\"order_year\", \"order_quarter\", F.col(\"total_revenue\").desc())\n",
    ")\n",
    "\n",
    "display(revenue_by_country_quarter)\n",
    "\n",
    "# Query 2: Top Products by Category (Product dimension)\n",
    "print(\"\\n[Query 2] Top 10 Products by Revenue per Category\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "top_products_by_category = (\n",
    "    spark.table(gold_order_fact_table)\n",
    "    .groupBy(\"category\", \"product_name\")\n",
    "    .agg(\n",
    "        F.sum(\"total_amount\").alias(\"total_revenue\"),\n",
    "        F.sum(\"quantity\").alias(\"total_quantity\"),\n",
    "        F.countDistinct(\"customer_id\").alias(\"unique_buyers\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"rank\",\n",
    "        F.row_number().over(\n",
    "            Window.partitionBy(\"category\")\n",
    "            .orderBy(F.col(\"total_revenue\").desc())\n",
    "        )\n",
    "    )\n",
    "    .filter(F.col(\"rank\") <= 3)  # Top 3 per category\n",
    "    .orderBy(\"category\", \"rank\")\n",
    ")\n",
    "\n",
    "display(top_products_by_category)\n",
    "\n",
    "# Query 3: Payment Method Trends by Month (Time + Payment dimension)\n",
    "print(\"\\n[Query 3] Payment Method Trends Over Time\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "payment_trends = (\n",
    "    spark.table(gold_order_fact_table)\n",
    "    .groupBy(\"order_year\", \"order_month\", \"payment_method\")\n",
    "    .agg(\n",
    "        F.count(\"order_id\").alias(\"order_count\"),\n",
    "        F.sum(\"total_amount\").alias(\"revenue\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"revenue_share\",\n",
    "        F.round(\n",
    "            F.col(\"revenue\") / F.sum(\"revenue\").over(Window.partitionBy(\"order_year\", \"order_month\")) * 100,\n",
    "            2\n",
    "        )\n",
    "    )\n",
    "    .orderBy(\"order_year\", \"order_month\", F.col(\"revenue\").desc())\n",
    ")\n",
    "\n",
    "display(payment_trends)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ… PrzykÅ‚adowe queries pokazujÄ… jak denormalized fact table\")\n",
    "print(\"   eliminuje potrzebÄ™ joinÃ³w w query time â†’ performance BI tools\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c90f74",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Sekcja 4: Pipeline Monitoring & Lineage\n",
    "\n",
    "**Wprowadzenie teoretyczne:**\n",
    "\n",
    "Production pipeline wymaga monitoringu na kaÅ¼dym etapie: data volumes, quality metrics, processing time.\n",
    "\n",
    "**Kluczowe metryki:**\n",
    "- Record counts per warstwa\n",
    "- Rejection rates\n",
    "- Processing time\n",
    "- Data freshness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f4d028",
   "metadata": {},
   "source": [
    "### PrzykÅ‚ad 4.1: Pipeline Health Dashboard\n",
    "\n",
    "**Cel:** Monitoring kompletnego pipeline'u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda28853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad 4.1 - Pipeline Health Dashboard\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"                    PIPELINE HEALTH DASHBOARD                    \")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Bronze layer metrics\n",
    "print(\"\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "print(\"â”‚                     BRONZE LAYER (Raw Data)                  â”‚\")\n",
    "print(\"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "\n",
    "bronze_orders_count = spark.table(bronze_orders_table).count()\n",
    "bronze_customers_count = spark.table(bronze_customers_table).count()\n",
    "bronze_products_count = spark.table(bronze_products_table).count()\n",
    "\n",
    "print(f\"  ğŸ“¦ Orders:    {bronze_orders_count:>8,} records\")\n",
    "print(f\"  ğŸ‘¥ Customers: {bronze_customers_count:>8,} records\")\n",
    "print(f\"  ğŸ“¦ Products:  {bronze_products_count:>8,} records\")\n",
    "print(f\"  Total:        {bronze_orders_count + bronze_customers_count + bronze_products_count:>8,} records\")\n",
    "\n",
    "# Silver layer metrics\n",
    "print(\"\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "print(\"â”‚                  SILVER LAYER (Cleansed Data)                â”‚\")\n",
    "print(\"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "\n",
    "silver_orders_count = spark.table(silver_orders_table).count()\n",
    "silver_customers_count = spark.table(silver_customers_table).count()\n",
    "silver_products_count = spark.table(silver_products_table).count()\n",
    "\n",
    "orders_rejection_rate = ((bronze_orders_count - silver_orders_count) / bronze_orders_count * 100) if bronze_orders_count > 0 else 0\n",
    "customers_rejection_rate = ((bronze_customers_count - silver_customers_count) / bronze_customers_count * 100) if bronze_customers_count > 0 else 0\n",
    "products_rejection_rate = ((bronze_products_count - silver_products_count) / bronze_products_count * 100) if bronze_products_count > 0 else 0\n",
    "\n",
    "print(f\"  ğŸ“¦ Orders:    {silver_orders_count:>8,} records (rejection: {orders_rejection_rate:>5.2f}%)\")\n",
    "print(f\"  ğŸ‘¥ Customers: {silver_customers_count:>8,} records (rejection: {customers_rejection_rate:>5.2f}%)\")\n",
    "print(f\"  ğŸ“¦ Products:  {silver_products_count:>8,} records (rejection: {products_rejection_rate:>5.2f}%)\")\n",
    "\n",
    "# Gold layer metrics\n",
    "print(\"\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "print(\"â”‚              GOLD LAYER (Business-Ready Data)                â”‚\")\n",
    "print(\"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "\n",
    "gold_fact_count = spark.table(gold_order_fact_table).count()\n",
    "gold_daily_count = spark.table(gold_daily_summary_table).count()\n",
    "gold_monthly_count = spark.table(gold_monthly_summary_table).count()\n",
    "gold_customer_count = spark.table(gold_customer_analytics_table).count()\n",
    "\n",
    "print(f\"  â­ Order Fact Table:    {gold_fact_count:>8,} records\")\n",
    "print(f\"  ğŸ“Š Daily Summary:       {gold_daily_count:>8,} aggregates\")\n",
    "print(f\"  ğŸ“Š Monthly Summary:     {gold_monthly_count:>8,} aggregates\")\n",
    "print(f\"  ğŸ‘¥ Customer Analytics:  {gold_customer_count:>8,} customers\")\n",
    "\n",
    "# Data quality summary\n",
    "print(\"\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "print(\"â”‚                     DATA QUALITY METRICS                     â”‚\")\n",
    "print(\"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "\n",
    "print(f\"  âœ… Orders rejection rate:     {orders_rejection_rate:>6.2f}%\")\n",
    "print(f\"  âœ… Customers rejection rate:  {customers_rejection_rate:>6.2f}%\")\n",
    "print(f\"  âœ… Products rejection rate:   {products_rejection_rate:>6.2f}%\")\n",
    "print(f\"  âœ… Silverâ†’Gold propagation:  {(gold_fact_count / silver_orders_count * 100) if silver_orders_count > 0 else 0:>6.2f}%\")\n",
    "\n",
    "# Data flow summary\n",
    "print(\"\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "print(\"â”‚                      DATA FLOW SUMMARY                       â”‚\")\n",
    "print(\"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "\n",
    "print(f\"  Bronze â†’ Silver: {bronze_orders_count:>8,} â†’ {silver_orders_count:>8,} orders\")\n",
    "print(f\"  Silver â†’ Gold:   {silver_orders_count:>8,} â†’ {gold_fact_count:>8,} fact records\")\n",
    "\n",
    "# Overall status\n",
    "overall_rejection = (orders_rejection_rate + customers_rejection_rate + products_rejection_rate) / 3\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "if overall_rejection < 5:\n",
    "    print(\"                 âœ… Pipeline Status: HEALTHY\")\n",
    "elif overall_rejection < 10:\n",
    "    print(\"                 âš ï¸  Pipeline Status: WARNING (High Rejection)\")\n",
    "else:\n",
    "    print(\"                 âŒ Pipeline Status: CRITICAL (Very High Rejection)\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bf97f7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Best Practices - Production Pipeline\n",
    "\n",
    "### Bronze Layer Best Practices\n",
    "\n",
    "**âœ… Audit Metadata:**\n",
    "- Zawsze dodawaj `_bronze_ingest_timestamp`, `_bronze_source_file`, `_bronze_ingested_by`\n",
    "- UmoÅ¼liwia data lineage i troubleshooting\n",
    "- Weryfikacja: kiedy i skÄ…d dane trafiÅ‚y do lakehouse\n",
    "\n",
    "**âœ… Immutability:**\n",
    "- Nigdy nie UPDATE/DELETE w Bronze - tylko APPEND\n",
    "- Bronze = landing zone dla raw data recovery\n",
    "- UÅ¼ywaj `_bronze_version` dla schema evolution\n",
    "\n",
    "**âœ… Idempotency:**\n",
    "- UÅ¼ywaj COPY INTO lub Auto Loader\n",
    "- Checkpoint locations dla streaming\n",
    "- Zapobiega duplicate loads przy retry\n",
    "\n",
    "**âœ… Multi-format Support:**\n",
    "```python\n",
    "# JSON z multi-line\n",
    "spark.read.format(\"json\").option(\"multiLine\", \"true\").load(path)\n",
    "\n",
    "# CSV z header inference\n",
    "spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(path)\n",
    "\n",
    "# Parquet (binary efficient)\n",
    "spark.read.format(\"parquet\").load(path)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Silver Layer Best Practices\n",
    "\n",
    "**âœ… Data Quality Gates:**\n",
    "```python\n",
    "# Walidacja NOT NULL\n",
    ".filter(F.col(\"customer_id\").isNotNull())\n",
    "\n",
    "# Walidacja range\n",
    ".filter(F.col(\"total_amount\") > 0)\n",
    "\n",
    "# Walidacja regex (email)\n",
    ".filter(F.col(\"email\").rlike(r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\"))\n",
    "```\n",
    "\n",
    "**âœ… Rejection Rate Monitoring:**\n",
    "- Log rejection rates dla alerting (threshold: 5%)\n",
    "- Zapisuj rejected records do quarantine table dla investigation\n",
    "```python\n",
    "rejected_count = bronze_count - silver_count\n",
    "rejection_rate = (rejected_count / bronze_count * 100)\n",
    "if rejection_rate > 5:\n",
    "    # Alert operations team\n",
    "    pass\n",
    "```\n",
    "\n",
    "**âœ… Standaryzacja:**\n",
    "```python\n",
    "# Dates\n",
    ".withColumn(\"order_date\", F.to_date(F.col(\"order_datetime\")))\n",
    "\n",
    "# Text normalization\n",
    ".withColumn(\"email\", F.lower(F.trim(F.col(\"email\"))))\n",
    "\n",
    "# Case consistency\n",
    ".withColumn(\"country\", F.upper(F.trim(F.col(\"country\"))))\n",
    "```\n",
    "\n",
    "**âœ… Type Casting:**\n",
    "```python\n",
    "# Explicit type casting\n",
    ".withColumn(\"total_amount\", F.col(\"total_amount\").cast(\"decimal(10,2)\"))\n",
    ".withColumn(\"quantity\", F.col(\"quantity\").cast(\"integer\"))\n",
    "```\n",
    "\n",
    "**âœ… Slowly Changing Dimensions (SCD):**\n",
    "- SCD Type 1: Overwrite (dla dimension tables jak Customer, Product)\n",
    "- SCD Type 2: History tracking (jeÅ›li potrzebny audit history zmian)\n",
    "\n",
    "---\n",
    "\n",
    "### Gold Layer Best Practices\n",
    "\n",
    "**âœ… Denormalizacja dla Performance:**\n",
    "- Pre-compute joins miÄ™dzy fact i dimensions\n",
    "- Trade-off: wiÄ™kszy storage vs szybsze queries\n",
    "- Idealny dla BI dashboards (eliminuje joiny w runtime)\n",
    "\n",
    "```python\n",
    "# Denormalized fact table\n",
    "fact_with_dimensions = (\n",
    "    fact\n",
    "    .join(dim_customer, \"customer_id\", \"left\")  # LEFT JOIN!\n",
    "    .join(dim_product, \"product_id\", \"left\")\n",
    ")\n",
    "```\n",
    "\n",
    "**âš ï¸ UÅ¼ywaj LEFT JOIN:**\n",
    "- Zachowaj wszystkie fact records nawet bez dimension match\n",
    "- Monitor unmatched records (orphans)\n",
    "\n",
    "**âœ… Pre-agregacje:**\n",
    "```python\n",
    "# Daily summary\n",
    ".groupBy(\"order_date\", \"country\", \"payment_method\")\n",
    "\n",
    "# Monthly summary\n",
    ".groupBy(\"order_year\", \"order_month\", \"country\")\n",
    "\n",
    "# Customer-level\n",
    ".groupBy(\"customer_id\")\n",
    "```\n",
    "\n",
    "**âœ… Partitioning Strategy:**\n",
    "```python\n",
    "# Partition po date dla time-based queries\n",
    ".write.partitionBy(\"order_year\", \"order_month\")\n",
    "\n",
    "# ZORDER BY dla multi-dimensional filtering\n",
    "spark.sql(f\"OPTIMIZE {table_name} ZORDER BY (country, payment_method)\")\n",
    "```\n",
    "\n",
    "**âœ… Time Dimensions:**\n",
    "```python\n",
    "# Dodaj time dimensions dla analytics\n",
    ".withColumn(\"order_year\", F.year(\"order_date\"))\n",
    ".withColumn(\"order_month\", F.month(\"order_date\"))\n",
    ".withColumn(\"order_quarter\", F.quarter(\"order_date\"))\n",
    ".withColumn(\"order_day_of_week\", F.dayofweek(\"order_date\"))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Monitoring Best Practices\n",
    "\n",
    "**âœ… Pipeline Health Metrics:**\n",
    "- Record counts per warstwa\n",
    "- Rejection rates (Bronze â†’ Silver)\n",
    "- Processing time per stage\n",
    "- Data freshness (last ingest timestamp)\n",
    "\n",
    "**âœ… Alerting Thresholds:**\n",
    "- Rejection rate > 5% â†’ WARNING\n",
    "- Rejection rate > 10% â†’ CRITICAL\n",
    "- Unmatched dimensions > 1% â†’ WARNING\n",
    "\n",
    "**âœ… Data Lineage:**\n",
    "```python\n",
    "# DESCRIBE HISTORY dla audytu\n",
    "spark.sql(f\"DESCRIBE HISTORY {table_name}\").show()\n",
    "\n",
    "# Track data flow\n",
    "Bronze (_bronze_ingest_timestamp) \n",
    "  â†’ Silver (_silver_processed_timestamp) \n",
    "  â†’ Gold (_gold_created_timestamp)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Performance Optimization\n",
    "\n",
    "**âœ… File Size Optimization:**\n",
    "```python\n",
    "# OPTIMIZE dla small files problem\n",
    "spark.sql(f\"OPTIMIZE {table_name}\")\n",
    "\n",
    "# Auto optimize (Databricks specific)\n",
    "spark.sql(f\"ALTER TABLE {table_name} SET TBLPROPERTIES (delta.autoOptimize.optimizeWrite = true)\")\n",
    "```\n",
    "\n",
    "**âœ… ZORDER BY dla Multi-dimensional Queries:**\n",
    "```python\n",
    "# Colocate related information\n",
    "spark.sql(f\"OPTIMIZE {table_name} ZORDER BY (country, payment_method, order_date)\")\n",
    "```\n",
    "\n",
    "**âœ… VACUUM dla Storage Management:**\n",
    "```python\n",
    "# Clean up old files (default retention: 7 days)\n",
    "spark.sql(f\"VACUUM {table_name} RETAIN 168 HOURS\")  # 7 days\n",
    "```\n",
    "\n",
    "**âœ… Predicate Pushdown:**\n",
    "```python\n",
    "# Filter early w pipeline\n",
    ".filter(F.col(\"order_date\") >= \"2024-01-01\")  # Pushed to file scan\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5967a935",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Troubleshooting - Typowe problemy i rozwiÄ…zania\n",
    "\n",
    "### Problem 1: High Rejection Rate w Silver (> 5%)\n",
    "\n",
    "**Symptom:** DuÅ¼a liczba rekordÃ³w odrzucana podczas Bronze â†’ Silver\n",
    "\n",
    "**Diagnoza:**\n",
    "```python\n",
    "# Analiza odrzuconych rekordÃ³w\n",
    "bronze_df = spark.table(bronze_orders_table)\n",
    "rejected = bronze_df.filter(\n",
    "    F.col(\"order_id\").isNull() | \n",
    "    F.col(\"customer_id\").isNull() |\n",
    "    (F.col(\"total_amount\") <= 0)\n",
    ")\n",
    "\n",
    "print(f\"Rejected count: {rejected.count()}\")\n",
    "display(rejected.groupBy(\"_bronze_source_file\").count())\n",
    "```\n",
    "\n",
    "**RozwiÄ…zanie:**\n",
    "1. Zidentyfikuj root cause: null values, invalid formats, business rule violations\n",
    "2. Komunikuj z data source team o jakoÅ›ci danych\n",
    "3. RozwaÅ¼ quarantine table dla rejected records:\n",
    "```python\n",
    "# Zapisz rejected records\n",
    "rejected.write.format(\"delta\").mode(\"append\").saveAsTable(\"quarantine.rejected_orders\")\n",
    "```\n",
    "4. Implementuj auto-remediation dla known issues (np. fill defaults)\n",
    "\n",
    "---\n",
    "\n",
    "### Problem 2: Unmatched Foreign Keys w Gold (Orphan Records)\n",
    "\n",
    "**Symptom:** Orders bez matching customer/product po LEFT JOIN\n",
    "\n",
    "**Diagnoza:**\n",
    "```python\n",
    "# SprawdÅº unmatched customers\n",
    "fact_orders = spark.table(gold_order_fact_table)\n",
    "unmatched_customers = fact_orders.filter(F.col(\"customer_name\").isNull())\n",
    "\n",
    "print(f\"Unmatched customers: {unmatched_customers.count()}\")\n",
    "display(unmatched_customers.select(\"order_id\", \"customer_id\"))\n",
    "```\n",
    "\n",
    "**RozwiÄ…zanie:**\n",
    "1. **Referential integrity check** w Silver przed Gold:\n",
    "```python\n",
    "# Validate foreign keys przed joinami\n",
    "valid_customer_ids = dim_customer.select(\"customer_id\").distinct()\n",
    "orders_validated = orders.join(valid_customer_ids, \"customer_id\", \"inner\")\n",
    "```\n",
    "\n",
    "2. **Default handling** dla orphans:\n",
    "```python\n",
    "# UÅ¼yj coalesce dla missing dimensions\n",
    ".withColumn(\"customer_name\", F.coalesce(F.col(\"customer_name\"), F.lit(\"UNKNOWN\")))\n",
    "```\n",
    "\n",
    "3. **Monitor orphan rate** w pipeline metrics\n",
    "\n",
    "---\n",
    "\n",
    "### Problem 3: DÅ‚ugi Processing Time dla Gold Aggregations\n",
    "\n",
    "**Symptom:** Gold pipeline execution > 10 minutes dla small data volumes\n",
    "\n",
    "**Diagnoza:**\n",
    "```python\n",
    "# Explain query plan\n",
    "spark.table(silver_orders_table).explain(True)\n",
    "\n",
    "# Check file statistics\n",
    "spark.sql(f\"DESCRIBE DETAIL {silver_orders_table}\").show()\n",
    "```\n",
    "\n",
    "**RozwiÄ…zanie:**\n",
    "\n",
    "1. **Incremental Processing:**\n",
    "```python\n",
    "# Process tylko nowe/updated dates\n",
    "max_processed_date = spark.table(gold_daily_summary_table).agg(F.max(\"order_date\")).collect()[0][0]\n",
    "\n",
    "orders_incremental = (\n",
    "    spark.table(silver_orders_table)\n",
    "    .filter(F.col(\"order_date\") > max_processed_date)\n",
    ")\n",
    "```\n",
    "\n",
    "2. **Cache Silver tables** przed wieloma agregacjami:\n",
    "```python\n",
    "orders_silver_df.cache()\n",
    "# Multiple aggregations...\n",
    "orders_silver_df.unpersist()\n",
    "```\n",
    "\n",
    "3. **Optimize Silver tables:**\n",
    "```python\n",
    "spark.sql(f\"OPTIMIZE {silver_orders_table}\")\n",
    "spark.sql(f\"OPTIMIZE {silver_orders_table} ZORDER BY (order_date, customer_id)\")\n",
    "```\n",
    "\n",
    "4. **Partitioning:**\n",
    "```python\n",
    "# Partition Gold tables po date\n",
    ".write.partitionBy(\"order_year\", \"order_month\").saveAsTable(...)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Problem 4: Small Files Problem w Bronze\n",
    "\n",
    "**Symptom:** TysiÄ…ce maÅ‚ych plikÃ³w w Bronze Delta table\n",
    "\n",
    "**Diagnoza:**\n",
    "```python\n",
    "# Check file count\n",
    "detail = spark.sql(f\"DESCRIBE DETAIL {bronze_orders_table}\").collect()[0]\n",
    "print(f\"Number of files: {detail['numFiles']}\")\n",
    "print(f\"Size in bytes: {detail['sizeInBytes']}\")\n",
    "```\n",
    "\n",
    "**RozwiÄ…zanie:**\n",
    "\n",
    "1. **OPTIMIZE regualrnie:**\n",
    "```python\n",
    "# Manual optimize\n",
    "spark.sql(f\"OPTIMIZE {bronze_orders_table}\")\n",
    "\n",
    "# Auto-optimize (Databricks)\n",
    "spark.sql(f\"\"\"\n",
    "ALTER TABLE {bronze_orders_table} \n",
    "SET TBLPROPERTIES (\n",
    "  delta.autoOptimize.optimizeWrite = true,\n",
    "  delta.autoOptimize.autoCompact = true\n",
    ")\n",
    "\"\"\")\n",
    "```\n",
    "\n",
    "2. **Batch load zamiast per-file:**\n",
    "```python\n",
    "# Load wszystkie pliki w jednej operacji\n",
    "spark.read.format(\"json\").load(\"path/to/folder/*.json\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Problem 5: Schema Evolution Failures\n",
    "\n",
    "**Symptom:** Pipeline fails z schema mismatch error\n",
    "\n",
    "**Diagnoza:**\n",
    "```python\n",
    "# Compare schemas\n",
    "bronze_schema = spark.table(bronze_orders_table).schema\n",
    "new_data_schema = spark.read.json(new_file_path).schema\n",
    "\n",
    "print(\"Bronze schema:\", bronze_schema)\n",
    "print(\"New data schema:\", new_data_schema)\n",
    "```\n",
    "\n",
    "**RozwiÄ…zanie:**\n",
    "\n",
    "1. **Enable schema evolution:**\n",
    "```python\n",
    "# Merge schema mode\n",
    ".write.format(\"delta\").mode(\"append\").option(\"mergeSchema\", \"true\").saveAsTable(...)\n",
    "```\n",
    "\n",
    "2. **Schema validation before write:**\n",
    "```python\n",
    "# Validate schema compatibility\n",
    "if new_data_schema != expected_schema:\n",
    "    # Handle schema change\n",
    "    pass\n",
    "```\n",
    "\n",
    "3. **Track schema changes w audit:**\n",
    "```python\n",
    "# DESCRIBE HISTORY shows schema changes\n",
    "spark.sql(f\"DESCRIBE HISTORY {bronze_orders_table}\").filter(\"operation = 'WRITE'\").show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Problem 6: Data Quality Regression\n",
    "\n",
    "**Symptom:** Nagle spike w rejection rate lub invalid values\n",
    "\n",
    "**Diagnoza:**\n",
    "```python\n",
    "# Trend analysis rejection rates\n",
    "rejection_history = spark.sql(f\"\"\"\n",
    "SELECT \n",
    "    date(_bronze_ingest_timestamp) as ingest_date,\n",
    "    count(*) as total_records,\n",
    "    sum(case when _data_quality_flag = 'INVALID' then 1 else 0 end) as invalid_count\n",
    "FROM {silver_orders_table}\n",
    "GROUP BY date(_bronze_ingest_timestamp)\n",
    "ORDER BY ingest_date DESC\n",
    "\"\"\")\n",
    "\n",
    "display(rejection_history)\n",
    "```\n",
    "\n",
    "**RozwiÄ…zanie:**\n",
    "\n",
    "1. **Automated data quality checks:**\n",
    "```python\n",
    "# Define quality rules\n",
    "quality_checks = [\n",
    "    (\"not_null\", F.col(\"order_id\").isNotNull()),\n",
    "    (\"positive_amount\", F.col(\"total_amount\") > 0),\n",
    "    (\"valid_date\", F.col(\"order_date\") <= F.current_date())\n",
    "]\n",
    "\n",
    "for check_name, condition in quality_checks:\n",
    "    invalid_count = df.filter(~condition).count()\n",
    "    if invalid_count > threshold:\n",
    "        # Alert\n",
    "        pass\n",
    "```\n",
    "\n",
    "2. **Quarantine invalid data:**\n",
    "```python\n",
    "invalid_df = df.filter(~all_conditions)\n",
    "invalid_df.write.format(\"delta\").mode(\"append\").saveAsTable(\"quarantine_table\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Problem 7: Memory Out of Error (OOM)\n",
    "\n",
    "**Symptom:** Executor crashes z OutOfMemoryError\n",
    "\n",
    "**Diagnoza:**\n",
    "```python\n",
    "# Check data skew\n",
    "spark.table(silver_orders_table).groupBy(\"customer_id\").count().orderBy(F.col(\"count\").desc()).show()\n",
    "```\n",
    "\n",
    "**RozwiÄ…zanie:**\n",
    "\n",
    "1. **Repartition data:**\n",
    "```python\n",
    "# Repartition przed heavy operations\n",
    "df = df.repartition(200, \"customer_id\")\n",
    "```\n",
    "\n",
    "2. **Increase executor memory** w cluster configuration\n",
    "\n",
    "3. **Use broadcast joins** dla small dimension tables:\n",
    "```python\n",
    "from pyspark.sql.functions import broadcast\n",
    "fact.join(broadcast(small_dim), \"key\")\n",
    "```\n",
    "\n",
    "4. **Process w batches:**\n",
    "```python\n",
    "# Process per country\n",
    "countries = [row.country for row in df.select(\"country\").distinct().collect()]\n",
    "for country in countries:\n",
    "    country_df = df.filter(F.col(\"country\") == country)\n",
    "    # Process...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86ab351",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Podsumowanie\n",
    "\n",
    "**W tym notebooku zbudowaliÅ›my kompletny Bronze â†’ Silver â†’ Gold pipeline:**\n",
    "\n",
    "âœ… **Bronze Layer:**\n",
    "- Multi-format ingestion (JSON, CSV, Parquet)\n",
    "- Audit metadata dla lineage\n",
    "- Immutable landing zone\n",
    "\n",
    "âœ… **Silver Layer:**\n",
    "- Data quality validation\n",
    "- Deduplikacja i standaryzacja\n",
    "- Business rules enforcement\n",
    "- Quality metrics logging\n",
    "\n",
    "âœ… **Gold Layer:**\n",
    "- Denormalized fact tables\n",
    "- Pre-aggregated summaries (daily, monthly)\n",
    "- Customer analytics i segmentacja\n",
    "- BI-ready tables\n",
    "\n",
    "âœ… **Monitoring:**\n",
    "- Pipeline health dashboard\n",
    "- Data quality metrics\n",
    "- Rejection rate tracking\n",
    "\n",
    "**Kluczowe wnioski:**\n",
    "1. End-to-end pipeline wymaga rÃ³Å¼nych transformacji per warstwa\n",
    "2. Data quality gates w Silver chroniÄ… przed bad data w Gold\n",
    "3. Denormalizacja w Gold poprawia performance BI dashboardÃ³w\n",
    "4. Monitoring jest kluczowy dla production reliability\n",
    "\n",
    "**NastÄ™pne kroki:**\n",
    "- **Kolejny notebook**: 05_optimization_best_practices.ipynb\n",
    "- **Warsztat praktyczny**: 03_end_to_end_bronze_silver_gold_workshop.ipynb\n",
    "- **Delta Live Tables**: Declarative pipelines z automatic data quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abfbefa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cleanup\n",
    "\n",
    "PosprzÄ…taj zasoby utworzone podczas notebooka:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1def90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opcjonalne czyszczenie zasobÃ³w testowych\n",
    "# UWAGA: Uruchom tylko jeÅ›li chcesz usunÄ…Ä‡ wszystkie utworzone dane\n",
    "\n",
    "# Bronze\n",
    "# spark.sql(f\"DROP TABLE IF EXISTS {bronze_orders_table}\")\n",
    "# spark.sql(f\"DROP TABLE IF EXISTS {bronze_customers_table}\")\n",
    "# spark.sql(f\"DROP TABLE IF EXISTS {bronze_products_table}\")\n",
    "\n",
    "# Silver\n",
    "# spark.sql(f\"DROP TABLE IF EXISTS {silver_orders_table}\")\n",
    "# spark.sql(f\"DROP TABLE IF EXISTS {silver_customers_table}\")\n",
    "# spark.sql(f\"DROP TABLE IF EXISTS {silver_products_table}\")\n",
    "\n",
    "# Gold\n",
    "# spark.sql(f\"DROP TABLE IF EXISTS {gold_order_fact_table}\")\n",
    "# spark.sql(f\"DROP TABLE IF EXISTS {gold_daily_summary_table}\")\n",
    "# spark.sql(f\"DROP TABLE IF EXISTS {gold_monthly_summary_table}\")\n",
    "# spark.sql(f\"DROP TABLE IF EXISTS {gold_customer_analytics_table}\")\n",
    "\n",
    "# spark.catalog.clearCache()\n",
    "# print(\"Zasoby zostaÅ‚y wyczyszczone\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
