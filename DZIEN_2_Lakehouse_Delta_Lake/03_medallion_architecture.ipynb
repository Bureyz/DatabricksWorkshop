{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb6d571c-ebfe-44a0-908e-8079cd0e7cf3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Medallion Architecture\n",
    "\n",
    "**Cel szkoleniowy:** Opanowanie implementacji architektury medalionowej (Bronze ‚Üí Silver ‚Üí Gold) w Databricks.\n",
    "\n",
    "**Zakres tematyczny:**\n",
    "- Bronze Layer: Ingestion surowych danych (CSV, JSON, Parquet)\n",
    "- Silver Layer: Data Quality, Deduplication & Validation\n",
    "- SCD (Slowly Changing Dimensions): Implementacja SCD Type 1 i Type 2\n",
    "- Gold Layer: Agregacje biznesowe i Star Schema\n",
    "- Best Practices: Partycjonowanie, Z-Ordering, Data Retention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d54ecb3-6758-4504-b2d9-e38d7067126e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Kontekst i wymagania\n",
    "\n",
    "- **Dzie≈Ñ szkolenia**: Dzie≈Ñ 2 - Delta Lake & Lakehouse\n",
    "- **Typ notebooka**: Demo\n",
    "- **Wymagania techniczne**:\n",
    "  - Databricks Runtime 16.4 LTS lub nowszy (zalecane: 17.3 LTS)\n",
    "  - Unity Catalog w≈ÇƒÖczony\n",
    "  - Uprawnienia: CREATE TABLE, CREATE SCHEMA, SELECT, MODIFY\n",
    "  - Klaster: Standard lub **Serverless Compute** (zalecane)\n",
    "- **Zale≈ºno≈õci**: \n",
    "  - Wykonany notebook `01_delta_lake_operations.ipynb`\n",
    "  - Wykonany notebook `02_Lakeflow_Connection.ipynb` (dla danych Bronze)\n",
    "- **Czas realizacji**: ~90 minut\n",
    "\n",
    "> **Uwaga (2025):** Serverless Compute jest teraz domy≈õlnym trybem dla nowych workload√≥w."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4698a3de-470f-41c4-a11a-5dbec2b244a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Wstƒôp teoretyczny - Medallion Architecture\n",
    "\n",
    "**Cel sekcji:** Zrozumienie architektury medalionowej jako fundamentalnego design pattern dla data lakehouse.\n",
    "\n",
    "---\n",
    "\n",
    "### Czym jest Medallion Architecture?\n",
    "\n",
    "**Medallion Architecture** to wielowarstwowy wzorzec organizacji danych w data lakehouse, kt√≥ry dzieli dane na trzy warstwy o rosnƒÖcej jako≈õci i warto≈õci biznesowej:\n",
    "\n",
    "```\n",
    "DATA SOURCES\n",
    "    ‚Üì\n",
    "ü•â BRONZE (Raw)\n",
    "    ‚Üì cleansing\n",
    "ü•à SILVER (Validated)\n",
    "    ‚Üì aggregation\n",
    "ü•á GOLD (Business)\n",
    "    ‚Üì\n",
    "CONSUMPTION\n",
    "```\n",
    "\n",
    "### Warstwy - Szczeg√≥≈Çowy Opis\n",
    "\n",
    "#### ü•â Bronze Layer - Raw / Landing Zone\n",
    "\n",
    "**Charakterystyka:**\n",
    "- Dane \"as-is\" bez transformacji warto≈õci\n",
    "- Append-only, immutable\n",
    "- Audit metadata: `_ingestion_timestamp`, `_source_file`, `_user`\n",
    "- Multi-format: JSON, CSV, Parquet, Avro\n",
    "- Schema-on-read approach\n",
    "\n",
    "**Retention:** 3-7 lat (d≈Çugoterminowa historia)\n",
    "\n",
    "**Use Cases:**\n",
    "- Data recovery (reprocess pipeline)\n",
    "- Audit trail & compliance\n",
    "- Historical analysis\n",
    "- Data science exploration\n",
    "\n",
    "**Przyk≈Çad Bronze Table:**\n",
    "```sql\n",
    "CREATE TABLE bronze.orders_raw (\n",
    "    order_id STRING,\n",
    "    customer_id STRING,\n",
    "    order_date STRING,        -- Raw string, nie parsed\n",
    "    total_amount STRING,      -- Raw string, nie validated\n",
    "    payment_method STRING,\n",
    "    _ingestion_timestamp TIMESTAMP,\n",
    "    _source_file STRING,\n",
    "    _rescued_data STRING      -- Schema evolution\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ü•à Silver Layer - Cleansed / Validated\n",
    "\n",
    "**Charakterystyka:**\n",
    "- **Deduplikacja** po kluczu biznesowym\n",
    "- **Walidacja**: NOT NULL, data types, ranges\n",
    "- **Standaryzacja**: dates, text, formats\n",
    "- **Business rules** enforcement\n",
    "- **Schema enforcement** (strict schema)\n",
    "- **Upsert/Merge** patterns (SCD)\n",
    "\n",
    "**Retention:** 1-2 lata (medium-term history)\n",
    "\n",
    "**Use Cases:**\n",
    "- Foundation for analytics\n",
    "- Joins & enrichment\n",
    "- ML feature engineering\n",
    "- Data quality monitoring\n",
    "\n",
    "**Przyk≈Çad Silver Table:**\n",
    "```sql\n",
    "CREATE TABLE silver.orders_clean (\n",
    "    order_id BIGINT NOT NULL,     -- Validated, parsed\n",
    "    customer_id BIGINT NOT NULL,\n",
    "    order_date DATE NOT NULL,     -- Parsed to DATE\n",
    "    total_amount DECIMAL(10,2),   -- Validated numeric\n",
    "    payment_method STRING,\n",
    "    _quality_score INT,           -- Data quality metric\n",
    "    _processing_timestamp TIMESTAMP,\n",
    "    _is_valid BOOLEAN\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ü•á Gold Layer - Business / Aggregates\n",
    "\n",
    "**Charakterystyka:**\n",
    "- **Pre-aggregated** summaries (daily, monthly, yearly)\n",
    "- **Denormalized** tables (joins pre-computed)\n",
    "- **KPI calculations** & business metrics\n",
    "- **Star schema** / dimensional models\n",
    "- **ML feature stores**\n",
    "- **Query-optimized** (partitioned, indexed)\n",
    "\n",
    "**Retention:** 6-12 miesiƒôcy (short-term, refreshable)\n",
    "\n",
    "**Use Cases:**\n",
    "- BI dashboards (Power BI, Tableau)\n",
    "- Executive reports\n",
    "- ML model training\n",
    "- Self-service analytics\n",
    "\n",
    "**Przyk≈Çad Gold Table:**\n",
    "```sql\n",
    "CREATE TABLE gold.daily_sales_summary (\n",
    "    report_date DATE NOT NULL,\n",
    "    payment_method STRING,\n",
    "    total_orders BIGINT,\n",
    "    total_revenue DECIMAL(15,2),\n",
    "    avg_order_value DECIMAL(10,2),\n",
    "    unique_customers BIGINT,\n",
    "    _computation_timestamp TIMESTAMP\n",
    ")\n",
    "PARTITIONED BY (report_date)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Kluczowe Zasady Medallion Architecture\n",
    "\n",
    "**1. Separation of Concerns**\n",
    "- Bronze: Ingestion\n",
    "- Silver: Data Quality\n",
    "- Gold: Business Logic\n",
    "\n",
    "**2. Incremental Processing**\n",
    "- Process tylko nowe/zmienione dane\n",
    "- Delta Lake MERGE operations\n",
    "- Checkpoint management\n",
    "\n",
    "**3. Idempotency**\n",
    "- Mo≈ºna uruchomiƒá wielokrotnie bez duplikacji\n",
    "- Deterministic transformations\n",
    "- Unique keys & deduplication\n",
    "\n",
    "**4. Schema Evolution**\n",
    "- Bronze: Flexible (rescued data)\n",
    "- Silver: Controlled (addNewColumns)\n",
    "- Gold: Strict (versioned)\n",
    "\n",
    "**5. Data Quality Gates**\n",
    "- Validate before promoting to next layer\n",
    "- Quarantine bad records\n",
    "- Monitoring & alerting\n",
    "\n",
    "---\n",
    "\n",
    "### ETL vs ELT w Medallion\n",
    "\n",
    "**Traditional ETL:**\n",
    "```\n",
    "Extract ‚Üí Transform ‚Üí Load\n",
    "         (outside DB)\n",
    "```\n",
    "\n",
    "**Medallion ELT:**\n",
    "```\n",
    "Extract ‚Üí Load (Bronze) ‚Üí Transform (Silver) ‚Üí Load (Gold)\n",
    "                 ‚Üì                    ‚Üì              ‚Üì\n",
    "             raw data          cleansed data    aggregates\n",
    "```\n",
    "\n",
    "**Dlaczego ELT?**\n",
    "- Zachowanie raw data (compliance)\n",
    "- Flexibility (re-transform later)\n",
    "- Scalability (Spark distributed processing)\n",
    "- Cost-effective (storage cheaper than compute)\n",
    "\n",
    "---\n",
    "\n",
    "### Medallion vs Traditional Data Warehouse\n",
    "\n",
    "| Feature | Traditional DWH | Medallion Lakehouse |\n",
    "|---------|-----------------|---------------------|\n",
    "| **Storage** | Proprietary (expensive) | Cloud object storage (cheap) |\n",
    "| **Schema** | Schema-on-write | Schema-on-read (Bronze) |\n",
    "| **Data Types** | Structured only | Structured + semi-structured |\n",
    "| **Flexibility** | Rigid | Flexible (schema evolution) |\n",
    "| **Raw Data** | Discarded | Preserved (Bronze) |\n",
    "| **Processing** | ETL (batch) | ELT (batch + streaming) |\n",
    "| **Cost** | High (compute + storage) | Lower (decouple compute/storage) |\n",
    "| **Use Cases** | BI & reporting | BI + ML + data science |\n",
    "\n",
    "---\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "**1. Naming Conventions:**\n",
    "```\n",
    "bronze.{source_system}_{entity}_raw\n",
    "silver.{entity}_clean\n",
    "gold.{business_domain}_{aggregation_level}\n",
    "```\n",
    "\n",
    "**2. Partitioning:**\n",
    "- Bronze: Ingestion date (`_ingestion_date`)\n",
    "- Silver: Business date (`order_date`, `transaction_date`)\n",
    "- Gold: Report date (`report_date`)\n",
    "\n",
    "**3. Metadata Columns:**\n",
    "```python\n",
    "# Bronze\n",
    "_ingestion_timestamp, _source_file, _user\n",
    "\n",
    "# Silver\n",
    "_processing_timestamp, _quality_score, _is_valid\n",
    "\n",
    "# Gold\n",
    "_computation_timestamp, _version\n",
    "```\n",
    "\n",
    "**4. Refresh Cadence:**\n",
    "- Bronze: Real-time / hourly\n",
    "- Silver: Hourly / daily\n",
    "- Gold: Daily / on-demand\n",
    "\n",
    "**5. Data Retention:**\n",
    "```python\n",
    "# Bronze: 3-7 years (compliance)\n",
    "spark.sql(\"ALTER TABLE bronze.orders SET TBLPROPERTIES (\n",
    "    'delta.logRetentionDuration' = '2555 days',\n",
    "    'delta.deletedFileRetentionDuration' = '2555 days'\n",
    ")\")\n",
    "\n",
    "# Silver: 1-2 years\n",
    "# Gold: 6-12 months (refreshable from Silver)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Pipeline Architecture Diagram\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                      DATA SOURCES                             ‚îÇ\n",
    "‚îÇ  ‚Ä¢ PostgreSQL  ‚Ä¢ MySQL  ‚Ä¢ APIs  ‚Ä¢ S3 Files  ‚Ä¢ Kafka          ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                         ‚îÇ COPY INTO / Auto Loader\n",
    "                         ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                   ü•â BRONZE LAYER                             ‚îÇ\n",
    "‚îÇ                                                               ‚îÇ\n",
    "‚îÇ  bronze.customers_raw      bronze.orders_raw                 ‚îÇ\n",
    "‚îÇ  bronze.products_raw       bronze.events_raw                 ‚îÇ\n",
    "‚îÇ                                                               ‚îÇ\n",
    "‚îÇ  Features:                                                    ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Raw data (as-is)                                          ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Append-only                                               ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Audit metadata                                            ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Long retention (3-7y)                                     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                         ‚îÇ MERGE (Dedup, Validate)\n",
    "                         ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                   ü•à SILVER LAYER                             ‚îÇ\n",
    "‚îÇ                                                               ‚îÇ\n",
    "‚îÇ  silver.customers_clean    silver.orders_clean               ‚îÇ\n",
    "‚îÇ  silver.products_clean     silver.events_clean               ‚îÇ\n",
    "‚îÇ                                                               ‚îÇ\n",
    "‚îÇ  Features:                                                    ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Deduplicated                                              ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Validated (types, nulls)                                  ‚îÇ\n",
    "‚îÇ  ‚Ä¢ SCD Type 1/2 (history)                                    ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Medium retention (1-2y)                                   ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                         ‚îÇ GROUP BY / JOIN / AGGREGATE\n",
    "                         ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                   ü•á GOLD LAYER                               ‚îÇ\n",
    "‚îÇ                                                               ‚îÇ\n",
    "‚îÇ  gold.daily_sales_summary                                    ‚îÇ\n",
    "‚îÇ  gold.customer_360                                           ‚îÇ\n",
    "‚îÇ  gold.product_performance                                    ‚îÇ\n",
    "‚îÇ                                                               ‚îÇ\n",
    "‚îÇ  Features:                                                    ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Pre-aggregated                                            ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Denormalized (star schema)                                ‚îÇ\n",
    "‚îÇ  ‚Ä¢ KPIs & metrics                                            ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Short retention (6-12m)                                   ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                         ‚îÇ\n",
    "                         ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                  CONSUMPTION LAYER                            ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Power BI  ‚Ä¢ Tableau  ‚Ä¢ SQL Analytics  ‚Ä¢ ML Models         ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70768a08-3efd-458d-b186-e11c7a6372f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Izolacja per u≈ºytkownik\n",
    "\n",
    "Uruchom skrypt inicjalizacyjny dla per-user izolacji katalog√≥w i schemat√≥w:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2beb7c6c-feee-4484-8a79-ce93f91916b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../00_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9434034c-106e-4069-b478-88abd48f1594",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Konfiguracja\n",
    "\n",
    "Import bibliotek i ustawienie zmiennych ≈õrodowiskowych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "523e2bef-ff77-470c-a1ee-0038087a9919",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Wy≈õwietl kontekst u≈ºytkownika\n",
    "display({\n",
    "    \"Katalog\": CATALOG,\n",
    "    \"Schema Bronze\": BRONZE_SCHEMA,\n",
    "    \"Schema Silver\": SILVER_SCHEMA,\n",
    "    \"Schema Gold\": GOLD_SCHEMA,\n",
    "    \"U≈ºytkownik\": raw_user,\n",
    "    \"Dataset base\": DATASET_BASE_PATH\n",
    "})\n",
    "\n",
    "# Ustaw katalog i schemat jako domy≈õlne\n",
    "spark.sql(f\"USE CATALOG {CATALOG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kontekst u≈ºytkownika\n",
    "\n",
    "Wy≈õwietlenie aktualnej konfiguracji ≈õrodowiska oraz ≈õcie≈ºek do danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"USE CATALOG {CATALOG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Konfiguracja katalogu Unity Catalog:**\n",
    "\n",
    "Ustawienie domy≈õlnego katalogu dla wszystkich operacji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0552d1fb-1052-45c6-bb26-944b565508d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sekcja 1: Bronze Layer - Raw Data Landing\n",
    "\n",
    "**Cel sekcji:** Zrozumienie roli Bronze layer jako landing zone dla raw data.\n",
    "\n",
    "### Bronze Layer - Kluczowe Cechy\n",
    "\n",
    "**1. Raw Data \"As-Is\"**\n",
    "- Dane zapisywane bez transformacji warto≈õci\n",
    "- Zachowanie oryginalnego formatu\n",
    "- Multi-format support (JSON, CSV, Parquet)\n",
    "\n",
    "**2. Append-Only Pattern**\n",
    "- Nigdy nie usuwamy/modyfikujemy danych\n",
    "- Immutable history\n",
    "- Time-travel capability\n",
    "\n",
    "**3. Audit Metadata**\n",
    "```python\n",
    "# Metadane audytowe w Bronze\n",
    "_ingestion_timestamp  # Kiedy za≈Çadowano\n",
    "_source_file         # SkƒÖd pochodzƒÖ dane\n",
    "_user                # Kto za≈Çadowa≈Ç\n",
    "_rescued_data        # Schema evolution (unexpected columns)\n",
    "```\n",
    "\n",
    "**4. Schema-on-Read**\n",
    "- Elastyczny schemat (mo≈ºe siƒô zmieniaƒá)\n",
    "- Rescued data column dla unknown columns\n",
    "- Reprocessing capability\n",
    "\n",
    "### Bronze Tables - Struktura\n",
    "\n",
    "W tym demo za≈Çadujemy dane bezpo≈õrednio z plik√≥w ≈∫r√≥d≈Çowych (CSV, JSON, Parquet) do warstwy Bronze, aby zapewniƒá niezale≈ºno≈õƒá tego notebooka.\n",
    "\n",
    "**Tabele Bronze:**\n",
    "- `bronze.customers_raw` - dane klient√≥w (CSV)\n",
    "- `bronze.orders_raw` - zam√≥wienia (JSON)\n",
    "- `bronze.products_raw` - produkty (Parquet)\n",
    "\n",
    "### Dlaczego Bronze jest Wa≈ºny?\n",
    "\n",
    "**1. Data Recovery**\n",
    "```python\n",
    "# Mo≈ºemy reprocessowaƒá pipeline od Bronze\n",
    "bronze_data = spark.table(\"bronze.orders_raw\")\n",
    "# Re-run transformations ‚Üí Silver ‚Üí Gold\n",
    "```\n",
    "\n",
    "**2. Schema Evolution**\n",
    "```python\n",
    "# Nowe kolumny w source nie ≈ÇamiƒÖ pipeline\n",
    "# TrafiajƒÖ do _rescued_data\n",
    "```\n",
    "\n",
    "**3. Compliance & Audit**\n",
    "```python\n",
    "# Pe≈Çna historia: kto, co, kiedy za≈Çadowa≈Ç\n",
    "# Retention: 3-7 lat (regulacje prawne)\n",
    "```\n",
    "\n",
    "**4. Data Science Exploration**\n",
    "```python\n",
    "# Analitycy mogƒÖ eksplorowaƒá raw data\n",
    "# Tworzyƒá nowe features z surowych danych\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e23da394-d79a-4736-850e-ab58bc53ec44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przyk≈Çad 1.1: Inspekcja Bronze Layer\n",
    "\n",
    "**Cel:** Sprawdziƒá dane w Bronze layer i zrozumieƒá ich strukturƒô."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przyk≈Çad 1.1: Ingestion do Bronze Layer (Raw Data)\n",
    "\n",
    "Wczytujemy dane bezpo≈õrednio z plik√≥w ≈∫r√≥d≈Çowych (CSV, JSON, Parquet) do tabel Bronze.\n",
    "Dziƒôki temu notebook jest niezale≈ºny od poprzednich krok√≥w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Customers (CSV)\n",
    "customers_path = f\"{DATASET_BASE_PATH}/customers/customers.csv\"\n",
    "\n",
    "customers_df = (spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\") # In Bronze we often infer or use string\n",
    "    .load(customers_path)\n",
    ")\n",
    "\n",
    "display(customers_df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load Products (Parquet)\n",
    "products_path = f\"{DATASET_BASE_PATH}/products/products.parquet\"\n",
    "\n",
    "products_df = (spark.read\n",
    "    .format(\"parquet\")\n",
    "    .load(products_path)\n",
    ")\n",
    "\n",
    "# Write to Bronze\n",
    "(products_df.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .saveAsTable(\"bronze.products_raw\")\n",
    ")\n",
    "\n",
    "display({\"status\": \"‚úÖ Table bronze.products_raw created/overwritten\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load Orders (JSON)\n",
    "orders_path = f\"{DATASET_BASE_PATH}/orders/orders_batch.json\"\n",
    "\n",
    "orders_df = (spark.read\n",
    "    .format(\"json\")\n",
    "    .load(orders_path)\n",
    ")\n",
    "\n",
    "# Write to Bronze\n",
    "(orders_df.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .saveAsTable(\"bronze.orders_raw\")\n",
    ")\n",
    "\n",
    "display({\"status\": \"‚úÖ Table bronze.orders_raw created/overwritten\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to Bronze (Overwrite for full load simulation)\n",
    "(customers_df.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .saveAsTable(\"bronze.customers_raw\")\n",
    ")\n",
    "\n",
    "display({\"status\": \"‚úÖ Table bronze.customers_raw created/overwritten\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utworzone tabele Bronze:**\n",
    "\n",
    "Konwersja danych z batch do raw tables zosta≈Ça zako≈Ñczona pomy≈õlnie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf979d26-91e7-44e4-b426-b573656a2b60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Inspekcja Bronze Layer\n",
    "bronze_tables = [\"customers_raw\", \"orders_raw\", \"products_raw\"]\n",
    "results = []\n",
    "\n",
    "for table in bronze_tables:\n",
    "    full_table = f\"{CATALOG}.{BRONZE_SCHEMA}.{table}\"\n",
    "    \n",
    "    if spark.catalog.tableExists(full_table):\n",
    "        df = spark.table(full_table)\n",
    "        results.append({\n",
    "            \"table\": table,\n",
    "            \"status\": \"‚úÖ\",\n",
    "            \"records\": df.count(),\n",
    "            \"columns\": len(df.columns)\n",
    "        })\n",
    "\n",
    "display(spark.createDataFrame(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Podsumowanie inspekcji Bronze Layer:**\n",
    "\n",
    "Bronze Layer zawiera RAW data bez transformacji, zachowuje pe≈ÇnƒÖ historiƒô (append-only) i stanowi foundation dla dalszych transformacji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1b7d116-87c4-44f0-9790-54bc9ef7417f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sekcja 2: Silver Layer - Cleansing & Validation\n",
    "\n",
    "**Cel sekcji:** Transformacja danych z Bronze do Silver z zastosowaniem data quality rules.\n",
    "\n",
    "### Silver Layer - Kluczowe Cechy\n",
    "\n",
    "**1. Data Cleansing**\n",
    "- Parsing: string ‚Üí proper types (INT, DATE, DECIMAL)\n",
    "- Trimming: whitespace, special characters\n",
    "- Standardization: dates, phone numbers, emails\n",
    "- Null handling: replacements, defaults\n",
    "\n",
    "**2. Deduplication**\n",
    "- Identyfikacja unique business key\n",
    "- MERGE operation (upsert pattern)\n",
    "- Keeping latest version based on timestamp\n",
    "\n",
    "**3. Validation Rules**\n",
    "```python\n",
    "# Przyk≈Çadowe validations\n",
    "- NOT NULL constraints\n",
    "- Range checks (amount > 0)\n",
    "- Referential integrity (FK exists)\n",
    "- Business rules (discount <= price)\n",
    "```\n",
    "\n",
    "**4. Schema Enforcement**\n",
    "- Strict schema (vs Bronze flexible)\n",
    "- Explicit data types\n",
    "- Column constraints\n",
    "\n",
    "### Bronze ‚Üí Silver Transformation Pattern\n",
    "\n",
    "**Typical Flow:**\n",
    "```python\n",
    "bronze_df = spark.table(\"bronze.orders_raw\")\n",
    "\n",
    "silver_df = (bronze_df\n",
    "    # 1. Parse & Cast\n",
    "    .withColumn(\"order_id\", col(\"order_id\").cast(\"bigint\"))\n",
    "    .withColumn(\"order_date\", to_date(col(\"order_date\")))\n",
    "    .withColumn(\"total_amount\", col(\"total_amount\").cast(\"decimal(10,2)\"))\n",
    "    \n",
    "    # 2. Validate\n",
    "    .filter(col(\"order_id\").isNotNull())\n",
    "    .filter(col(\"total_amount\") > 0)\n",
    "    \n",
    "    # 3. Standardize\n",
    "    .withColumn(\"payment_method\", upper(trim(col(\"payment_method\"))))\n",
    "    \n",
    "    # 4. Add metadata\n",
    "    .withColumn(\"_processing_timestamp\", current_timestamp())\n",
    "    .withColumn(\"_is_valid\", lit(True))\n",
    ")\n",
    "\n",
    "# 5. MERGE to Silver (deduplication)\n",
    "silver_df.write.format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"mergeSchema\", \"false\") \\\n",
    "    .saveAsTable(\"silver.orders_clean\")\n",
    "```\n",
    "\n",
    "### MERGE Operation - Deduplication Pattern\n",
    "\n",
    "**Problem:** Bronze zawiera duplikaty (append-only)\n",
    "\n",
    "**RozwiƒÖzanie:** MERGE w Silver (upsert)\n",
    "\n",
    "```sql\n",
    "MERGE INTO silver.orders_clean AS target\n",
    "USING (\n",
    "    SELECT DISTINCT *\n",
    "    FROM bronze.orders_raw\n",
    "    WHERE _ingestion_timestamp > (\n",
    "        SELECT MAX(_processing_timestamp)\n",
    "        FROM silver.orders_clean\n",
    "    )\n",
    ") AS source\n",
    "ON target.order_id = source.order_id\n",
    "WHEN MATCHED THEN UPDATE SET *\n",
    "WHEN NOT MATCHED THEN INSERT *\n",
    "```\n",
    "\n",
    "### Data Quality Checks\n",
    "\n",
    "**Levels of Quality:**\n",
    "\n",
    "**Level 1: Schema Validation**\n",
    "- Correct data types\n",
    "- Required columns present\n",
    "- No unexpected nulls\n",
    "\n",
    "**Level 2: Business Rules**\n",
    "- Ranges (amount between 0-1000000)\n",
    "- Referential integrity (customer_id exists)\n",
    "- Logical consistency (order_date <= ship_date)\n",
    "\n",
    "**Level 3: Statistical Checks**\n",
    "- Outlier detection\n",
    "- Distribution monitoring\n",
    "- Anomaly alerts\n",
    "\n",
    "**Quarantine Pattern:**\n",
    "```python\n",
    "# Valid records ‚Üí Silver\n",
    "valid_df = df.filter(col(\"_is_valid\") == True)\n",
    "valid_df.write.saveAsTable(\"silver.orders_clean\")\n",
    "\n",
    "# Invalid records ‚Üí Quarantine\n",
    "invalid_df = df.filter(col(\"_is_valid\") == False)\n",
    "invalid_df.write.saveAsTable(\"silver.orders_quarantine\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9464d305-e7d7-4cc8-8553-d31e08fbc43f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przyk≈Çad 2.1: Bronze ‚Üí Silver Transformation (Orders)\n",
    "\n",
    "**Cel:** Transform orders z Bronze do Silver z cleansing i validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3788a6a3-beac-48bc-8bae-5c536d87c206",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Bronze ‚Üí Silver: Orders\n",
    "bronze_orders = spark.table(f\"{BRONZE_SCHEMA}.orders_raw\")\n",
    "\n",
    "# Transform & Validate\n",
    "silver_orders = (bronze_orders\n",
    "    .withColumn(\"order_id\", F.col(\"order_id\").cast(\"bigint\"))\n",
    "    .withColumn(\"customer_id\", F.col(\"customer_id\").cast(\"bigint\"))\n",
    "    .withColumn(\"order_datetime\", F.to_timestamp(F.col(\"order_datetime\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "    .withColumn(\"total_amount\", F.col(\"total_amount\").cast(\"decimal(10,2)\"))\n",
    "    .withColumn(\"payment_method\", F.upper(F.trim(F.col(\"payment_method\"))))\n",
    "    .withColumn(\"_is_valid\", \n",
    "        F.when(\n",
    "            (F.col(\"order_id\").isNotNull()) &\n",
    "            (F.col(\"customer_id\").isNotNull()) &\n",
    "            (F.col(\"order_datetime\").isNotNull()) &\n",
    "            (F.col(\"total_amount\") > 0),\n",
    "            True\n",
    "        ).otherwise(False)\n",
    "    )\n",
    "    .withColumn(\"_processing_timestamp\", F.current_timestamp())\n",
    "    .select(\n",
    "        \"order_id\", \"customer_id\", \"order_datetime\", \n",
    "        \"total_amount\", \"payment_method\",\n",
    "        \"_is_valid\", \"_processing_timestamp\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Split valid/invalid\n",
    "valid_orders = silver_orders.filter(F.col(\"_is_valid\") == True)\n",
    "invalid_orders = silver_orders.filter(F.col(\"_is_valid\") == False)\n",
    "\n",
    "# Write to Silver\n",
    "valid_orders.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{SILVER_SCHEMA}.orders_clean\")\n",
    "\n",
    "display({\n",
    "    \"bronze_records\": bronze_orders.count(),\n",
    "    \"valid_orders\": valid_orders.count(),\n",
    "    \"invalid_orders\": invalid_orders.count(),\n",
    "    \"status\": f\"‚úÖ Created {SILVER_SCHEMA}.orders_clean\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(spark.table(f\"{SILVER_SCHEMA}.orders_clean\").limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uwaga dotyczƒÖca production:**\n",
    "\n",
    "W ≈õrodowisku produkcyjnym u≈ºyliby≈õmy operacji MERGE dla deduplikacji zamiast prostego overwrite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "374501e7-a2e0-471b-944c-76dfe5085199",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sekcja 3: SCD (Slowly Changing Dimensions)\n",
    "\n",
    "**Cel sekcji:** Implementacja SCD Type 1 i Type 2 dla ≈õledzenia zmian w danych.\n",
    "\n",
    "### Co to jest SCD?\n",
    "\n",
    "**Slowly Changing Dimensions (SCD)** to techniki ≈õledzenia zmian w wymiarach (dimension tables) w hurtowniach danych.\n",
    "\n",
    "**Problem:**\n",
    "```\n",
    "Klient zmienia adres:\n",
    "- Jan Kowalski, Warszawa ‚Üí Krak√≥w\n",
    "\n",
    "Pytanie: Czy zachowaƒá historiƒô?\n",
    "```\n",
    "\n",
    "### SCD Types - Overview\n",
    "\n",
    "| Type | Strategy | History | Use Case |\n",
    "|------|----------|---------|----------|\n",
    "| **Type 0** | No changes allowed | N/A | Reference data (countries) |\n",
    "| **Type 1** | Overwrite | ‚ùå No | Current state only |\n",
    "| **Type 2** | Add new row | ‚úÖ Yes | Full history tracking |\n",
    "| **Type 3** | Add new column | ‚ö†Ô∏è Limited | Previous value only |\n",
    "\n",
    "---\n",
    "\n",
    "### SCD Type 1 - Overwrite\n",
    "\n",
    "**Strategia:** Nadpisz starƒÖ warto≈õƒá nowƒÖ (bez historii)\n",
    "\n",
    "**Implementacja:** Simple UPDATE/MERGE\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Before:\n",
    "customer_id | name        | city\n",
    "1           | Jan Kowalski| Warszawa\n",
    "\n",
    "Change: city ‚Üí Krak√≥w\n",
    "\n",
    "After:\n",
    "customer_id | name        | city\n",
    "1           | Jan Kowalski| Krak√≥w     # Overwritten!\n",
    "```\n",
    "\n",
    "**Kod SQL:**\n",
    "```sql\n",
    "MERGE INTO silver.customers_dim AS target\n",
    "USING updates AS source\n",
    "ON target.customer_id = source.customer_id\n",
    "WHEN MATCHED THEN UPDATE SET\n",
    "    target.city = source.city,\n",
    "    target.updated_at = current_timestamp()\n",
    "```\n",
    "\n",
    "**Pros:**\n",
    "- ‚úÖ Simple implementation\n",
    "- ‚úÖ No history bloat\n",
    "- ‚úÖ Always current values\n",
    "\n",
    "**Cons:**\n",
    "- ‚ùå No historical tracking\n",
    "- ‚ùå Can't analyze \"as of date\"\n",
    "- ‚ùå Lose audit trail\n",
    "\n",
    "**Use Cases:**\n",
    "- Correcting data entry errors\n",
    "- Non-critical attributes (e.g., marketing preferences)\n",
    "- Reference data that shouldn't have history\n",
    "\n",
    "---\n",
    "\n",
    "### SCD Type 2 - Historical Tracking\n",
    "\n",
    "**Strategia:** Dodaj nowy rekord dla ka≈ºdej zmiany (pe≈Çna historia)\n",
    "\n",
    "**Implementacja:** MERGE z version tracking\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Before:\n",
    "customer_id | name        | city    | effective_from | effective_to | is_current\n",
    "1           | Jan Kowalski| Warszawa| 2023-01-01     | 9999-12-31   | true\n",
    "\n",
    "Change: city ‚Üí Krak√≥w (2024-06-15)\n",
    "\n",
    "After:\n",
    "customer_id | name        | city    | effective_from | effective_to | is_current\n",
    "1           | Jan Kowalski| Warszawa| 2023-01-01     | 2024-06-14   | false  # Closed\n",
    "1           | Jan Kowalski| Krak√≥w  | 2024-06-15     | 9999-12-31   | true   # New!\n",
    "```\n",
    "\n",
    "**Kolumny SCD Type 2:**\n",
    "- `effective_from` / `valid_from`: Start date\n",
    "- `effective_to` / `valid_to`: End date (9999-12-31 = current)\n",
    "- `is_current` / `is_active`: Boolean flag\n",
    "- `version`: Optional version number\n",
    "- `surrogate_key`: Technical key (not business key)\n",
    "\n",
    "**Kod SQL (simplified):**\n",
    "```sql\n",
    "-- Step 1: Close old records\n",
    "UPDATE silver.customers_dim\n",
    "SET \n",
    "    effective_to = current_date() - 1,\n",
    "    is_current = false\n",
    "WHERE customer_id IN (SELECT customer_id FROM updates)\n",
    "  AND is_current = true;\n",
    "\n",
    "-- Step 2: Insert new records\n",
    "INSERT INTO silver.customers_dim\n",
    "SELECT \n",
    "    customer_id,\n",
    "    name,\n",
    "    city,\n",
    "    current_date() AS effective_from,\n",
    "    DATE '9999-12-31' AS effective_to,\n",
    "    true AS is_current\n",
    "FROM updates;\n",
    "```\n",
    "\n",
    "**Pros:**\n",
    "- ‚úÖ Full history preserved\n",
    "- ‚úÖ \"As of date\" queries possible\n",
    "- ‚úÖ Audit trail\n",
    "- ‚úÖ Temporal analytics\n",
    "\n",
    "**Cons:**\n",
    "- ‚ùå Table grows (more rows)\n",
    "- ‚ùå More complex queries (need to filter is_current)\n",
    "- ‚ùå Surrogate keys needed\n",
    "\n",
    "**Use Cases:**\n",
    "- Customer dimensions (address, preferences)\n",
    "- Product dimensions (price history)\n",
    "- Employee dimensions (salary, department)\n",
    "- Compliance & audit requirements\n",
    "\n",
    "---\n",
    "\n",
    "### SCD Type 3 - Limited History (rzadziej u≈ºywany)\n",
    "\n",
    "**Strategia:** Dodaj kolumnƒô dla previous value\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "customer_id | name        | city    | previous_city\n",
    "1           | Jan Kowalski| Krak√≥w  | Warszawa\n",
    "```\n",
    "\n",
    "**Pros:**\n",
    "- ‚úÖ Simple (one previous value)\n",
    "- ‚úÖ No row explosion\n",
    "\n",
    "**Cons:**\n",
    "- ‚ùå Only 1 previous value\n",
    "- ‚ùå Limited analytics\n",
    "\n",
    "**Use Case:** Rarely used (SCD Type 2 is better)\n",
    "\n",
    "---\n",
    "\n",
    "### SCD Decision Matrix\n",
    "\n",
    "**Kiedy u≈ºywaƒá kt√≥rego typu?**\n",
    "\n",
    "| Requirement | Recommended Type |\n",
    "|-------------|------------------|\n",
    "| No history needed | Type 1 |\n",
    "| Full history required | Type 2 |\n",
    "| Audit/compliance | Type 2 |\n",
    "| Data corrections | Type 1 |\n",
    "| Current state only | Type 1 |\n",
    "| Temporal analytics | Type 2 |\n",
    "| Growing table OK | Type 2 |\n",
    "| Storage constrained | Type 1 |\n",
    "\n",
    "**üí° Best Practice:** \n",
    "- Use **Type 1** for Silver layer (current state)\n",
    "- Use **Type 2** for Gold dimensional tables (history)\n",
    "\n",
    "---\n",
    "\n",
    "### MERGE Pattern for SCD Type 2 (Advanced)\n",
    "\n",
    "**Complete Implementation:**\n",
    "\n",
    "```sql\n",
    "MERGE INTO silver.customers_dim AS target\n",
    "USING (\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        name,\n",
    "        city,\n",
    "        email,\n",
    "        current_timestamp() AS effective_from,\n",
    "        CAST('9999-12-31' AS DATE) AS effective_to,\n",
    "        true AS is_current\n",
    "    FROM staging.customers_updates\n",
    ") AS source\n",
    "ON target.customer_id = source.customer_id \n",
    "   AND target.is_current = true\n",
    "\n",
    "-- Case 1: No change ‚Üí do nothing\n",
    "WHEN MATCHED AND (\n",
    "    target.city = source.city AND\n",
    "    target.email = source.email\n",
    ") THEN UPDATE SET target.updated_at = current_timestamp()\n",
    "\n",
    "-- Case 2: Change detected ‚Üí close old, insert new\n",
    "WHEN MATCHED AND (\n",
    "    target.city != source.city OR\n",
    "    target.email != source.email\n",
    ") THEN UPDATE SET\n",
    "    target.effective_to = current_date() - 1,\n",
    "    target.is_current = false\n",
    "\n",
    "-- Case 3: New customer ‚Üí insert\n",
    "WHEN NOT MATCHED THEN INSERT (\n",
    "    customer_id, name, city, email,\n",
    "    effective_from, effective_to, is_current\n",
    ") VALUES (\n",
    "    source.customer_id, source.name, source.city, source.email,\n",
    "    source.effective_from, source.effective_to, source.is_current\n",
    ");\n",
    "\n",
    "-- Step 2: Insert new versions for changed records\n",
    "INSERT INTO silver.customers_dim\n",
    "SELECT \n",
    "    source.*\n",
    "FROM staging.customers_updates AS source\n",
    "INNER JOIN silver.customers_dim AS target\n",
    "    ON source.customer_id = target.customer_id\n",
    "WHERE target.is_current = false\n",
    "  AND target.effective_to = current_date() - 1;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9749366-4468-48ca-a120-2b9c5d49e2ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przyk≈Çad 3.1: SCD Type 1 - Customers (Overwrite)\n",
    "\n",
    "**Cel:** Implementacja SCD Type 1 - prosty overwrite bez historii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1275366-9948-4eb1-b51f-c05361925ba8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SCD Type 1: Customers\n",
    "bronze_customers = spark.table(f\"{BRONZE_SCHEMA}.customers_raw\")\n",
    "\n",
    "# Transform to Silver (SCD Type 1 - current state only)\n",
    "customers_type1 = (bronze_customers\n",
    "    .withColumn(\"customer_id\", F.col(\"customer_id\").cast(\"bigint\"))\n",
    "    .withColumn(\"name\", F.trim(F.col(\"name\")))\n",
    "    .withColumn(\"email\", F.lower(F.trim(F.col(\"email\"))))\n",
    "    .withColumn(\"city\", F.initcap(F.trim(F.col(\"city\"))))\n",
    "    .withColumn(\"updated_at\", F.current_timestamp())\n",
    "    .select(\"customer_id\", \"name\", \"email\", \"city\", \"updated_at\")\n",
    ")\n",
    "\n",
    "# Create/Replace table (Type 1 = overwrite)\n",
    "customers_type1.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{SILVER_SCHEMA}.customers_type1\")\n",
    "\n",
    "display({\n",
    "    \"status\": f\"‚úÖ Created {SILVER_SCHEMA}.customers_type1\",\n",
    "    \"records\": customers_type1.count(),\n",
    "    \"note\": \"SCD Type 1: Zawsze aktualny stan, bez historii\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utworzona tabela SCD Type 1:**\n",
    "\n",
    "Tabela `customers_type1` zawiera zawsze aktualny stan bez historii. Wy≈õwietlenie przyk≈Çadowych danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(spark.table(f\"{SILVER_SCHEMA}.customers_type1\").limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symulacja UPDATE - zmiana miasta dla customer_id=1\n",
    "\n",
    "**PRZED ZMIANƒÑ:** Wy≈õwietlenie aktualnego stanu customer_id=1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "    SELECT * FROM {SILVER_SCHEMA}.customers_type1 \n",
    "    WHERE customer_id = 1\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, LongType, StringType\n",
    "updates_schema = StructType([\n",
    "    StructField(\"customer_id\", LongType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"email\", StringType(), True),\n",
    "    StructField(\"city\", StringType(), True)\n",
    "])\n",
    "\n",
    "updates_data = [(1, \"Jan Kowalski\", \"jan@example.com\", \"Krak√≥w\")]  # Changed city!\n",
    "updates_df = spark.createDataFrame(updates_data, updates_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updates_df.createOrReplaceTempView(\"customer_updates\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    MERGE INTO {SILVER_SCHEMA}.customers_type1 AS target\n",
    "    USING customer_updates AS source\n",
    "    ON target.customer_id = source.customer_id\n",
    "    WHEN MATCHED THEN UPDATE SET\n",
    "        target.city = source.city,\n",
    "        target.updated_at = current_timestamp()\n",
    "    WHEN NOT MATCHED THEN INSERT *\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PO ZMIANIE (SCD Type 1 - overwrite):** Wy≈õwietlenie zaktualizowanego stanu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "    SELECT * FROM {SILVER_SCHEMA}.customers_type1 \n",
    "    WHERE customer_id = 1\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚ö†Ô∏è  UWAGA:** Historia zmiany zosta≈Ça UTRACONA\n",
    "\n",
    "**üí° Stara warto≈õƒá (Warszawa) zosta≈Ça nadpisana (Krak√≥w)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85dd1603-be26-43f4-a11c-a5b63916563b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przyk≈Çad 3.2: SCD Type 2 - Customers (Historical Tracking)\n",
    "\n",
    "**Cel:** Implementacja SCD Type 2 - pe≈Çne ≈õledzenie historii zmian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c946d8d2-f9a3-4c96-a02b-2a5e62db1c3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SCD Type 2: Customers (Historical Tracking)\n",
    "bronze_customers = spark.table(f\"{BRONZE_SCHEMA}.customers_raw\")\n",
    "\n",
    "customers_type2_initial = (bronze_customers\n",
    "    .withColumn(\"customer_id\", F.col(\"customer_id\").cast(\"bigint\"))\n",
    "    .withColumn(\"name\", F.trim(F.col(\"name\")))\n",
    "    .withColumn(\"email\", F.lower(F.trim(F.col(\"email\"))))\n",
    "    .withColumn(\"city\", F.initcap(F.trim(F.col(\"city\"))))\n",
    "    # SCD Type 2 columns\n",
    "    .withColumn(\"effective_from\", F.current_date())\n",
    "    .withColumn(\"effective_to\", F.lit(\"9999-12-31\").cast(\"date\"))\n",
    "    .withColumn(\"is_current\", F.lit(True))\n",
    "    .withColumn(\"version\", F.lit(1))\n",
    "    .select(\n",
    "        \"customer_id\", \"name\", \"email\", \"city\",\n",
    "        \"effective_from\", \"effective_to\", \"is_current\", \"version\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create initial table\n",
    "customers_type2_initial.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{SILVER_SCHEMA}.customers_type2\")\n",
    "\n",
    "display({\n",
    "    \"status\": f\"‚úÖ Created {SILVER_SCHEMA}.customers_type2\",\n",
    "    \"records\": customers_type2_initial.count(),\n",
    "    \"columns\": \"effective_from, effective_to, is_current, version\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utworzona tabela SCD Type 2:**\n",
    "\n",
    "Tabela `customers_type2` zawiera kolumny: effective_from, effective_to, is_current, version. Wy≈õwietlenie przyk≈Çadowych danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(spark.table(f\"{SILVER_SCHEMA}.customers_type2\").limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symulacja CHANGE - zmiana miasta dla customer_id=1\n",
    "\n",
    "**PRZED ZMIANƒÑ:** Wy≈õwietlenie aktualnego stanu customer_id=1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "    SELECT * FROM {SILVER_SCHEMA}.customers_type2 \n",
    "    WHERE customer_id = 1\n",
    "    ORDER BY effective_from\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updates_data = [(1, \"Jan Kowalski\", \"jan@example.com\", \"Krak√≥w\")]  # Changed city!\n",
    "updates_df = spark.createDataFrame(updates_data, [\"customer_id\", \"name\", \"email\", \"city\"])\n",
    "updates_df.createOrReplaceTempView(\"customer_updates_type2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Close old records** (set effective_to, is_current=false):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "    MERGE INTO {SILVER_SCHEMA}.customers_type2 AS target\n",
    "    USING (\n",
    "        SELECT DISTINCT u.customer_id\n",
    "        FROM customer_updates_type2 u\n",
    "        INNER JOIN {SILVER_SCHEMA}.customers_type2 t\n",
    "            ON u.customer_id = t.customer_id\n",
    "        WHERE t.is_current = true\n",
    "          AND (u.city != t.city OR u.email != t.email)  -- Detect changes\n",
    "    ) AS changed\n",
    "    ON target.customer_id = changed.customer_id \n",
    "       AND target.is_current = true\n",
    "    WHEN MATCHED THEN UPDATE SET\n",
    "        target.effective_to = current_date() - INTERVAL 1 DAY,\n",
    "        target.is_current = false\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Insert new versions** - dodanie nowych rekord√≥w z updated values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "    INSERT INTO {SILVER_SCHEMA}.customers_type2\n",
    "    SELECT \n",
    "        u.customer_id,\n",
    "        u.name,\n",
    "        u.email,\n",
    "        u.city,\n",
    "        current_date() AS effective_from,\n",
    "        CAST('9999-12-31' AS DATE) AS effective_to,\n",
    "        true AS is_current,\n",
    "        COALESCE(MAX(t.version), 0) + 1 AS version\n",
    "    FROM customer_updates_type2 u\n",
    "    LEFT JOIN {SILVER_SCHEMA}.customers_type2 t\n",
    "        ON u.customer_id = t.customer_id\n",
    "    WHERE NOT EXISTS (\n",
    "        SELECT 1 FROM {SILVER_SCHEMA}.customers_type2 existing\n",
    "        WHERE existing.customer_id = u.customer_id\n",
    "          AND existing.is_current = true\n",
    "          AND existing.city = u.city\n",
    "          AND existing.email = u.email\n",
    "    )\n",
    "    GROUP BY u.customer_id, u.name, u.email, u.city\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PO ZMIANIE (SCD Type 2 - historical tracking):**\n",
    "\n",
    "Historia zosta≈Ça zachowana! Wy≈õwietlenie wszystkich wersji customer_id=1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        city,\n",
    "        effective_from,\n",
    "        effective_to,\n",
    "        is_current,\n",
    "        version\n",
    "    FROM {SILVER_SCHEMA}.customers_type2 \n",
    "    WHERE customer_id = 1\n",
    "    ORDER BY effective_from\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚úÖ Historia zachowana!**\n",
    "\n",
    "Mamy teraz 2 rekordy:\n",
    "- **Version 1**: Warszawa (effective_to = dzisiaj-1, is_current=false)  \n",
    "- **Version 2**: Krak√≥w (effective_to = 9999-12-31, is_current=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przyk≈Çad: Query 'as of date'\n",
    "\n",
    "**Gdzie mieszka≈Ç klient 1 miesiƒÖc temu?** SCD Type 2 umo≈ºliwia temporal queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_month_ago = (datetime.now() - timedelta(days=30)).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        name,\n",
    "        city,\n",
    "        effective_from,\n",
    "        effective_to\n",
    "    FROM {SILVER_SCHEMA}.customers_type2\n",
    "    WHERE customer_id = 1\n",
    "      AND '{one_month_ago}' BETWEEN effective_from AND effective_to\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cb23f29-f3a5-4c11-a47e-7a65b3ad44d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sekcja 4: Gold Layer - Business Aggregates & Analytics\n",
    "\n",
    "**Cel sekcji:** Transformacja Silver ‚Üí Gold z agregacjami biznesowymi.\n",
    "\n",
    "### Gold Layer - Kluczowe Cechy\n",
    "\n",
    "**1. Pre-Aggregated Data**\n",
    "- Daily/Monthly/Yearly summaries\n",
    "- Pre-computed KPIs\n",
    "- Reduced data volume (faster queries)\n",
    "\n",
    "**2. Denormalized Tables**\n",
    "- Joins pre-computed (star schema)\n",
    "- Wide tables dla BI tools\n",
    "- No complex joins needed\n",
    "\n",
    "**3. Business Logic**\n",
    "- Revenue calculations\n",
    "- Customer segmentation\n",
    "- Product performance metrics\n",
    "\n",
    "**4. Query Optimization**\n",
    "- Partitioned by report_date\n",
    "- Z-ordered for common filters\n",
    "- Materialized views\n",
    "\n",
    "### Silver ‚Üí Gold Transformation Pattern\n",
    "\n",
    "**Typical Aggregation:**\n",
    "```python\n",
    "# Silver: Detail level (millions of rows)\n",
    "silver_orders = spark.table(\"silver.orders_clean\")\n",
    "\n",
    "# Gold: Aggregated (thousands of rows)\n",
    "gold_daily_sales = (silver_orders\n",
    "    .groupBy(\n",
    "        F.to_date(\"order_date\").alias(\"report_date\"),\n",
    "        \"payment_method\"\n",
    "    )\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"total_orders\"),\n",
    "        F.sum(\"total_amount\").alias(\"total_revenue\"),\n",
    "        F.avg(\"total_amount\").alias(\"avg_order_value\"),\n",
    "        F.countDistinct(\"customer_id\").alias(\"unique_customers\")\n",
    "    )\n",
    ")\n",
    "```\n",
    "\n",
    "### Gold Layer Tables - Examples\n",
    "\n",
    "**1. Daily Sales Summary**\n",
    "```sql\n",
    "gold.daily_sales_summary\n",
    "- report_date, payment_method\n",
    "- total_orders, total_revenue, avg_order_value\n",
    "- PARTITIONED BY (report_date)\n",
    "```\n",
    "\n",
    "**2. Customer 360**\n",
    "```sql\n",
    "gold.customer_360\n",
    "- customer_id, name, email, city\n",
    "- total_lifetime_value, total_orders, first_order_date, last_order_date\n",
    "- customer_segment (VIP, Regular, New)\n",
    "```\n",
    "\n",
    "**3. Product Performance**\n",
    "```sql\n",
    "gold.product_performance\n",
    "- product_id, product_name, category\n",
    "- total_sold, total_revenue, avg_price\n",
    "- PARTITIONED BY (category)\n",
    "```\n",
    "\n",
    "### Star Schema Pattern\n",
    "\n",
    "**Fact Table (Orders):**\n",
    "- order_id, customer_key, product_key, date_key\n",
    "- total_amount, quantity\n",
    "\n",
    "**Dimension Tables:**\n",
    "- dim_customers (SCD Type 2)\n",
    "- dim_products\n",
    "- dim_dates\n",
    "\n",
    "**Benefits:**\n",
    "- Simplified queries\n",
    "- Better performance (pre-joined)\n",
    "- BI tool friendly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca9f9c7f-f53f-4d3b-813b-e6a3524b2974",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przyk≈Çad 4.1: Gold - Daily Sales Summary\n",
    "\n",
    "**Cel:** Agregacja zam√≥wie≈Ñ do daily sales summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ca302cc-5126-4368-a0a9-fd63e8fc27c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Gold: Daily Sales Summary\n",
    "silver_orders = spark.table(f\"{SILVER_SCHEMA}.orders_clean\")\n",
    "\n",
    "# Aggregate to daily summary\n",
    "daily_sales = (silver_orders\n",
    "    .withColumn(\"report_date\", F.to_date(\"order_datetime\"))\n",
    "    .groupBy(\"report_date\", \"payment_method\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"total_orders\"),\n",
    "        F.sum(\"total_amount\").alias(\"total_revenue\"),\n",
    "        F.avg(\"total_amount\").alias(\"avg_order_value\"),\n",
    "        F.countDistinct(\"customer_id\").alias(\"unique_customers\"),\n",
    "        F.min(\"total_amount\").alias(\"min_order\"),\n",
    "        F.max(\"total_amount\").alias(\"max_order\")\n",
    "    )\n",
    "    .withColumn(\"_computation_timestamp\", F.current_timestamp())\n",
    "    .orderBy(\"report_date\", \"payment_method\")\n",
    ")\n",
    "\n",
    "# Write to Gold\n",
    "daily_sales.write.format(\"delta\").mode(\"overwrite\").partitionBy(\"report_date\").saveAsTable(f\"{GOLD_SCHEMA}.daily_sales_summary\")\n",
    "\n",
    "display({\n",
    "    \"status\": f\"‚úÖ Created {GOLD_SCHEMA}.daily_sales_summary\",\n",
    "    \"aggregated_rows\": daily_sales.count(),\n",
    "    \"partitioned_by\": \"report_date\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utworzona tabela Gold:**\n",
    "\n",
    "Tabela `daily_sales_summary` zosta≈Ça utworzona z partycjƒÖ po `report_date`. Wy≈õwietlenie Top 10 dni po revenue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    spark.table(f\"{GOLD_SCHEMA}.daily_sales_summary\")\n",
    "    .orderBy(F.desc(\"total_revenue\"))\n",
    "    .limit(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Reduction Metrics\n",
    "\n",
    "Por√≥wnanie wielko≈õci danych miƒôdzy Silver a Gold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_count = silver_orders.count()\n",
    "gold_count = daily_sales.count()\n",
    "reduction_pct = ((silver_count - gold_count) / silver_count) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Redukcja danych:**\n",
    "\n",
    "Gold tables sƒÖ znacznie mniejsze ‚Üí szybsze queries!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b567a9e-ec08-4042-9973-28c9117a90ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Przyk≈Çad 4.2: Gold - Customer 360 (Denormalized)\n",
    "\n",
    "**Cel:** Stworzenie denormalized customer view z KPIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1aa72ab7-4a44-4fc8-9440-6cad937d403b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Gold: Customer 360\n",
    "customers = spark.table(f\"{SILVER_SCHEMA}.customers_type1\")\n",
    "orders = spark.table(f\"{SILVER_SCHEMA}.orders_clean\")\n",
    "\n",
    "customer_360 = (customers\n",
    "    .join(\n",
    "        orders.groupBy(\"customer_id\").agg(\n",
    "            F.count(\"*\").alias(\"total_orders\"),\n",
    "            F.sum(\"total_amount\").alias(\"lifetime_value\"),\n",
    "            F.avg(\"total_amount\").alias(\"avg_order_value\"),\n",
    "            F.min(\"order_datetime\").alias(\"first_order_date\"),\n",
    "            F.max(\"order_datetime\").alias(\"last_order_date\")\n",
    "        ),\n",
    "        \"customer_id\",\n",
    "        \"left\"\n",
    "    )\n",
    "    .withColumn(\"customer_segment\",\n",
    "        F.when(F.col(\"lifetime_value\") > 1000, \"VIP\")\n",
    "        .when(F.col(\"lifetime_value\") > 500, \"Regular\")\n",
    "        .otherwise(\"New\")\n",
    "    )\n",
    "    .withColumn(\"_computation_timestamp\", F.current_timestamp())\n",
    "    .select(\n",
    "        \"customer_id\", \"name\", \"email\", \"city\",\n",
    "        \"total_orders\", \"lifetime_value\", \"avg_order_value\",\n",
    "        \"first_order_date\", \"last_order_date\", \"customer_segment\",\n",
    "        \"_computation_timestamp\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Write to Gold\n",
    "customer_360.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{GOLD_SCHEMA}.customer_360\")\n",
    "\n",
    "display({\n",
    "    \"status\": f\"‚úÖ Created {GOLD_SCHEMA}.customer_360\",\n",
    "    \"customers\": customer_360.count()\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utworzona tabela Customer 360:**\n",
    "\n",
    "Denormalized view z KPIs klient√≥w. Top 10 klient√≥w po Lifetime Value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    spark.table(f\"{GOLD_SCHEMA}.customer_360\")\n",
    "    .orderBy(F.desc(\"lifetime_value\"))\n",
    "    .limit(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Segmentation\n",
    "\n",
    "Rozk≈Çad segment√≥w klient√≥w:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        customer_segment,\n",
    "        COUNT(*) as customer_count,\n",
    "        SUM(lifetime_value) as total_value,\n",
    "        AVG(lifetime_value) as avg_value\n",
    "    FROM {GOLD_SCHEMA}.customer_360\n",
    "    GROUP BY customer_segment\n",
    "    ORDER BY total_value DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Customer 360:** Denormalized view dla BI dashboards z precomputed KPIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "039dde8f-ea44-43e0-97bd-f628e4969004",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sekcja 5: Podsumowanie & Best Practices\n",
    "\n",
    "### Co zosta≈Ço osiƒÖgniƒôte?\n",
    "\n",
    "‚úÖ **1. Medallion Architecture Implementation**\n",
    "- ü•â Bronze: Raw data landing (append-only, immutable)\n",
    "- ü•à Silver: Cleansed & validated data (deduplicated)\n",
    "- ü•á Gold: Business aggregates & KPIs (pre-computed)\n",
    "\n",
    "‚úÖ **2. SCD (Slowly Changing Dimensions)**\n",
    "- **Type 1**: Overwrite (no history) - dla current state\n",
    "- **Type 2**: Historical tracking (full history) - dla temporal analytics\n",
    "\n",
    "‚úÖ **3. Data Quality Patterns**\n",
    "- Validation rules (NOT NULL, ranges, types)\n",
    "- Quarantine pattern (valid/invalid split)\n",
    "- Metadata tracking (_processing_timestamp, _is_valid)\n",
    "\n",
    "‚úÖ **4. Business Logic Implementations**\n",
    "- Daily sales aggregations\n",
    "- Customer 360 view (denormalized)\n",
    "- Customer segmentation (VIP/Regular/New)\n",
    "\n",
    "### Kluczowe Wnioski\n",
    "\n",
    "üí° **1. Separation of Concerns**\n",
    "```\n",
    "Bronze = Ingestion (raw data)\n",
    "Silver = Data Quality (cleansing, dedup)\n",
    "Gold = Business Logic (aggregates, KPIs)\n",
    "```\n",
    "\n",
    "üí° **2. ELT > ETL**\n",
    "```\n",
    "Traditional ETL: Transform outside DB\n",
    "Medallion ELT: Load first, transform in-place\n",
    "- Preserve raw data (Bronze)\n",
    "- Re-process capability\n",
    "- Scalable (Spark distributed)\n",
    "```\n",
    "\n",
    "üí° **3. SCD Strategy**\n",
    "```\n",
    "Silver: Type 1 (current state)\n",
    "Gold: Type 2 (history for dimensions)\n",
    "Fact tables: Immutable (no SCD needed)\n",
    "```\n",
    "\n",
    "üí° **4. Incremental Processing**\n",
    "```\n",
    "Bronze ‚Üí Silver: MERGE (deduplication)\n",
    "Silver ‚Üí Gold: Overwrite or MERGE (depends on use case)\n",
    "Always use checkpoints for streaming\n",
    "```\n",
    "\n",
    "üí° **5. Partitioning Strategy**\n",
    "```\n",
    "Bronze: _ingestion_date\n",
    "Silver: Business date (order_date, transaction_date)\n",
    "Gold: Report date (report_date)\n",
    "```\n",
    "\n",
    "### Medallion Architecture - Decision Matrix\n",
    "\n",
    "| Layer | Purpose | Schema | Updates | Retention | Use Case |\n",
    "|-------|---------|--------|---------|-----------|----------|\n",
    "| **Bronze** | Raw landing | Flexible | Append-only | 3-7 years | Recovery, audit |\n",
    "| **Silver** | Validated | Strict | MERGE (dedup) | 1-2 years | Analytics prep |\n",
    "| **Gold** | Business | Optimized | Overwrite/MERGE | 6-12 months | BI, reports |\n",
    "\n",
    "### Production Checklist\n",
    "\n",
    "**Bronze Layer:**\n",
    "- [ ] Audit metadata (_ingestion_timestamp, _source_file)\n",
    "- [ ] Schema evolution enabled (rescued_data)\n",
    "- [ ] Long retention (compliance)\n",
    "- [ ] Partition by _ingestion_date\n",
    "\n",
    "**Silver Layer:**\n",
    "- [ ] Data quality rules implemented\n",
    "- [ ] Deduplication logic (MERGE)\n",
    "- [ ] SCD Type 1 for dimension tables\n",
    "- [ ] Quarantine pattern for bad data\n",
    "- [ ] Partition by business date\n",
    "\n",
    "**Gold Layer:**\n",
    "- [ ] Pre-aggregated summaries\n",
    "- [ ] Denormalized tables (star schema)\n",
    "- [ ] SCD Type 2 for dimensions (optional)\n",
    "- [ ] Partition by report_date\n",
    "- [ ] Z-ordering for common filters\n",
    "\n",
    "### Nastƒôpne Kroki\n",
    "\n",
    "**üìö Kolejne Notebooki:**\n",
    "- **05_optimization_best_practices.ipynb** - Performance tuning\n",
    "- **Warsztaty praktyczne** - End-to-end pipeline implementation\n",
    "\n",
    "**üõ†Ô∏è Zadanie Domowe:**\n",
    "1. Zaimplementuj complete Bronze‚ÜíSilver‚ÜíGold pipeline\n",
    "2. Dodaj SCD Type 2 dla products dimension\n",
    "3. Stw√≥rz Gold table: monthly_product_performance\n",
    "4. Zaimplementuj data quality monitoring\n",
    "\n",
    "### Useful SQL Queries\n",
    "\n",
    "**Query current customers only (SCD Type 2):**\n",
    "```sql\n",
    "SELECT * FROM silver.customers_type2\n",
    "WHERE is_current = true\n",
    "```\n",
    "\n",
    "**Query historical data (as of date):**\n",
    "```sql\n",
    "SELECT * FROM silver.customers_type2\n",
    "WHERE '2024-01-15' BETWEEN effective_from AND effective_to\n",
    "```\n",
    "\n",
    "**Gold aggregation refresh:**\n",
    "```sql\n",
    "INSERT OVERWRITE gold.daily_sales_summary\n",
    "SELECT \n",
    "    CAST(order_date AS DATE) as report_date,\n",
    "    payment_method,\n",
    "    COUNT(*) as total_orders,\n",
    "    SUM(total_amount) as total_revenue,\n",
    "    AVG(total_amount) as avg_order_value\n",
    "FROM silver.orders_clean\n",
    "GROUP BY 1, 2\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Gratulacje!** üéâ \n",
    "Uko≈Ñczy≈Çe≈õ implementacjƒô Medallion Architecture z SCD Type 1/2!\n",
    "Jeste≈õ gotowy do budowania production-grade data lakehouse pipelines!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e58748e-1fd8-4de1-86ff-8e3e13e32eb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sekcja 6: Czyszczenie Zasob√≥w\n",
    "\n",
    "**Uwaga:** Ta sekcja jest opcjonalna. Uruchom tylko je≈õli chcesz usunƒÖƒá wszystkie dane utworzone w tym notebooku.\n",
    "\n",
    "### Opcja 1: Sprawd≈∫ utworzone zasoby (zalecane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92ef54ea-b672-4608-a9bc-847251e33b02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sprawd≈∫ utworzone zasoby\n",
    "medallion_tables = {\n",
    "    \"Silver\": [\n",
    "        f\"{SILVER_SCHEMA}.orders_clean\",\n",
    "        f\"{SILVER_SCHEMA}.customers_type1\",\n",
    "        f\"{SILVER_SCHEMA}.customers_type2\"\n",
    "    ],\n",
    "    \"Gold\": [\n",
    "        f\"{GOLD_SCHEMA}.daily_sales_summary\",\n",
    "        f\"{GOLD_SCHEMA}.customer_360\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "results = []\n",
    "for layer, tables in medallion_tables.items():\n",
    "    for table in tables:\n",
    "        full_table = f\"{CATALOG}.{table}\"\n",
    "        if spark.catalog.tableExists(full_table):\n",
    "            count = spark.table(full_table).count()\n",
    "            detail = spark.sql(f\"DESCRIBE DETAIL {full_table}\").collect()[0]\n",
    "            size_mb = detail['sizeInBytes'] / (1024 * 1024)\n",
    "            results.append({\"layer\": layer, \"table\": table, \"records\": count, \"size_mb\": round(size_mb, 2)})\n",
    "\n",
    "display(spark.createDataFrame(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dane sƒÖ zachowane dla dalszego u≈ºytku**\n",
    "\n",
    "Aby usunƒÖƒá wszystkie tabele, uruchom nastƒôpnƒÖ kom√≥rkƒô w sekcji opcjonalnej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5dea6788-3610-410f-a222-6962f3f01fc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Opcja 2: Usu≈Ñ wszystkie zasoby (tylko je≈õli naprawdƒô chcesz)\n",
    "\n",
    "**UWAGA:** To usunie wszystkie tabele Silver i Gold utworzone w tym notebooku!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6409dd7e-5b44-4ca7-9aba-e089f8b849d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Opcja 2: Usu≈Ñ wszystkie zasoby (TYLKO JE≈öLI JESTE≈ö PEWIEN!)\n",
    "\n",
    "# ‚ö†Ô∏è  UWAGA: Odkomentuj poni≈ºszy kod tylko je≈õli chcesz usunƒÖƒá wszystko!\n",
    "\n",
    "\"\"\"\n",
    "print(\"=== üóëÔ∏è  USUWANIE ZASOB√ìW MEDALLION ===\\n\")\n",
    "\n",
    "# Lista tabel do usuniƒôcia\n",
    "tables_to_drop = [\n",
    "    f\"{SILVER_SCHEMA}.orders_clean\",\n",
    "    f\"{SILVER_SCHEMA}.customers_type1\",\n",
    "    f\"{SILVER_SCHEMA}.customers_type2\",\n",
    "    f\"{GOLD_SCHEMA}.daily_sales_summary\",\n",
    "    f\"{GOLD_SCHEMA}.customer_360\"\n",
    "]\n",
    "\n",
    "print(\"Usuwanie tabel...\\n\")\n",
    "for table in tables_to_drop:\n",
    "    full_table = f\"{CATALOG}.{table}\"\n",
    "    try:\n",
    "        spark.sql(f\"DROP TABLE IF EXISTS {full_table}\")\n",
    "        print(f\"  ‚úì Usuniƒôto: {table}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è  B≈ÇƒÖd przy {table}: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Czyszczenie zako≈Ñczone!\")\n",
    "print(\"üí° Wszystkie tabele Medallion zosta≈Çy usuniƒôte\")\n",
    "print(\"üí° Mo≈ºesz uruchomiƒá notebook od nowa\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚ö†Ô∏è  KOD CZYSZCZENIA JEST ZAKOMENTOWANY\")\n",
    "print(\"‚ö†Ô∏è  Odkomentuj powy≈ºszy kod tylko je≈õli chcesz usunƒÖƒá wszystkie zasoby\")\n",
    "print(\"\\nüí° Zalecenie: Zostaw dane dla kolejnych notebook√≥w i warsztat√≥w!\")\n",
    "print(\"üí° Nastƒôpny notebook: 05_optimization_best_practices.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "04_medallion_architecture",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
