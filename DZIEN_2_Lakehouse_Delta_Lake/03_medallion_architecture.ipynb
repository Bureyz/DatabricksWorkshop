{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb6d571c-ebfe-44a0-908e-8079cd0e7cf3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Medallion Architecture\n",
    "\n",
    "**Cel szkoleniowy:** Opanowanie implementacji architektury medalionowej (Bronze â†’ Silver â†’ Gold) w Databricks.\n",
    "\n",
    "**Zakres tematyczny:**\n",
    "- Bronze Layer: Ingestion surowych danych (CSV, JSON, Parquet)\n",
    "- Silver Layer: Data Quality, Deduplication & Validation, Kalkulacje biznesowe\n",
    "- SCD (Slowly Changing Dimensions): Implementacja SCD Type 1 i Type 2\n",
    "- Gold Layer: Star Schema (Fact & Dimension Tables)\n",
    "- Best Practices: Partycjonowanie, Z-Ordering, Data Retention\n",
    "\n",
    "**Model danych zgodny z Lakeflow Pipeline:**\n",
    "- `bronze_customers`, `bronze_orders`, `bronze_products`\n",
    "- `silver_customers` (SCD2), `silver_orders`, `silver_products`\n",
    "- `fact_sales`, `dim_customer`, `dim_product`, `dim_date`, `dim_store`, `dim_payment_method`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d54ecb3-6758-4504-b2d9-e38d7067126e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Kontekst i wymagania\n",
    "\n",
    "- **DzieÅ„ szkolenia**: DzieÅ„ 2 - Delta Lake & Lakehouse\n",
    "- **Typ notebooka**: Demo\n",
    "- **Wymagania techniczne**:\n",
    "  - Databricks Runtime 16.4 LTS lub nowszy (zalecane: 17.3 LTS)\n",
    "  - Unity Catalog wÅ‚Ä…czony\n",
    "  - Uprawnienia: CREATE TABLE, CREATE SCHEMA, SELECT, MODIFY\n",
    "  - Klaster: Standard lub **Serverless Compute** (zalecane)\n",
    "- **ZaleÅ¼noÅ›ci**: \n",
    "  - Wykonany notebook `01_delta_lake_operations.ipynb`\n",
    "  - Wykonany notebook `02_Lakeflow_Connection.ipynb` (dla danych Bronze)\n",
    "- **Czas realizacji**: ~90 minut\n",
    "\n",
    "> **Uwaga (2025):** Serverless Compute jest teraz domyÅ›lnym trybem dla nowych workloadÃ³w."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4698a3de-470f-41c4-a11a-5dbec2b244a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## WstÄ™p teoretyczny - Medallion Architecture\n",
    "\n",
    "**Cel sekcji:** Zrozumienie architektury medalionowej jako fundamentalnego design pattern dla data lakehouse.\n",
    "\n",
    "---\n",
    "\n",
    "### Czym jest Medallion Architecture?\n",
    "\n",
    "**Medallion Architecture** to wielowarstwowy wzorzec organizacji danych w data lakehouse, ktÃ³ry dzieli dane na trzy warstwy o rosnÄ…cej jakoÅ›ci i wartoÅ›ci biznesowej:\n",
    "\n",
    "```\n",
    "DATA SOURCES\n",
    "    â†“\n",
    "ğŸ¥‰ BRONZE (Raw)\n",
    "    â†“ cleansing\n",
    "ğŸ¥ˆ SILVER (Validated)\n",
    "    â†“ aggregation\n",
    "ğŸ¥‡ GOLD (Business)\n",
    "    â†“\n",
    "CONSUMPTION\n",
    "```\n",
    "\n",
    "### Warstwy - SzczegÃ³Å‚owy Opis\n",
    "\n",
    "#### ğŸ¥‰ Bronze Layer - Raw / Landing Zone\n",
    "\n",
    "**Charakterystyka:**\n",
    "- Dane \"as-is\" bez transformacji wartoÅ›ci\n",
    "- Append-only, immutable\n",
    "- Audit metadata: `source_file_path`, `ingestion_ts`, `load_ts`\n",
    "- Multi-format: JSON, CSV, Parquet, Avro\n",
    "- Schema-on-read approach\n",
    "\n",
    "**Retention:** 3-7 lat (dÅ‚ugoterminowa historia)\n",
    "\n",
    "**Use Cases:**\n",
    "- Data recovery (reprocess pipeline)\n",
    "- Audit trail & compliance\n",
    "- Historical analysis\n",
    "- Data science exploration\n",
    "\n",
    "**PrzykÅ‚ad Bronze Table (nasz model):**\n",
    "```sql\n",
    "CREATE TABLE bronze.orders_raw (\n",
    "    order_id STRING,\n",
    "    customer_id STRING,\n",
    "    product_id STRING,\n",
    "    store_id STRING,\n",
    "    order_datetime STRING,\n",
    "    quantity INT,\n",
    "    unit_price DOUBLE,\n",
    "    discount_percent INT,\n",
    "    total_amount DOUBLE,\n",
    "    payment_method STRING,\n",
    "    -- Metadata columns\n",
    "    source_system STRING,           -- 'batch' lub 'stream'\n",
    "    source_file_path STRING,        -- ÅšcieÅ¼ka ÅºrÃ³dÅ‚owa\n",
    "    ingestion_ts TIMESTAMP,         -- Timestamp przetwarzania\n",
    "    load_ts TIMESTAMP               -- Timestamp zaÅ‚adowania\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ¥ˆ Silver Layer - Cleansed / Validated\n",
    "\n",
    "**Charakterystyka:**\n",
    "- **Deduplikacja** po kluczu biznesowym\n",
    "- **Walidacja**: NOT NULL, data types, ranges (CONSTRAINTS)\n",
    "- **Kalkulacje biznesowe**: gross_amount, discount_amount, net_amount\n",
    "- **Flagi jakoÅ›ciowe**: is_return, is_future_dated, is_unknown_*\n",
    "- **SCD Type 2** dla wymiarÃ³w (customers)\n",
    "\n",
    "**Retention:** 1-2 lata (medium-term history)\n",
    "\n",
    "**Use Cases:**\n",
    "- Foundation for analytics\n",
    "- Joins & enrichment\n",
    "- ML feature engineering\n",
    "- Data quality monitoring\n",
    "\n",
    "**PrzykÅ‚ad Silver Table (nasz model):**\n",
    "```sql\n",
    "CREATE TABLE silver.orders_clean (\n",
    "    -- Klucze\n",
    "    order_id STRING NOT NULL,\n",
    "    customer_id STRING NOT NULL,\n",
    "    product_id STRING NOT NULL,\n",
    "    store_id STRING,\n",
    "    \n",
    "    -- Daty\n",
    "    order_ts TIMESTAMP,\n",
    "    order_date DATE,\n",
    "    order_date_key INT,              -- Format: yyyyMMdd (dla joins)\n",
    "    \n",
    "    -- Miary oryginalne\n",
    "    quantity INT,\n",
    "    unit_price DOUBLE,\n",
    "    discount_percent INT,\n",
    "    \n",
    "    -- Miary kalkulowane\n",
    "    gross_amount DOUBLE,             -- quantity * unit_price\n",
    "    discount_amount DOUBLE,          -- gross_amount * discount_percent / 100\n",
    "    net_amount DOUBLE,               -- gross_amount - discount_amount\n",
    "    \n",
    "    -- Flagi jakoÅ›ciowe\n",
    "    payment_method_code STRING,\n",
    "    source_system STRING,\n",
    "    is_return INT,                   -- 1 jeÅ›li quantity < 0\n",
    "    is_future_dated INT,             -- 1 jeÅ›li order_date > today\n",
    "    is_unknown_customer INT,\n",
    "    is_unknown_product INT\n",
    ")\n",
    "```\n",
    "\n",
    "**Constraints (Lakeflow):**\n",
    "```sql\n",
    "CONSTRAINT valid_order_id EXPECT (order_id IS NOT NULL) ON VIOLATION DROP ROW\n",
    "CONSTRAINT valid_quantity EXPECT (quantity IS NOT NULL AND quantity <> 0) ON VIOLATION DROP ROW\n",
    "CONSTRAINT valid_unit_price EXPECT (unit_price >= 0) ON VIOLATION DROP ROW\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ¥‡ Gold Layer - Star Schema\n",
    "\n",
    "**Charakterystyka:**\n",
    "- **Fact Table**: `fact_sales` - gÅ‚Ã³wna tabela transakcji\n",
    "- **Dimension Tables**: `dim_customer`, `dim_product`, `dim_date`, `dim_store`, `dim_payment_method`\n",
    "- **Pre-computed joins** (denormalized dla BI)\n",
    "- **Query-optimized** (partitioned, indexed)\n",
    "\n",
    "**Retention:** 6-12 miesiÄ™cy (refreshable from Silver)\n",
    "\n",
    "**Use Cases:**\n",
    "- BI dashboards (Power BI, Tableau)\n",
    "- Executive reports\n",
    "- ML model training\n",
    "- Self-service analytics\n",
    "\n",
    "**PrzykÅ‚ad Gold Tables (nasz model - Star Schema):**\n",
    "\n",
    "```sql\n",
    "-- FACT TABLE\n",
    "CREATE TABLE gold.fact_sales (\n",
    "    order_id STRING,\n",
    "    customer_id STRING,\n",
    "    product_id STRING,\n",
    "    store_id STRING,\n",
    "    payment_method_code STRING,\n",
    "    order_date_key INT,              -- FK do dim_date\n",
    "    order_ts TIMESTAMP,\n",
    "    \n",
    "    -- Miary\n",
    "    quantity INT,\n",
    "    unit_price DOUBLE,\n",
    "    discount_percent INT,\n",
    "    gross_amount DOUBLE,\n",
    "    discount_amount DOUBLE,\n",
    "    net_amount DOUBLE,\n",
    "    \n",
    "    -- Flagi\n",
    "    is_return INT,\n",
    "    is_future_dated INT,\n",
    "    source_system STRING\n",
    ")\n",
    "\n",
    "-- DIMENSION TABLES\n",
    "CREATE TABLE gold.dim_customer (\n",
    "    customer_id STRING,\n",
    "    first_name STRING,\n",
    "    last_name STRING,\n",
    "    email STRING,\n",
    "    city STRING,\n",
    "    country STRING,\n",
    "    customer_segment STRING\n",
    ")\n",
    "\n",
    "CREATE TABLE gold.dim_date (\n",
    "    date_key INT,                    -- PK: yyyyMMdd\n",
    "    date DATE,\n",
    "    year INT,\n",
    "    quarter INT,\n",
    "    month INT,\n",
    "    day INT,\n",
    "    day_of_week STRING,\n",
    "    is_weekend INT\n",
    ")\n",
    "\n",
    "CREATE TABLE gold.dim_payment_method (\n",
    "    payment_method_code STRING,\n",
    "    payment_method_group STRING      -- Card, Cash, Digital wallet\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Kluczowe Zasady Medallion Architecture\n",
    "\n",
    "**1. Separation of Concerns**\n",
    "- Bronze: Ingestion (raw data)\n",
    "- Silver: Data Quality (cleansing, validation, kalkulacje)\n",
    "- Gold: Business Logic (Star Schema, agregacje)\n",
    "\n",
    "**2. Incremental Processing**\n",
    "- Process tylko nowe/zmienione dane\n",
    "- Delta Lake MERGE operations\n",
    "- Checkpoint management dla streaming\n",
    "\n",
    "**3. Idempotency**\n",
    "- MoÅ¼na uruchomiÄ‡ wielokrotnie bez duplikacji\n",
    "- Deterministic transformations\n",
    "- Unique keys & deduplication\n",
    "\n",
    "**4. Schema Evolution**\n",
    "- Bronze: Flexible (rescued data)\n",
    "- Silver: Controlled (addNewColumns)\n",
    "- Gold: Strict (versioned)\n",
    "\n",
    "**5. Data Quality Gates**\n",
    "- CONSTRAINTS w Silver (DROP ROW on violation)\n",
    "- Flagi jakoÅ›ciowe (is_return, is_future_dated)\n",
    "- UNKNOWN handling (dim_product z is_unknown=1)\n",
    "\n",
    "---\n",
    "\n",
    "### ETL vs ELT w Medallion\n",
    "\n",
    "**Traditional ETL:**\n",
    "```\n",
    "Extract â†’ Transform â†’ Load\n",
    "         (outside DB)\n",
    "```\n",
    "\n",
    "**Medallion ELT:**\n",
    "```\n",
    "Extract â†’ Load (Bronze) â†’ Transform (Silver) â†’ Load (Gold)\n",
    "                 â†“                    â†“              â†“\n",
    "             raw data          cleansed data    star schema\n",
    "```\n",
    "\n",
    "**Dlaczego ELT?**\n",
    "- Zachowanie raw data (compliance)\n",
    "- Flexibility (re-transform later)\n",
    "- Scalability (Spark distributed processing)\n",
    "- Cost-effective (storage cheaper than compute)\n",
    "\n",
    "---\n",
    "\n",
    "### Medallion vs Traditional Data Warehouse\n",
    "\n",
    "| Feature | Traditional DWH | Medallion Lakehouse |\n",
    "|---------|-----------------|---------------------|\n",
    "| **Storage** | Proprietary (expensive) | Cloud object storage (cheap) |\n",
    "| **Schema** | Schema-on-write | Schema-on-read (Bronze) |\n",
    "| **Data Types** | Structured only | Structured + semi-structured |\n",
    "| **Flexibility** | Rigid | Flexible (schema evolution) |\n",
    "| **Raw Data** | Discarded | Preserved (Bronze) |\n",
    "| **Processing** | ETL (batch) | ELT (batch + streaming) |\n",
    "| **Cost** | High (compute + storage) | Lower (decouple compute/storage) |\n",
    "| **Use Cases** | BI & reporting | BI + ML + data science |\n",
    "\n",
    "---\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "**1. Naming Conventions (nasz model):**\n",
    "```\n",
    "bronze.{entity}_raw           -- bronze.orders_raw\n",
    "silver.{entity}_clean         -- silver.orders_clean\n",
    "gold.fact_{entity}            -- gold.fact_sales\n",
    "gold.dim_{dimension}          -- gold.dim_customer\n",
    "```\n",
    "\n",
    "**2. Partitioning:**\n",
    "- Bronze: Ingestion date (`ingestion_ts`)\n",
    "- Silver: Business date (`order_date`)\n",
    "- Gold: Report date (`order_date_key`)\n",
    "\n",
    "**3. Metadata Columns:**\n",
    "```python\n",
    "# Bronze (nasz model)\n",
    "source_file_path, ingestion_ts, load_ts, source_system\n",
    "\n",
    "# Silver (nasz model)\n",
    "order_date_key, is_return, is_future_dated, is_unknown_*\n",
    "\n",
    "# Gold (nasz model)\n",
    "order_date_key (surrogate key for joins)\n",
    "```\n",
    "\n",
    "**4. Refresh Cadence:**\n",
    "- Bronze: Real-time (Lakeflow STREAMING TABLE)\n",
    "- Silver: Real-time (Lakeflow STREAMING TABLE)\n",
    "- Gold: Real-time (Lakeflow MATERIALIZED VIEW)\n",
    "\n",
    "---\n",
    "\n",
    "### Pipeline Architecture Diagram (nasz model)\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                      DATA SOURCES                             â”‚\n",
    "â”‚  â€¢ customers.csv  â€¢ orders_batch.json  â€¢ products.parquet    â”‚\n",
    "â”‚  â€¢ orders_stream_*.json (streaming)                          â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                         â”‚ Lakeflow: read_files() / STREAM\n",
    "                         â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                   ğŸ¥‰ BRONZE LAYER                             â”‚\n",
    "â”‚                                                               â”‚\n",
    "â”‚  bronze.customers_raw      bronze.orders_raw                 â”‚\n",
    "â”‚  bronze.products_raw                                         â”‚\n",
    "â”‚                                                               â”‚\n",
    "â”‚  Features:                                                    â”‚\n",
    "â”‚  â€¢ Raw data (as-is)                                          â”‚\n",
    "â”‚  â€¢ Metadata: source_file_path, ingestion_ts, load_ts         â”‚\n",
    "â”‚  â€¢ source_system: 'batch' / 'stream'                         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                         â”‚ MERGE / CONSTRAINTS / Calculations\n",
    "                         â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                   ğŸ¥ˆ SILVER LAYER                             â”‚\n",
    "â”‚                                                               â”‚\n",
    "â”‚  silver.customers_type2    (SCD Type 2: __START_AT, __END_AT)â”‚\n",
    "â”‚  silver.orders_clean       (gross/discount/net_amount)       â”‚\n",
    "â”‚  silver.products                                             â”‚\n",
    "â”‚                                                               â”‚\n",
    "â”‚  Features:                                                    â”‚\n",
    "â”‚  â€¢ Calculated: gross_amount, discount_amount, net_amount     â”‚\n",
    "â”‚  â€¢ Flags: is_return, is_future_dated, is_unknown_*           â”‚\n",
    "â”‚  â€¢ CONSTRAINTS: valid_order_id, valid_quantity, etc.         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                         â”‚ Star Schema / Dimensional Model\n",
    "                         â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                   ğŸ¥‡ GOLD LAYER (Star Schema)                 â”‚\n",
    "â”‚                                                               â”‚\n",
    "â”‚  FACT: fact_sales                                            â”‚\n",
    "â”‚  DIMS: dim_customer, dim_product, dim_date,                  â”‚\n",
    "â”‚        dim_store, dim_payment_method                         â”‚\n",
    "â”‚                                                               â”‚\n",
    "â”‚  Features:                                                    â”‚\n",
    "â”‚  â€¢ Surrogate keys (order_date_key = yyyyMMdd)                â”‚\n",
    "â”‚  â€¢ Denormalized dimensions                                    â”‚\n",
    "â”‚  â€¢ UNKNOWN handling (is_unknown flag)                        â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                         â”‚\n",
    "                         â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                  CONSUMPTION LAYER                            â”‚\n",
    "â”‚  â€¢ Power BI  â€¢ Tableau  â€¢ SQL Analytics  â€¢ ML Models         â”‚\n",
    "â”‚                                                               â”‚\n",
    "â”‚  Example Query:                                               â”‚\n",
    "â”‚  SELECT f.*, d.year, c.customer_segment, p.product_name      â”‚\n",
    "â”‚  FROM fact_sales f                                           â”‚\n",
    "â”‚  JOIN dim_date d ON f.order_date_key = d.date_key            â”‚\n",
    "â”‚  JOIN dim_customer c ON f.customer_id = c.customer_id        â”‚\n",
    "â”‚  JOIN dim_product p ON f.product_id = p.product_id           â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70768a08-3efd-458d-b186-e11c7a6372f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Izolacja per uÅ¼ytkownik\n",
    "\n",
    "Uruchom skrypt inicjalizacyjny dla per-user izolacji katalogÃ³w i schematÃ³w:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2beb7c6c-feee-4484-8a79-ce93f91916b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../00_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9434034c-106e-4069-b478-88abd48f1594",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Konfiguracja\n",
    "\n",
    "Import bibliotek i ustawienie zmiennych Å›rodowiskowych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "523e2bef-ff77-470c-a1ee-0038087a9919",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# WyÅ›wietl kontekst uÅ¼ytkownika\n",
    "display({\n",
    "    \"Katalog\": CATALOG,\n",
    "    \"Schema Bronze\": BRONZE_SCHEMA,\n",
    "    \"Schema Silver\": SILVER_SCHEMA,\n",
    "    \"Schema Gold\": GOLD_SCHEMA,\n",
    "    \"UÅ¼ytkownik\": raw_user,\n",
    "    \"Dataset base\": DATASET_BASE_PATH\n",
    "})\n",
    "\n",
    "# Ustaw katalog i schemat jako domyÅ›lne\n",
    "spark.sql(f\"USE CATALOG {CATALOG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kontekst uÅ¼ytkownika\n",
    "\n",
    "WyÅ›wietlenie aktualnej konfiguracji Å›rodowiska oraz Å›cieÅ¼ek do danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"USE CATALOG {CATALOG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Konfiguracja katalogu Unity Catalog:**\n",
    "\n",
    "Ustawienie domyÅ›lnego katalogu dla wszystkich operacji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0552d1fb-1052-45c6-bb26-944b565508d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sekcja 1: Bronze Layer - Raw Data Landing\n",
    "\n",
    "**Cel sekcji:** Zrozumienie roli Bronze layer jako landing zone dla raw data.\n",
    "\n",
    "### Bronze Layer - Kluczowe Cechy\n",
    "\n",
    "**1. Raw Data \"As-Is\"**\n",
    "- Dane zapisywane bez transformacji wartoÅ›ci\n",
    "- Zachowanie oryginalnego formatu\n",
    "- Multi-format support (JSON, CSV, Parquet)\n",
    "\n",
    "**2. Append-Only Pattern**\n",
    "- Nigdy nie usuwamy/modyfikujemy danych\n",
    "- Immutable history\n",
    "- Time-travel capability\n",
    "\n",
    "**3. Audit Metadata**\n",
    "```python\n",
    "# Metadane audytowe w Bronze (zgodne z Lakeflow)\n",
    "source_file_path     # ÅšcieÅ¼ka ÅºrÃ³dÅ‚owa pliku\n",
    "ingestion_ts         # Timestamp przetwarzania pliku\n",
    "load_ts              # Timestamp zaÅ‚adowania do Bronze\n",
    "```\n",
    "\n",
    "**4. Schema-on-Read**\n",
    "- Elastyczny schemat (moÅ¼e siÄ™ zmieniaÄ‡)\n",
    "- Rescued data column dla unknown columns\n",
    "- Reprocessing capability\n",
    "\n",
    "### Bronze Tables - Model Danych (zgodny z Lakeflow)\n",
    "\n",
    "**`bronze_customers`** (CSV):\n",
    "- `customer_id`, `first_name`, `last_name`, `email`, `phone`\n",
    "- `city`, `state`, `country`, `registration_date`, `customer_segment`\n",
    "- Metadata: `source_file_path`, `ingestion_ts`, `load_ts`\n",
    "\n",
    "**`bronze_orders`** (JSON):\n",
    "- `order_id`, `customer_id`, `product_id`, `store_id`\n",
    "- `order_datetime`, `quantity`, `unit_price`, `discount_percent`, `total_amount`\n",
    "- `payment_method`, `source_system`\n",
    "- Metadata: `source_file_path`, `ingestion_ts`, `load_ts`\n",
    "\n",
    "**`bronze_products`** (Parquet):\n",
    "- `product_id`, `product_name`, `subcategory_code`, `brand`\n",
    "- `unit_cost`, `list_price`, `weight_kg`, `status`\n",
    "- Metadata: `source_file_path`, `ingestion_ts`, `load_ts`\n",
    "\n",
    "### Dlaczego Bronze jest WaÅ¼ny?\n",
    "\n",
    "**1. Data Recovery**\n",
    "```python\n",
    "# MoÅ¼emy reprocessowaÄ‡ pipeline od Bronze\n",
    "bronze_data = spark.table(\"bronze.orders_raw\")\n",
    "# Re-run transformations â†’ Silver â†’ Gold\n",
    "```\n",
    "\n",
    "**2. Schema Evolution**\n",
    "```python\n",
    "# Nowe kolumny w source nie Å‚amiÄ… pipeline\n",
    "# TrafiajÄ… do _rescued_data\n",
    "```\n",
    "\n",
    "**3. Compliance & Audit**\n",
    "```python\n",
    "# PeÅ‚na historia: kto, co, kiedy zaÅ‚adowaÅ‚\n",
    "# Retention: 3-7 lat (regulacje prawne)\n",
    "```\n",
    "\n",
    "**4. Data Science Exploration**\n",
    "```python\n",
    "# Analitycy mogÄ… eksplorowaÄ‡ raw data\n",
    "# TworzyÄ‡ nowe features z surowych danych\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e23da394-d79a-4736-850e-ab58bc53ec44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### PrzykÅ‚ad 1.1: Inspekcja Bronze Layer\n",
    "\n",
    "**Cel:** SprawdziÄ‡ dane w Bronze layer i zrozumieÄ‡ ich strukturÄ™."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PrzykÅ‚ad 1.1: Ingestion do Bronze Layer (Raw Data)\n",
    "\n",
    "Wczytujemy dane bezpoÅ›rednio z plikÃ³w ÅºrÃ³dÅ‚owych (CSV, JSON, Parquet) do tabel Bronze.\n",
    "DziÄ™ki temu notebook jest niezaleÅ¼ny od poprzednich krokÃ³w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Customers (CSV) - zgodne z modelem Lakeflow\n",
    "customers_path = f\"{DATASET_BASE_PATH}/customers/customers.csv\"\n",
    "\n",
    "customers_df = (spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(customers_path)\n",
    "    # Dodaj metadata columns (jak w Lakeflow)\n",
    "    .withColumn(\"source_file_path\", F.input_file_name())\n",
    "    .withColumn(\"ingestion_ts\", F.current_timestamp())\n",
    "    .withColumn(\"load_ts\", F.current_timestamp())\n",
    ")\n",
    "\n",
    "display(customers_df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load Products (Parquet) - zgodne z modelem Lakeflow\n",
    "products_path = f\"{DATASET_BASE_PATH}/products/products.parquet\"\n",
    "\n",
    "products_df = (spark.read\n",
    "    .format(\"parquet\")\n",
    "    .load(products_path)\n",
    "    # Dodaj metadata columns (jak w Lakeflow)\n",
    "    .withColumn(\"source_file_path\", F.input_file_name())\n",
    "    .withColumn(\"ingestion_ts\", F.current_timestamp())\n",
    "    .withColumn(\"load_ts\", F.current_timestamp())\n",
    ")\n",
    "\n",
    "# Write to Bronze\n",
    "(products_df.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .saveAsTable(f\"{BRONZE_SCHEMA}.products_raw\")\n",
    ")\n",
    "\n",
    "display({\"status\": f\"âœ… Table {BRONZE_SCHEMA}.products_raw created/overwritten\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load Orders (JSON) - zgodne z modelem Lakeflow\n",
    "orders_path = f\"{DATASET_BASE_PATH}/orders/orders_batch.json\"\n",
    "\n",
    "orders_df = (spark.read\n",
    "    .format(\"json\")\n",
    "    .load(orders_path)\n",
    "    # Dodaj metadata columns (jak w Lakeflow)\n",
    "    .withColumn(\"source_system\", F.lit(\"batch\"))\n",
    "    .withColumn(\"source_file_path\", F.input_file_name())\n",
    "    .withColumn(\"ingestion_ts\", F.current_timestamp())\n",
    "    .withColumn(\"load_ts\", F.current_timestamp())\n",
    ")\n",
    "\n",
    "# Write to Bronze\n",
    "(orders_df.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .saveAsTable(f\"{BRONZE_SCHEMA}.orders_raw\")\n",
    ")\n",
    "\n",
    "display({\"status\": f\"âœ… Table {BRONZE_SCHEMA}.orders_raw created/overwritten\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Customers to Bronze\n",
    "(customers_df.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .saveAsTable(f\"{BRONZE_SCHEMA}.customers_raw\")\n",
    ")\n",
    "\n",
    "display({\"status\": f\"âœ… Table {BRONZE_SCHEMA}.customers_raw created/overwritten\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utworzone tabele Bronze:**\n",
    "\n",
    "Konwersja danych z batch do raw tables zostaÅ‚a zakoÅ„czona pomyÅ›lnie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf979d26-91e7-44e4-b426-b573656a2b60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Inspekcja Bronze Layer\n",
    "bronze_tables = [\"customers_raw\", \"orders_raw\", \"products_raw\"]\n",
    "results = []\n",
    "\n",
    "for table in bronze_tables:\n",
    "    full_table = f\"{CATALOG}.{BRONZE_SCHEMA}.{table}\"\n",
    "    \n",
    "    if spark.catalog.tableExists(full_table):\n",
    "        df = spark.table(full_table)\n",
    "        results.append({\n",
    "            \"table\": table,\n",
    "            \"status\": \"âœ…\",\n",
    "            \"records\": df.count(),\n",
    "            \"columns\": len(df.columns)\n",
    "        })\n",
    "\n",
    "display(spark.createDataFrame(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Podsumowanie inspekcji Bronze Layer:**\n",
    "\n",
    "Bronze Layer zawiera RAW data bez transformacji, zachowuje peÅ‚nÄ… historiÄ™ (append-only) i stanowi foundation dla dalszych transformacji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1b7d116-87c4-44f0-9790-54bc9ef7417f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sekcja 2: Silver Layer - Cleansing & Validation\n",
    "\n",
    "**Cel sekcji:** Transformacja danych z Bronze do Silver z zastosowaniem data quality rules.\n",
    "\n",
    "### Silver Layer - Model Danych (zgodny z Lakeflow)\n",
    "\n",
    "**`silver_orders`** - Oczyszczone i policzone miary:\n",
    "- Klucze: `order_id`, `customer_id`, `product_id`, `store_id`\n",
    "- Daty: `order_ts`, `order_date`, `order_date_key` (INT: yyyyMMdd)\n",
    "- Miary oryginalne: `quantity`, `unit_price`, `discount_percent`\n",
    "- **Miary kalkulowane:**\n",
    "  - `gross_amount = quantity * unit_price`\n",
    "  - `discount_amount = quantity * unit_price * discount_percent / 100`\n",
    "  - `net_amount = gross_amount - discount_amount`\n",
    "- `payment_method_code` (standaryzowane)\n",
    "- **Flagi jakoÅ›ciowe:**\n",
    "  - `is_return` (quantity < 0 OR total_amount < 0)\n",
    "  - `is_future_dated` (order_date > current_date)\n",
    "  - `is_unknown_customer`, `is_unknown_product`\n",
    "\n",
    "**`silver_customers`** (SCD Type 2):\n",
    "- Pola: `customer_id`, `first_name`, `last_name`, `email`, `phone`, `city`, `state`, `country`\n",
    "- SCD2 columns: `__START_AT`, `__END_AT` (lub `effective_from`, `effective_to`)\n",
    "\n",
    "**`silver_products`**:\n",
    "- `product_id`, `product_name`, `subcategory_code`, `brand`\n",
    "- `unit_cost`, `list_price`, `weight_kg`, `status`\n",
    "- `is_active`, `is_unknown`\n",
    "\n",
    "### Constraints (jak w Lakeflow)\n",
    "\n",
    "```sql\n",
    "CONSTRAINT valid_order_id EXPECT (order_id IS NOT NULL) ON VIOLATION DROP ROW\n",
    "CONSTRAINT valid_customer EXPECT (customer_id IS NOT NULL) ON VIOLATION DROP ROW\n",
    "CONSTRAINT valid_product EXPECT (product_id IS NOT NULL) ON VIOLATION DROP ROW\n",
    "CONSTRAINT valid_quantity EXPECT (quantity IS NOT NULL AND quantity <> 0) ON VIOLATION DROP ROW\n",
    "CONSTRAINT valid_unit_price EXPECT (unit_price IS NOT NULL AND unit_price >= 0) ON VIOLATION DROP ROW\n",
    "```\n",
    "\n",
    "### MERGE Operation - Deduplication Pattern\n",
    "\n",
    "**Problem:** Bronze zawiera duplikaty (append-only)\n",
    "\n",
    "**RozwiÄ…zanie:** MERGE w Silver (upsert)\n",
    "\n",
    "```sql\n",
    "MERGE INTO silver.orders_clean AS target\n",
    "USING (\n",
    "    SELECT DISTINCT *\n",
    "    FROM bronze.orders_raw\n",
    "    WHERE ingestion_ts > (\n",
    "        SELECT MAX(load_ts) FROM silver.orders_clean\n",
    "    )\n",
    ") AS source\n",
    "ON target.order_id = source.order_id\n",
    "WHEN MATCHED THEN UPDATE SET *\n",
    "WHEN NOT MATCHED THEN INSERT *\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9464d305-e7d7-4cc8-8553-d31e08fbc43f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### PrzykÅ‚ad 2.1: Bronze â†’ Silver Transformation (Orders)\n",
    "\n",
    "**Cel:** Transform orders z Bronze do Silver z cleansing i validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3788a6a3-beac-48bc-8bae-5c536d87c206",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Bronze â†’ Silver: Orders (zgodne z modelem Lakeflow)\n",
    "bronze_orders = spark.table(f\"{BRONZE_SCHEMA}.orders_raw\")\n",
    "\n",
    "# Transform & Validate - kalkulacje jak w Lakeflow silver_orders\n",
    "silver_orders = (bronze_orders\n",
    "    # Klucze\n",
    "    .withColumn(\"order_id\", F.col(\"order_id\"))\n",
    "    .withColumn(\"customer_id\", F.col(\"customer_id\"))\n",
    "    .withColumn(\"product_id\", F.col(\"product_id\"))\n",
    "    .withColumn(\"store_id\", F.col(\"store_id\"))\n",
    "    \n",
    "    # Daty\n",
    "    .withColumn(\"order_ts\", F.to_timestamp(F.col(\"order_datetime\")))\n",
    "    .withColumn(\"order_date\", F.to_date(F.col(\"order_datetime\")))\n",
    "    .withColumn(\"order_date_key\", F.date_format(F.col(\"order_datetime\"), \"yyyyMMdd\").cast(\"int\"))\n",
    "    \n",
    "    # Miary oryginalne\n",
    "    .withColumn(\"quantity\", F.col(\"quantity\").cast(\"int\"))\n",
    "    .withColumn(\"unit_price\", F.col(\"unit_price\").cast(\"double\"))\n",
    "    .withColumn(\"discount_percent\", F.col(\"discount_percent\").cast(\"int\"))\n",
    "    \n",
    "    # Miary kalkulowane (zgodne z Lakeflow)\n",
    "    .withColumn(\"gross_amount\", F.col(\"quantity\") * F.col(\"unit_price\"))\n",
    "    .withColumn(\"discount_amount\", F.col(\"quantity\") * F.col(\"unit_price\") * F.col(\"discount_percent\") / 100.0)\n",
    "    .withColumn(\"net_amount\", \n",
    "        F.col(\"gross_amount\") - F.col(\"discount_amount\")\n",
    "    )\n",
    "    \n",
    "    # Payment method (standaryzowane)\n",
    "    .withColumn(\"payment_method_code\", F.coalesce(F.col(\"payment_method\"), F.lit(\"Unknown\")))\n",
    "    .withColumn(\"source_system\", F.col(\"source_system\"))\n",
    "    \n",
    "    # Flagi jakoÅ›ciowe (zgodne z Lakeflow)\n",
    "    .withColumn(\"is_return\", \n",
    "        F.when((F.col(\"quantity\") < 0) | (F.col(\"total_amount\") < 0), 1).otherwise(0)\n",
    "    )\n",
    "    .withColumn(\"is_future_dated\",\n",
    "        F.when(F.col(\"order_date\") > F.current_date(), 1).otherwise(0)\n",
    "    )\n",
    "    .withColumn(\"is_unknown_customer\",\n",
    "        F.when(F.col(\"customer_id\").isNull() | (F.col(\"customer_id\") == \"CUST999999\"), 1).otherwise(0)\n",
    "    )\n",
    "    .withColumn(\"is_unknown_product\",\n",
    "        F.when(F.col(\"product_id\").isNull() | (F.col(\"product_id\") == \"PROD999999\"), 1).otherwise(0)\n",
    "    )\n",
    "    \n",
    "    # Validation - DROP invalid rows (jak CONSTRAINT w Lakeflow)\n",
    "    .filter(F.col(\"order_id\").isNotNull())\n",
    "    .filter(F.col(\"customer_id\").isNotNull())\n",
    "    .filter(F.col(\"product_id\").isNotNull())\n",
    "    .filter((F.col(\"quantity\").isNotNull()) & (F.col(\"quantity\") != 0))\n",
    "    .filter((F.col(\"unit_price\").isNotNull()) & (F.col(\"unit_price\") >= 0))\n",
    "    \n",
    "    # Select final columns\n",
    "    .select(\n",
    "        \"order_id\", \"customer_id\", \"product_id\", \"store_id\",\n",
    "        \"order_ts\", \"order_date\", \"order_date_key\",\n",
    "        \"quantity\", \"unit_price\", \"discount_percent\",\n",
    "        \"gross_amount\", \"discount_amount\", \"net_amount\",\n",
    "        \"payment_method_code\", \"source_system\",\n",
    "        \"is_return\", \"is_future_dated\", \"is_unknown_customer\", \"is_unknown_product\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Write to Silver\n",
    "silver_orders.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{SILVER_SCHEMA}.orders_clean\")\n",
    "\n",
    "# Stats\n",
    "bronze_count = bronze_orders.count()\n",
    "silver_count = silver_orders.count()\n",
    "dropped_count = bronze_count - silver_count\n",
    "\n",
    "display({\n",
    "    \"bronze_records\": bronze_count,\n",
    "    \"silver_records\": silver_count,\n",
    "    \"dropped_by_constraints\": dropped_count,\n",
    "    \"status\": f\"âœ… Created {SILVER_SCHEMA}.orders_clean\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PodglÄ…d Silver Orders z nowymi kalkulacjami\n",
    "display(\n",
    "    spark.table(f\"{SILVER_SCHEMA}.orders_clean\")\n",
    "    .select(\"order_id\", \"order_date\", \"quantity\", \"unit_price\", \"discount_percent\", \n",
    "            \"gross_amount\", \"discount_amount\", \"net_amount\", \"is_return\", \"is_future_dated\")\n",
    "    .limit(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uwaga dotyczÄ…ca production:**\n",
    "\n",
    "W Å›rodowisku produkcyjnym uÅ¼ylibyÅ›my operacji MERGE dla deduplikacji zamiast prostego overwrite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "374501e7-a2e0-471b-944c-76dfe5085199",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sekcja 3: SCD (Slowly Changing Dimensions)\n",
    "\n",
    "**Cel sekcji:** Implementacja SCD Type 1 i Type 2 dla Å›ledzenia zmian w danych.\n",
    "\n",
    "### Model SCD w Lakeflow\n",
    "\n",
    "W naszym Lakeflow pipeline, `silver_customers` uÅ¼ywa **SCD Type 2** z kolumnami:\n",
    "- `__START_AT` - timestamp poczÄ…tku waÅ¼noÅ›ci rekordu\n",
    "- `__END_AT` - timestamp koÅ„ca waÅ¼noÅ›ci (NULL = aktualny rekord)\n",
    "\n",
    "```sql\n",
    "-- Lakeflow AUTO CDC for SCD2\n",
    "CREATE FLOW silver_customers_scd2_flow\n",
    "AS AUTO CDC INTO silver_customers\n",
    "FROM STREAM bronze_customers\n",
    "KEYS (customer_id)\n",
    "SEQUENCE BY ingestion_ts\n",
    "STORED AS SCD TYPE 2;\n",
    "```\n",
    "\n",
    "### SCD Types - Overview\n",
    "\n",
    "| Type | Strategy | History | Use Case |\n",
    "|------|----------|---------|----------|\n",
    "| **Type 0** | No changes allowed | N/A | Reference data (countries) |\n",
    "| **Type 1** | Overwrite | âŒ No | Current state only |\n",
    "| **Type 2** | Add new row | âœ… Yes | Full history tracking |\n",
    "| **Type 3** | Add new column | âš ï¸ Limited | Previous value only |\n",
    "\n",
    "---\n",
    "\n",
    "### SCD Type 1 - Overwrite\n",
    "\n",
    "**Strategia:** Nadpisz starÄ… wartoÅ›Ä‡ nowÄ… (bez historii)\n",
    "\n",
    "**Implementacja:** Simple UPDATE/MERGE\n",
    "\n",
    "**Pros:**\n",
    "- âœ… Simple implementation\n",
    "- âœ… No history bloat\n",
    "- âœ… Always current values\n",
    "\n",
    "**Cons:**\n",
    "- âŒ No historical tracking\n",
    "- âŒ Can't analyze \"as of date\"\n",
    "- âŒ Lose audit trail\n",
    "\n",
    "**Use Cases:**\n",
    "- Correcting data entry errors\n",
    "- Non-critical attributes (e.g., marketing preferences)\n",
    "\n",
    "---\n",
    "\n",
    "### SCD Type 2 - Historical Tracking (uÅ¼ywane w Lakeflow)\n",
    "\n",
    "**Strategia:** Dodaj nowy rekord dla kaÅ¼dej zmiany (peÅ‚na historia)\n",
    "\n",
    "**Kolumny SCD Type 2 (Lakeflow format):**\n",
    "- `__START_AT`: Timestamp poczÄ…tku waÅ¼noÅ›ci\n",
    "- `__END_AT`: Timestamp koÅ„ca waÅ¼noÅ›ci (NULL = current)\n",
    "\n",
    "**Query aktualne rekordy:**\n",
    "```sql\n",
    "SELECT * FROM silver_customers WHERE __END_AT IS NULL\n",
    "```\n",
    "\n",
    "**Query historyczne (as of date):**\n",
    "```sql\n",
    "SELECT * FROM silver_customers \n",
    "WHERE '2024-01-15' >= __START_AT \n",
    "  AND ('2024-01-15' < __END_AT OR __END_AT IS NULL)\n",
    "```\n",
    "\n",
    "**Use Cases:**\n",
    "- Customer dimensions (address, preferences)\n",
    "- Product dimensions (price history)\n",
    "- Compliance & audit requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9749366-4468-48ca-a120-2b9c5d49e2ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### PrzykÅ‚ad 3.1: SCD Type 1 - Customers (Overwrite)\n",
    "\n",
    "**Cel:** Implementacja SCD Type 1 - prosty overwrite bez historii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1275366-9948-4eb1-b51f-c05361925ba8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SCD Type 1: Customers (Current State Only)\n",
    "bronze_customers = spark.table(f\"{BRONZE_SCHEMA}.customers_raw\")\n",
    "\n",
    "# Transform to Silver (SCD Type 1 - current state only)\n",
    "customers_type1 = (bronze_customers\n",
    "    .withColumn(\"customer_id\", F.col(\"customer_id\"))\n",
    "    .withColumn(\"first_name\", F.trim(F.col(\"first_name\")))\n",
    "    .withColumn(\"last_name\", F.trim(F.col(\"last_name\")))\n",
    "    .withColumn(\"email\", F.lower(F.trim(F.col(\"email\"))))\n",
    "    .withColumn(\"phone\", F.col(\"phone\"))\n",
    "    .withColumn(\"city\", F.initcap(F.trim(F.col(\"city\"))))\n",
    "    .withColumn(\"state\", F.upper(F.trim(F.col(\"state\"))))\n",
    "    .withColumn(\"country\", F.upper(F.trim(F.col(\"country\"))))\n",
    "    .withColumn(\"registration_date\", F.to_date(F.col(\"registration_date\")))\n",
    "    .withColumn(\"customer_segment\", F.col(\"customer_segment\"))\n",
    "    .withColumn(\"updated_at\", F.current_timestamp())\n",
    "    .select(\n",
    "        \"customer_id\", \"first_name\", \"last_name\", \"email\", \"phone\",\n",
    "        \"city\", \"state\", \"country\", \"registration_date\", \"customer_segment\",\n",
    "        \"updated_at\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create/Replace table (Type 1 = overwrite)\n",
    "customers_type1.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{SILVER_SCHEMA}.customers_type1\")\n",
    "\n",
    "display({\n",
    "    \"status\": f\"âœ… Created {SILVER_SCHEMA}.customers_type1\",\n",
    "    \"records\": customers_type1.count(),\n",
    "    \"note\": \"SCD Type 1: Zawsze aktualny stan, bez historii\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utworzona tabela SCD Type 1:**\n",
    "\n",
    "Tabela `customers_type1` zawiera zawsze aktualny stan bez historii. WyÅ›wietlenie przykÅ‚adowych danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(spark.table(f\"{SILVER_SCHEMA}.customers_type1\").limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symulacja UPDATE - zmiana miasta dla customer_id=1\n",
    "\n",
    "**PRZED ZMIANÄ„:** WyÅ›wietlenie aktualnego stanu customer_id=1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    spark.sql(f\"\"\"\n",
    "        SELECT customer_id, first_name, last_name, city, state, country, customer_segment\n",
    "        FROM {SILVER_SCHEMA}.customers_type1 \n",
    "        WHERE customer_id = 'CUST000001'\n",
    "    \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symulacja UPDATE - zmiana miasta dla customer_id\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "updates_schema = StructType([\n",
    "    StructField(\"customer_id\", StringType(), True),\n",
    "    StructField(\"first_name\", StringType(), True),\n",
    "    StructField(\"last_name\", StringType(), True),\n",
    "    StructField(\"email\", StringType(), True),\n",
    "    StructField(\"phone\", StringType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"state\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"registration_date\", StringType(), True),\n",
    "    StructField(\"customer_segment\", StringType(), True)\n",
    "])\n",
    "\n",
    "updates_data = [(\"CUST000001\", \"Jesse\", \"Hoffman\", \"jesse.hoffman@interia.pl\", \"+48 694 026 542\", \n",
    "                 \"KrakÃ³w\", \"MA\", \"POL\", \"2025-10-16\", \"Premium\")]  # Changed city & country!\n",
    "updates_df = spark.createDataFrame(updates_data, updates_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCD Type 1: MERGE (Overwrite)\n",
    "updates_df.createOrReplaceTempView(\"customer_updates\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    MERGE INTO {SILVER_SCHEMA}.customers_type1 AS target\n",
    "    USING customer_updates AS source\n",
    "    ON target.customer_id = source.customer_id\n",
    "    WHEN MATCHED THEN UPDATE SET\n",
    "        target.city = source.city,\n",
    "        target.state = source.state,\n",
    "        target.country = source.country,\n",
    "        target.customer_segment = source.customer_segment,\n",
    "        target.updated_at = current_timestamp()\n",
    "    WHEN NOT MATCHED THEN INSERT (\n",
    "        customer_id, first_name, last_name, email, phone,\n",
    "        city, state, country, registration_date, customer_segment, updated_at\n",
    "    ) VALUES (\n",
    "        source.customer_id, source.first_name, source.last_name, source.email, source.phone,\n",
    "        source.city, source.state, source.country, CAST(source.registration_date AS DATE), \n",
    "        source.customer_segment, current_timestamp()\n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PO ZMIANIE (SCD Type 1 - overwrite):** WyÅ›wietlenie zaktualizowanego stanu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    spark.sql(f\"\"\"\n",
    "        SELECT customer_id, first_name, last_name, city, state, country, customer_segment\n",
    "        FROM {SILVER_SCHEMA}.customers_type1 \n",
    "        WHERE customer_id = 'CUST000001'\n",
    "    \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**âš ï¸  UWAGA:** Historia zmiany zostaÅ‚a UTRACONA\n",
    "\n",
    "**ğŸ’¡ Stara wartoÅ›Ä‡ (Warszawa) zostaÅ‚a nadpisana (KrakÃ³w)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85dd1603-be26-43f4-a11c-a5b63916563b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### PrzykÅ‚ad 3.2: SCD Type 2 - Customers (Historical Tracking)\n",
    "\n",
    "**Cel:** Implementacja SCD Type 2 - peÅ‚ne Å›ledzenie historii zmian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c946d8d2-f9a3-4c96-a02b-2a5e62db1c3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SCD Type 2: Customers (Historical Tracking - format Lakeflow)\n",
    "bronze_customers = spark.table(f\"{BRONZE_SCHEMA}.customers_raw\")\n",
    "\n",
    "# Transform with SCD Type 2 columns (Lakeflow format: __START_AT, __END_AT)\n",
    "customers_type2_initial = (bronze_customers\n",
    "    .withColumn(\"customer_id\", F.col(\"customer_id\"))\n",
    "    .withColumn(\"first_name\", F.trim(F.col(\"first_name\")))\n",
    "    .withColumn(\"last_name\", F.trim(F.col(\"last_name\")))\n",
    "    .withColumn(\"email\", F.lower(F.trim(F.col(\"email\"))))\n",
    "    .withColumn(\"phone\", F.col(\"phone\"))\n",
    "    .withColumn(\"city\", F.initcap(F.trim(F.col(\"city\"))))\n",
    "    .withColumn(\"state\", F.upper(F.trim(F.col(\"state\"))))\n",
    "    .withColumn(\"country\", F.upper(F.trim(F.col(\"country\"))))\n",
    "    .withColumn(\"registration_date\", F.to_date(F.col(\"registration_date\")))\n",
    "    .withColumn(\"customer_segment\", F.col(\"customer_segment\"))\n",
    "    # SCD Type 2 columns (Lakeflow format)\n",
    "    .withColumn(\"__START_AT\", F.current_timestamp())\n",
    "    .withColumn(\"__END_AT\", F.lit(None).cast(\"timestamp\"))  # NULL = current record\n",
    "    .select(\n",
    "        \"customer_id\", \"first_name\", \"last_name\", \"email\", \"phone\",\n",
    "        \"city\", \"state\", \"country\", \"registration_date\", \"customer_segment\",\n",
    "        \"__START_AT\", \"__END_AT\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create initial table\n",
    "customers_type2_initial.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{SILVER_SCHEMA}.customers_type2\")\n",
    "\n",
    "display({\n",
    "    \"status\": f\"âœ… Created {SILVER_SCHEMA}.customers_type2\",\n",
    "    \"records\": customers_type2_initial.count(),\n",
    "    \"columns\": \"__START_AT, __END_AT (Lakeflow format)\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utworzona tabela SCD Type 2:**\n",
    "\n",
    "Tabela `customers_type2` zawiera kolumny: `__START_AT`, `__END_AT` (format Lakeflow). WyÅ›wietlenie przykÅ‚adowych danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(spark.table(f\"{SILVER_SCHEMA}.customers_type2\").limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symulacja CHANGE - zmiana miasta dla customer_id=1\n",
    "\n",
    "**PRZED ZMIANÄ„:** WyÅ›wietlenie aktualnego stanu customer_id=1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    spark.sql(f\"\"\"\n",
    "        SELECT customer_id, first_name, last_name, city, country, __START_AT, __END_AT\n",
    "        FROM {SILVER_SCHEMA}.customers_type2 \n",
    "        WHERE customer_id = 'CUST000001'\n",
    "        ORDER BY __START_AT\n",
    "    \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symulacja UPDATE dla SCD Type 2 - ten sam update co dla Type 1\n",
    "# UÅ¼ywamy tego samego customer_updates view (juÅ¼ utworzony wczeÅ›niej)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Close old records** (set effective_to, is_current=false):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCD Type 2: Step 1 - Close old records (set __END_AT)\n",
    "spark.sql(f\"\"\"\n",
    "    MERGE INTO {SILVER_SCHEMA}.customers_type2 AS target\n",
    "    USING (\n",
    "        SELECT DISTINCT u.customer_id\n",
    "        FROM customer_updates u\n",
    "        INNER JOIN {SILVER_SCHEMA}.customers_type2 t\n",
    "            ON u.customer_id = t.customer_id\n",
    "        WHERE t.__END_AT IS NULL\n",
    "          AND (u.city != t.city OR u.country != t.country OR u.customer_segment != t.customer_segment)\n",
    "    ) AS changed\n",
    "    ON target.customer_id = changed.customer_id \n",
    "       AND target.__END_AT IS NULL\n",
    "    WHEN MATCHED THEN UPDATE SET\n",
    "        target.__END_AT = current_timestamp()\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Insert new versions** - dodanie nowych rekordÃ³w z updated values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCD Type 2: Step 2 - Insert new versions\n",
    "spark.sql(f\"\"\"\n",
    "    INSERT INTO {SILVER_SCHEMA}.customers_type2\n",
    "    SELECT \n",
    "        u.customer_id,\n",
    "        u.first_name,\n",
    "        u.last_name,\n",
    "        u.email,\n",
    "        u.phone,\n",
    "        u.city,\n",
    "        u.state,\n",
    "        u.country,\n",
    "        CAST(u.registration_date AS DATE),\n",
    "        u.customer_segment,\n",
    "        current_timestamp() AS __START_AT,\n",
    "        CAST(NULL AS TIMESTAMP) AS __END_AT\n",
    "    FROM customer_updates u\n",
    "    WHERE NOT EXISTS (\n",
    "        SELECT 1 FROM {SILVER_SCHEMA}.customers_type2 existing\n",
    "        WHERE existing.customer_id = u.customer_id\n",
    "          AND existing.__END_AT IS NULL\n",
    "          AND existing.city = u.city\n",
    "          AND existing.country = u.country\n",
    "          AND existing.customer_segment = u.customer_segment\n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PO ZMIANIE (SCD Type 2 - historical tracking):**\n",
    "\n",
    "Historia zostaÅ‚a zachowana! WyÅ›wietlenie wszystkich wersji customer_id=1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WyÅ›wietl historiÄ™ zmian dla CUST000001\n",
    "display(\n",
    "    spark.sql(f\"\"\"\n",
    "        SELECT \n",
    "            customer_id,\n",
    "            first_name,\n",
    "            city,\n",
    "            country,\n",
    "            customer_segment,\n",
    "            __START_AT,\n",
    "            __END_AT,\n",
    "            CASE WHEN __END_AT IS NULL THEN 'CURRENT' ELSE 'HISTORICAL' END AS status\n",
    "        FROM {SILVER_SCHEMA}.customers_type2 \n",
    "        WHERE customer_id = 'CUST000001'\n",
    "        ORDER BY __START_AT\n",
    "    \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**âœ… Historia zachowana! (format Lakeflow)**\n",
    "\n",
    "Mamy teraz 2 rekordy:\n",
    "- **Record 1**: New York, USA (__END_AT = timestamp zamkniÄ™cia)\n",
    "- **Record 2**: KrakÃ³w, POL (__END_AT = NULL = aktualny rekord)\n",
    "\n",
    "W Lakeflow ten sam efekt uzyskujemy automatycznie przez `AUTO CDC ... STORED AS SCD TYPE 2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PrzykÅ‚ad: Query 'as of date'\n",
    "\n",
    "**Gdzie mieszkaÅ‚ klient 1 miesiÄ…c temu?** SCD Type 2 umoÅ¼liwia temporal queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_month_ago = (datetime.now() - timedelta(days=30)).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query \"as of date\" - format Lakeflow\n",
    "display(\n",
    "    spark.sql(f\"\"\"\n",
    "        SELECT \n",
    "            customer_id,\n",
    "            first_name,\n",
    "            city,\n",
    "            country,\n",
    "            __START_AT,\n",
    "            __END_AT\n",
    "        FROM {SILVER_SCHEMA}.customers_type2\n",
    "        WHERE customer_id = 'CUST000001'\n",
    "          AND '{one_month_ago}' >= __START_AT \n",
    "          AND ('{one_month_ago}' < __END_AT OR __END_AT IS NULL)\n",
    "    \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cb23f29-f3a5-4c11-a47e-7a65b3ad44d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sekcja 4: Gold Layer - Star Schema (zgodny z Lakeflow)\n",
    "\n",
    "**Cel sekcji:** Implementacja Star Schema zgodnie z modelem Lakeflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca9f9c7f-f53f-4d3b-813b-e6a3524b2974",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Gold Layer - Model Danych (Lakeflow)\n",
    "\n",
    "**Fact Table:**\n",
    "- `fact_sales` - gÅ‚Ã³wna tabela faktÃ³w z miarami transakcyjnymi\n",
    "\n",
    "**Dimension Tables:**\n",
    "- `dim_customer` - wymiar klientÃ³w (snapshot z SCD2)\n",
    "- `dim_product` - wymiar produktÃ³w\n",
    "- `dim_date` - wymiar czasu\n",
    "- `dim_store` - wymiar sklepÃ³w\n",
    "- `dim_payment_method` - wymiar metod pÅ‚atnoÅ›ci\n",
    "\n",
    "### Star Schema Diagram\n",
    "\n",
    "```\n",
    "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                    â”‚   dim_date      â”‚\n",
    "                    â”‚ date_key (PK)   â”‚\n",
    "                    â”‚ year, quarter   â”‚\n",
    "                    â”‚ month, day      â”‚\n",
    "                    â”‚ is_weekend      â”‚\n",
    "                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                             â”‚\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ dim_customer â”‚    â”‚   fact_sales    â”‚    â”‚ dim_product  â”‚\n",
    "â”‚ customer_id  â”‚â”€â”€â”€â”€â”‚ order_id (PK)   â”‚â”€â”€â”€â”€â”‚ product_id   â”‚\n",
    "â”‚ first_name   â”‚    â”‚ customer_id (FK)â”‚    â”‚ product_name â”‚\n",
    "â”‚ last_name    â”‚    â”‚ product_id (FK) â”‚    â”‚ unit_cost    â”‚\n",
    "â”‚ city, state  â”‚    â”‚ store_id (FK)   â”‚    â”‚ list_price   â”‚\n",
    "â”‚ segment      â”‚    â”‚ date_key (FK)   â”‚    â”‚ is_active    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ payment_method  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                    â”‚ quantity        â”‚\n",
    "                    â”‚ unit_price      â”‚\n",
    "                    â”‚ gross_amount    â”‚\n",
    "                    â”‚ discount_amount â”‚\n",
    "                    â”‚ net_amount      â”‚\n",
    "                    â”‚ is_return       â”‚\n",
    "                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                             â”‚\n",
    "              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "              â”‚                             â”‚\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚    dim_store      â”‚     â”‚ dim_payment_method    â”‚\n",
    "    â”‚ store_id          â”‚     â”‚ payment_method_code   â”‚\n",
    "    â”‚ store_code        â”‚     â”‚ payment_method_group  â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### PrzykÅ‚ad 4.1: dim_customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ca302cc-5126-4368-a0a9-fd63e8fc27c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Gold: dim_customer (snapshot z SCD2 - tylko aktualne rekordy)\n",
    "dim_customer = spark.sql(f\"\"\"\n",
    "    SELECT\n",
    "        customer_id,\n",
    "        first_name,\n",
    "        last_name,\n",
    "        email,\n",
    "        phone,\n",
    "        city,\n",
    "        state,\n",
    "        country,\n",
    "        registration_date,\n",
    "        customer_segment\n",
    "    FROM {SILVER_SCHEMA}.customers_type2\n",
    "    WHERE __END_AT IS NULL\n",
    "\"\"\")\n",
    "\n",
    "dim_customer.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{GOLD_SCHEMA}.dim_customer\")\n",
    "\n",
    "display({\n",
    "    \"table\": f\"{GOLD_SCHEMA}.dim_customer\",\n",
    "    \"records\": dim_customer.count(),\n",
    "    \"status\": \"âœ… Created\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utworzona tabela dim_customer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(spark.table(f\"{GOLD_SCHEMA}.dim_customer\").limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PrzykÅ‚ad 4.2: dim_product (zgodne z Lakeflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gold: dim_product (zgodne z Lakeflow silver_products)\n",
    "bronze_products = spark.table(f\"{BRONZE_SCHEMA}.products_raw\")\n",
    "\n",
    "dim_product = (bronze_products\n",
    "    .withColumn(\"unit_cost\", F.col(\"unit_cost\").cast(\"double\"))\n",
    "    .withColumn(\"list_price\", F.col(\"list_price\").cast(\"double\"))\n",
    "    .withColumn(\"weight_kg\", F.col(\"weight_kg\").cast(\"double\"))\n",
    "    .withColumn(\"is_active\", \n",
    "        F.when(F.upper(F.col(\"status\")).isin(\"ACTIVE\", \"AVAILABLE\"), 1).otherwise(0)\n",
    "    )\n",
    "    .withColumn(\"is_unknown\", F.lit(0))\n",
    "    .select(\n",
    "        \"product_id\", \"product_name\", \"subcategory_code\", \"brand\",\n",
    "        \"unit_cost\", \"list_price\", \"weight_kg\", \"status\",\n",
    "        \"is_active\", \"is_unknown\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add UNKNOWN product (jak w Lakeflow)\n",
    "unknown_product = spark.createDataFrame([\n",
    "    (\"UNKNOWN\", \"Unknown product\", \"UNKNOWN\", \"Unknown\", None, None, None, \"Unknown\", 0, 1)\n",
    "], [\"product_id\", \"product_name\", \"subcategory_code\", \"brand\", \n",
    "    \"unit_cost\", \"list_price\", \"weight_kg\", \"status\", \"is_active\", \"is_unknown\"])\n",
    "\n",
    "dim_product_final = dim_product.unionByName(unknown_product)\n",
    "\n",
    "dim_product_final.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{GOLD_SCHEMA}.dim_product\")\n",
    "\n",
    "display({\n",
    "    \"table\": f\"{GOLD_SCHEMA}.dim_product\",\n",
    "    \"records\": dim_product_final.count(),\n",
    "    \"status\": \"âœ… Created (includes UNKNOWN product)\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utworzona tabela dim_product:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b567a9e-ec08-4042-9973-28c9117a90ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### PrzykÅ‚ad 4.3: dim_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1aa72ab7-4a44-4fc8-9440-6cad937d403b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.table(f\"{GOLD_SCHEMA}.dim_product\").limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utworzona tabela dim_date:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(spark.table(f\"{GOLD_SCHEMA}.dim_date\").limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gold: dim_date (generowane z silver_orders jak w Lakeflow)\n",
    "silver_orders = spark.table(f\"{SILVER_SCHEMA}.orders_clean\")\n",
    "\n",
    "dim_date = (silver_orders\n",
    "    .select(\"order_date\")\n",
    "    .filter(F.col(\"order_date\").isNotNull())  # Filtruj NULL dates\n",
    "    .distinct()\n",
    "    .withColumn(\"date_key\", F.date_format(F.col(\"order_date\"), \"yyyyMMdd\").cast(\"int\"))\n",
    "    .withColumn(\"date\", F.col(\"order_date\"))\n",
    "    .withColumn(\"year\", F.year(F.col(\"order_date\")))\n",
    "    .withColumn(\"quarter\", F.quarter(F.col(\"order_date\")))\n",
    "    .withColumn(\"month\", F.month(F.col(\"order_date\")))\n",
    "    .withColumn(\"day\", F.dayofmonth(F.col(\"order_date\")))\n",
    "    .withColumn(\"day_of_week\", F.date_format(F.col(\"order_date\"), \"E\"))\n",
    "    .withColumn(\"is_weekend\", \n",
    "        F.when(F.date_format(F.col(\"order_date\"), \"E\").isin(\"Sat\", \"Sun\"), 1).otherwise(0)\n",
    "    )\n",
    "    .select(\"date_key\", \"date\", \"year\", \"quarter\", \"month\", \"day\", \"day_of_week\", \"is_weekend\")\n",
    "    .orderBy(\"date_key\")\n",
    ")\n",
    "\n",
    "dim_date.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{GOLD_SCHEMA}.dim_date\")\n",
    "\n",
    "display({\n",
    "    \"table\": f\"{GOLD_SCHEMA}.dim_date\",\n",
    "    \"records\": dim_date.count(),\n",
    "    \"status\": \"âœ… Created\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PrzykÅ‚ad 4.5: dim_store i dim_payment_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gold: dim_store (generowane z silver_orders jak w Lakeflow)\n",
    "dim_store = (silver_orders\n",
    "    .select(\"store_id\")\n",
    "    .distinct()\n",
    "    .withColumn(\"store_code\", F.col(\"store_id\"))\n",
    ")\n",
    "\n",
    "dim_store.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{GOLD_SCHEMA}.dim_store\")\n",
    "\n",
    "# Gold: dim_payment_method (generowane z silver_orders jak w Lakeflow)\n",
    "dim_payment_method = (silver_orders\n",
    "    .select(\"payment_method_code\")\n",
    "    .distinct()\n",
    "    .withColumn(\"payment_method_group\",\n",
    "        F.when(F.col(\"payment_method_code\").isin(\"Credit Card\", \"Debit Card\"), \"Card\")\n",
    "        .when(F.col(\"payment_method_code\") == \"Cash\", \"Cash\")\n",
    "        .when(F.col(\"payment_method_code\") == \"PayPal\", \"Digital wallet\")\n",
    "        .otherwise(\"Other\")\n",
    "    )\n",
    ")\n",
    "\n",
    "dim_payment_method.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{GOLD_SCHEMA}.dim_payment_method\")\n",
    "\n",
    "display({\n",
    "    \"dim_store\": {\"records\": dim_store.count(), \"status\": \"âœ…\"},\n",
    "    \"dim_payment_method\": {\"records\": dim_payment_method.count(), \"status\": \"âœ…\"}\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PrzykÅ‚ad 4.6: fact_sales (tabela faktÃ³w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gold: fact_sales (gÅ‚Ã³wna tabela faktÃ³w - zgodna z Lakeflow)\n",
    "silver_orders = spark.table(f\"{SILVER_SCHEMA}.orders_clean\")\n",
    "\n",
    "fact_sales = (silver_orders\n",
    "    .select(\n",
    "        # Klucze do wymiarÃ³w\n",
    "        \"order_id\",\n",
    "        \"store_id\",\n",
    "        F.coalesce(F.col(\"customer_id\"), F.lit(\"UNKNOWN\")).alias(\"customer_id\"),\n",
    "        F.coalesce(F.col(\"product_id\"), F.lit(\"UNKNOWN\")).alias(\"product_id\"),\n",
    "        \"payment_method_code\",\n",
    "        \"order_date_key\",\n",
    "        \"order_ts\",\n",
    "        \n",
    "        # Miary\n",
    "        \"quantity\",\n",
    "        \"unit_price\",\n",
    "        \"discount_percent\",\n",
    "        \"gross_amount\",\n",
    "        \"discount_amount\",\n",
    "        \"net_amount\",\n",
    "        \n",
    "        # Flagi\n",
    "        \"is_return\",\n",
    "        \"is_future_dated\",\n",
    "        \"is_unknown_customer\",\n",
    "        \"is_unknown_product\",\n",
    "        \n",
    "        # Lineage\n",
    "        \"source_system\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fact_sales.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{GOLD_SCHEMA}.fact_sales\")\n",
    "\n",
    "display({\n",
    "    \"table\": f\"{GOLD_SCHEMA}.fact_sales\",\n",
    "    \"records\": fact_sales.count(),\n",
    "    \"status\": \"âœ… Created\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PodglÄ…d fact_sales z joinami do wymiarÃ³w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Star Schema - przykÅ‚adowy raport sprzedaÅ¼y\n",
    "display(\n",
    "    spark.sql(f\"\"\"\n",
    "        SELECT \n",
    "            d.date,\n",
    "            d.day_of_week,\n",
    "            c.first_name || ' ' || c.last_name AS customer_name,\n",
    "            c.customer_segment,\n",
    "            p.product_name,\n",
    "            p.brand,\n",
    "            pm.payment_method_group,\n",
    "            f.quantity,\n",
    "            f.gross_amount,\n",
    "            f.discount_amount,\n",
    "            f.net_amount\n",
    "        FROM {GOLD_SCHEMA}.fact_sales f\n",
    "        JOIN {GOLD_SCHEMA}.dim_date d ON f.order_date_key = d.date_key\n",
    "        JOIN {GOLD_SCHEMA}.dim_customer c ON f.customer_id = c.customer_id\n",
    "        JOIN {GOLD_SCHEMA}.dim_product p ON f.product_id = p.product_id\n",
    "        JOIN {GOLD_SCHEMA}.dim_payment_method pm ON f.payment_method_code = pm.payment_method_code\n",
    "        WHERE f.is_return = 0 AND f.is_future_dated = 0\n",
    "        ORDER BY f.net_amount DESC\n",
    "        LIMIT 10\n",
    "    \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "039dde8f-ea44-43e0-97bd-f628e4969004",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sekcja 5: Podsumowanie & Best Practices\n",
    "\n",
    "### Co zostaÅ‚o osiÄ…gniÄ™te?\n",
    "\n",
    "âœ… **1. Medallion Architecture Implementation (zgodna z Lakeflow)**\n",
    "\n",
    "**ğŸ¥‰ Bronze Layer:**\n",
    "- `bronze.customers_raw` - CSV z metadanymi (source_file_path, ingestion_ts, load_ts)\n",
    "- `bronze.orders_raw` - JSON z source_system (batch/stream)\n",
    "- `bronze.products_raw` - Parquet\n",
    "\n",
    "**ğŸ¥ˆ Silver Layer:**\n",
    "- `silver.orders_clean` - z kalkulacjami (gross_amount, discount_amount, net_amount)\n",
    "- `silver.orders_clean` - z flagami (is_return, is_future_dated, is_unknown_*)\n",
    "- `silver.customers_type1` - SCD Type 1 (current state)\n",
    "- `silver.customers_type2` - SCD Type 2 (__START_AT, __END_AT)\n",
    "\n",
    "**ğŸ¥‡ Gold Layer (Star Schema):**\n",
    "- `fact_sales` - tabela faktÃ³w z miarami i flagami\n",
    "- `dim_customer` - snapshot z SCD2\n",
    "- `dim_product` - z is_active, is_unknown\n",
    "- `dim_date` - date_key, year, quarter, month, is_weekend\n",
    "- `dim_store` - store_id, store_code\n",
    "- `dim_payment_method` - payment_method_group (Card/Cash/Digital wallet)\n",
    "\n",
    "âœ… **2. SCD (Slowly Changing Dimensions)**\n",
    "- **Type 1**: Overwrite (customers_type1)\n",
    "- **Type 2**: Historical tracking z __START_AT/__END_AT (customers_type2, format Lakeflow)\n",
    "\n",
    "âœ… **3. Data Quality (zgodne z Lakeflow CONSTRAINTS)**\n",
    "- valid_order_id: DROP ROW if NULL\n",
    "- valid_customer: DROP ROW if NULL\n",
    "- valid_product: DROP ROW if NULL\n",
    "- valid_quantity: DROP ROW if NULL or 0\n",
    "- valid_unit_price: DROP ROW if NULL or < 0\n",
    "\n",
    "### Model Danych - PorÃ³wnanie z Lakeflow\n",
    "\n",
    "| Lakeflow (Streaming) | Notebook (Batch) | Status |\n",
    "|---------------------|------------------|--------|\n",
    "| `bronze_customers` (STREAMING TABLE) | `bronze.customers_raw` | âœ… |\n",
    "| `bronze_orders` (STREAMING TABLE + FLOW) | `bronze.orders_raw` | âœ… |\n",
    "| `bronze_products` (MATERIALIZED VIEW) | `bronze.products_raw` | âœ… |\n",
    "| `silver_customers` (SCD2 AUTO CDC) | `silver.customers_type2` | âœ… |\n",
    "| `silver_orders` (CONSTRAINTS) | `silver.orders_clean` | âœ… |\n",
    "| `fact_sales` (STREAMING TABLE) | `gold.fact_sales` | âœ… |\n",
    "| `dim_customer` (MV) | `gold.dim_customer` | âœ… |\n",
    "| `dim_product` (MV) | `gold.dim_product` | âœ… |\n",
    "| `dim_date` (MV) | `gold.dim_date` | âœ… |\n",
    "| `dim_store` (MV) | `gold.dim_store` | âœ… |\n",
    "| `dim_payment_method` (MV) | `gold.dim_payment_method` | âœ… |\n",
    "\n",
    "### Kluczowe Wnioski\n",
    "\n",
    "ğŸ’¡ **1. Lakeflow Streaming vs Batch**\n",
    "```\n",
    "Lakeflow: CREATE OR REFRESH STREAMING TABLE + FLOW\n",
    "Notebook: spark.read â†’ transform â†’ write (batch)\n",
    "\n",
    "Obie metody tworzÄ… identyczny model danych!\n",
    "```\n",
    "\n",
    "ğŸ’¡ **2. Kalkulacje w Silver (nie Bronze)**\n",
    "```python\n",
    "# Silver orders - kalkulowane miary\n",
    "gross_amount = quantity * unit_price\n",
    "discount_amount = gross_amount * discount_percent / 100\n",
    "net_amount = gross_amount - discount_amount\n",
    "```\n",
    "\n",
    "ğŸ’¡ **3. SCD Type 2 - format Lakeflow**\n",
    "```python\n",
    "# Lakeflow: AUTO CDC ... STORED AS SCD TYPE 2\n",
    "# Notebook: Manual MERGE z __START_AT, __END_AT\n",
    "\n",
    "# Query current: WHERE __END_AT IS NULL\n",
    "# Query historical: WHERE date BETWEEN __START_AT AND __END_AT\n",
    "```\n",
    "\n",
    "ğŸ’¡ **4. Star Schema Query Pattern**\n",
    "```sql\n",
    "SELECT f.*, d.year, c.customer_segment, p.product_name\n",
    "FROM fact_sales f\n",
    "JOIN dim_date d ON f.order_date_key = d.date_key\n",
    "JOIN dim_customer c ON f.customer_id = c.customer_id\n",
    "JOIN dim_product p ON f.product_id = p.product_id\n",
    "```\n",
    "\n",
    "### Production Checklist\n",
    "\n",
    "**Bronze Layer:**\n",
    "- [x] Metadata columns (source_file_path, ingestion_ts, load_ts)\n",
    "- [x] source_system tracking (batch/stream)\n",
    "- [x] Multi-format support (CSV, JSON, Parquet)\n",
    "\n",
    "**Silver Layer:**\n",
    "- [x] Calculated measures (gross_amount, discount_amount, net_amount)\n",
    "- [x] Quality flags (is_return, is_future_dated, is_unknown_*)\n",
    "- [x] CONSTRAINT validation (DROP invalid rows)\n",
    "- [x] SCD Type 2 for customers (__START_AT, __END_AT)\n",
    "\n",
    "**Gold Layer:**\n",
    "- [x] Star Schema (fact_sales + dimensions)\n",
    "- [x] dim_customer (snapshot z SCD2)\n",
    "- [x] dim_product (is_active, is_unknown)\n",
    "- [x] dim_date (date_key, is_weekend)\n",
    "- [x] dim_store, dim_payment_method\n",
    "\n",
    "### NastÄ™pne Kroki\n",
    "\n",
    "**ğŸ“š Kolejne Notebooki:**\n",
    "- **04_optimization_best_practices.ipynb** - Performance tuning\n",
    "- **Warsztaty praktyczne** - End-to-end pipeline implementation\n",
    "\n",
    "**ğŸ› ï¸ Lakeflow Pipeline:**\n",
    "- Przejrzyj pliki SQL w `/Lakeflow/` dla production-ready streaming implementation\n",
    "\n",
    "---\n",
    "\n",
    "**Gratulacje!** ğŸ‰ \n",
    "UkoÅ„czyÅ‚eÅ› implementacjÄ™ Medallion Architecture zgodnÄ… z modelem Lakeflow!\n",
    "JesteÅ› gotowy do budowania production-grade data lakehouse pipelines!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e58748e-1fd8-4de1-86ff-8e3e13e32eb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sekcja 6: Czyszczenie ZasobÃ³w\n",
    "\n",
    "**Uwaga:** Ta sekcja jest opcjonalna. Uruchom tylko jeÅ›li chcesz usunÄ…Ä‡ wszystkie dane utworzone w tym notebooku.\n",
    "\n",
    "### Opcja 1: SprawdÅº utworzone zasoby (zalecane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92ef54ea-b672-4608-a9bc-847251e33b02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SprawdÅº utworzone zasoby (Star Schema)\n",
    "medallion_tables = {\n",
    "    \"Bronze\": [\n",
    "        f\"{BRONZE_SCHEMA}.customers_raw\",\n",
    "        f\"{BRONZE_SCHEMA}.orders_raw\",\n",
    "        f\"{BRONZE_SCHEMA}.products_raw\"\n",
    "    ],\n",
    "    \"Silver\": [\n",
    "        f\"{SILVER_SCHEMA}.orders_clean\",\n",
    "        f\"{SILVER_SCHEMA}.customers_type1\",\n",
    "        f\"{SILVER_SCHEMA}.customers_type2\"\n",
    "    ],\n",
    "    \"Gold\": [\n",
    "        f\"{GOLD_SCHEMA}.fact_sales\",\n",
    "        f\"{GOLD_SCHEMA}.dim_customer\",\n",
    "        f\"{GOLD_SCHEMA}.dim_product\",\n",
    "        f\"{GOLD_SCHEMA}.dim_date\",\n",
    "        f\"{GOLD_SCHEMA}.dim_store\",\n",
    "        f\"{GOLD_SCHEMA}.dim_payment_method\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "results = []\n",
    "for layer, tables in medallion_tables.items():\n",
    "    for table in tables:\n",
    "        full_table = f\"{CATALOG}.{table}\"\n",
    "        if spark.catalog.tableExists(full_table):\n",
    "            count = spark.table(full_table).count()\n",
    "            detail = spark.sql(f\"DESCRIBE DETAIL {full_table}\").collect()[0]\n",
    "            size_mb = detail['sizeInBytes'] / (1024 * 1024)\n",
    "            results.append({\"layer\": layer, \"table\": table, \"records\": count, \"size_mb\": round(size_mb, 2)})\n",
    "\n",
    "display(spark.createDataFrame(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dane sÄ… zachowane dla dalszego uÅ¼ytku**\n",
    "\n",
    "Aby usunÄ…Ä‡ wszystkie tabele, uruchom nastÄ™pnÄ… komÃ³rkÄ™ w sekcji opcjonalnej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5dea6788-3610-410f-a222-6962f3f01fc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Opcja 2: UsuÅ„ wszystkie zasoby (tylko jeÅ›li naprawdÄ™ chcesz)\n",
    "\n",
    "**UWAGA:** To usunie wszystkie tabele Silver i Gold utworzone w tym notebooku!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6409dd7e-5b44-4ca7-9aba-e089f8b849d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Opcja 2: UsuÅ„ wszystkie zasoby (TYLKO JEÅšLI JESTEÅš PEWIEN!)\n",
    "\n",
    "# âš ï¸  UWAGA: Odkomentuj poniÅ¼szy kod tylko jeÅ›li chcesz usunÄ…Ä‡ wszystko!\n",
    "\n",
    "\"\"\"\n",
    "print(\"=== ğŸ—‘ï¸  USUWANIE ZASOBÃ“W MEDALLION ===\\n\")\n",
    "\n",
    "# Lista tabel do usuniÄ™cia (Star Schema)\n",
    "tables_to_drop = [\n",
    "    # Silver\n",
    "    f\"{SILVER_SCHEMA}.orders_clean\",\n",
    "    f\"{SILVER_SCHEMA}.customers_type1\",\n",
    "    f\"{SILVER_SCHEMA}.customers_type2\",\n",
    "    # Gold - Star Schema\n",
    "    f\"{GOLD_SCHEMA}.fact_sales\",\n",
    "    f\"{GOLD_SCHEMA}.dim_customer\",\n",
    "    f\"{GOLD_SCHEMA}.dim_product\",\n",
    "    f\"{GOLD_SCHEMA}.dim_date\",\n",
    "    f\"{GOLD_SCHEMA}.dim_store\",\n",
    "    f\"{GOLD_SCHEMA}.dim_payment_method\"\n",
    "]\n",
    "\n",
    "print(\"Usuwanie tabel...\\n\")\n",
    "for table in tables_to_drop:\n",
    "    full_table = f\"{CATALOG}.{table}\"\n",
    "    try:\n",
    "        spark.sql(f\"DROP TABLE IF EXISTS {full_table}\")\n",
    "        print(f\"  âœ“ UsuniÄ™to: {table}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸  BÅ‚Ä…d przy {table}: {e}\")\n",
    "\n",
    "print(\"\\nâœ… Czyszczenie zakoÅ„czone!\")\n",
    "\"\"\"\n",
    "\n",
    "display({\n",
    "    \"status\": \"âš ï¸ KOD CZYSZCZENIA JEST ZAKOMENTOWANY\",\n",
    "    \"info\": \"Odkomentuj powyÅ¼szy kod tylko jeÅ›li chcesz usunÄ…Ä‡ wszystkie zasoby\",\n",
    "    \"zalecenie\": \"Zostaw dane dla kolejnych notebookÃ³w i warsztatÃ³w!\",\n",
    "    \"next\": \"04_optimization_best_practices.ipynb\"\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "04_medallion_architecture",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
