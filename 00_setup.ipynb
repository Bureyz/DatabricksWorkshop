{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "091d9255-523a-4f23-8b17-8a94d8a0e1f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Inicjalizacja kontekstu u≈ºytkownika\n",
    "\n",
    "Cel: izolacja zasob√≥w dla ka≈ºdego uczestnika. Tworzone sƒÖ schematy per u≈ºytkownik w katalogu `training_catalog`: `<user_slug>_bronze`, `<user_slug>_silver`, `<user_slug>_gold`. Uruchom tƒô kom√≥rkƒô przed dalszymi krokami w innych notebookach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ Architektura danych w szkoleniu\n",
    "\n",
    "Szkolenie u≈ºywa **dw√≥ch podej≈õƒá do przechowywania danych** w zale≈ºno≈õci od dnia:\n",
    "\n",
    "### Dzie≈Ñ 1-2: Lokalne pliki ‚Üí Delta Tables\n",
    "- **≈πr√≥d≈Ço**: Folder `dataset/` (CSV, JSON, Parquet)\n",
    "- **Zmienna**: `DATASET_BASE_PATH` \n",
    "- **Cel**: Za≈Çadowanie do Delta tables w schematach Bronze/Silver/Gold\n",
    "- **Przyk≈Çad**: `spark.read.csv(f\"{DATASET_BASE_PATH}/customers/customers.csv\")`\n",
    "\n",
    "### Dzie≈Ñ 3: Unity Catalog Volumes\n",
    "- **≈πr√≥d≈Ço**: Unity Catalog Volumes (`/Volumes/training_catalog/default/kion_datasets`)\n",
    "- **Zmienna**: `VOLUMES_BASE_PATH` (opcjonalne dla Dzie≈Ñ 3)\n",
    "- **Cel**: Demonstracja zaawansowanych feature'√≥w UC (DLT, Lakeflow, Governance)\n",
    "- **Przyk≈Çad**: `spark.read.csv(\"/Volumes/training_catalog/default/kion_datasets/customers.csv\")`\n",
    "\n",
    "### Dlaczego dwa podej≈õcia?\n",
    "- **Progresja edukacyjna**: Od prostych plik√≥w (Dzie≈Ñ 1) ‚Üí Delta Lake (Dzie≈Ñ 2) ‚Üí Unity Catalog (Dzie≈Ñ 3)\n",
    "- **Real-world scenarios**: W produkcji czƒôsto u≈ºywa siƒô Volumes dla managed data access w UC\n",
    "- **Best practices**: Dzie≈Ñ 3 pokazuje, jak zarzƒÖdzaƒá danymi w enterprise environment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e047da8-3e6c-46d1-9153-094034c7a9d4",
     "showTitle": false,
     "tableResultSettingsMap": {
      "1": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"dataset_path\":322},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1763579086288}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 1
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# === Konfiguracja katalog√≥w i schemat√≥w ===\n",
    "CATALOG = \"training_catalog\"\n",
    "\n",
    "# Pobierz aktualnego u≈ºytkownika (dla ≈õrodowiska produkcyjnego)\n",
    "# raw_user = spark.sql(\"SELECT current_user()\").first()[0]\n",
    "raw_user = \"trainer\"  # Dla ≈õrodowiska szkoleniowego\n",
    "\n",
    "import re\n",
    "user_slug = re.sub(\n",
    "    r'[^a-z0-9]', \n",
    "    '_', \n",
    "    raw_user.lower()\n",
    ")\n",
    "\n",
    "print(f\"User slug: {user_slug}\")\n",
    "\n",
    "# Schematy per u≈ºytkownik (izolacja zasob√≥w)\n",
    "BRONZE_SCHEMA = f\"{user_slug}_bronze\"\n",
    "SILVER_SCHEMA = f\"{user_slug}_silver\"\n",
    "GOLD_SCHEMA   = f\"{user_slug}_gold\"\n",
    "\n",
    "# === ≈öcie≈ºka do dataset√≥w ===\n",
    "# Dla lokalnego ≈õrodowiska - ≈õcie≈ºka do folderu dataset w tym repo\n",
    "import os\n",
    "DATASET_BASE_PATH = os.path.abspath(\"../dataset\")\n",
    "\n",
    "# Dla Databricks ≈õrodowiska - Unity Catalog Volume:\n",
    "# DATASET_BASE_PATH = \"/Volumes/training_catalog/default/kion_datasets\"\n",
    "\n",
    "\n",
    "print(f\"Dataset base path: {DATASET_BASE_PATH}\")\n",
    "\n",
    "# === Tworzenie katalog√≥w i schemat√≥w (tylko w Databricks) ===\n",
    "try:\n",
    "    spark.sql(f'USE CATALOG {CATALOG}')\n",
    "    \n",
    "    for s in [BRONZE_SCHEMA, SILVER_SCHEMA, GOLD_SCHEMA]:\n",
    "        spark.sql(f'CREATE SCHEMA IF NOT EXISTS {CATALOG}.{s}')\n",
    "    \n",
    "    spark.sql(f'USE SCHEMA {BRONZE_SCHEMA}')\n",
    "    print(\"‚úì Unity Catalog schemas created successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö† Unity Catalog not available or not configured: {e}\")\n",
    "    print(\"Continuing with default database...\")\n",
    "\n",
    "# === Wy≈õwietl informacje o katalogu ===\n",
    "print(\"\\n=== Informacje o katalogu ===\")\n",
    "display(\n",
    "    spark.sql(f\"DESCRIBE CATALOG EXTENDED {CATALOG}\")\n",
    ")\n",
    "\n",
    "# === Podsumowanie konfiguracji ===\n",
    "print(\"\\n=== Podsumowanie konfiguracji u≈ºytkownika ===\")\n",
    "display(\n",
    "    spark.createDataFrame(\n",
    "        [\n",
    "            (\n",
    "                raw_user, \n",
    "                f'{CATALOG}.{BRONZE_SCHEMA}', \n",
    "                f'{CATALOG}.{SILVER_SCHEMA}', \n",
    "                f'{CATALOG}.{GOLD_SCHEMA}',\n",
    "                DATASET_BASE_PATH\n",
    "            )\n",
    "        ],\n",
    "        ['user', 'bronze_schema', 'silver_schema', 'gold_schema', 'dataset_path']\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Inicjalizacja zako≈Ñczona pomy≈õlnie!\")\n",
    "print(f\"‚úì U≈ºytkownik: {raw_user}\")\n",
    "print(f\"‚úì Katalog: {CATALOG}\")\n",
    "print(f\"‚úì Schematy: {BRONZE_SCHEMA}, {SILVER_SCHEMA}, {GOLD_SCHEMA}\")\n",
    "print(f\"‚úì ≈öcie≈ºka do danych: {DATASET_BASE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Funkcje pomocnicze (opcjonalne - tylko dla Dzie≈Ñ 3)\n",
    "\n",
    "Poni≈ºsza funkcja kopiuje dane z lokalnego folderu `dataset/` do Unity Catalog Volumes.  \n",
    "**U≈ºyj tylko je≈õli pracujesz na Databricks i chcesz przygotowaƒá dane dla Dzie≈Ñ 3.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_dataset_to_volumes():\n",
    "    \"\"\"\n",
    "    Kopiuje dane z lokalnego folderu dataset/ do Unity Catalog Volumes.\n",
    "    U≈ºywane tylko w ≈õrodowisku Databricks dla przygotowania Dzie≈Ñ 3.\n",
    "    \"\"\"\n",
    "    import shutil\n",
    "    from pathlib import Path\n",
    "    \n",
    "    print(\"=== Kopiowanie danych do Unity Catalog Volumes ===\")\n",
    "    print(f\"≈πr√≥d≈Ço: {DATASET_BASE_PATH}\")\n",
    "    print(f\"Cel: {VOLUMES_BASE_PATH}\")\n",
    "    \n",
    "    try:\n",
    "        # Sprawd≈∫, czy Volume istnieje\n",
    "        dbutils.fs.ls(VOLUMES_BASE_PATH)\n",
    "        print(\"‚úì Volume dostƒôpny\")\n",
    "        \n",
    "        # Kopiuj ka≈ºdy folder z dataset/\n",
    "        folders_to_copy = ['customers', 'orders', 'products']\n",
    "        \n",
    "        for folder in folders_to_copy:\n",
    "            source = os.path.join(DATASET_BASE_PATH, folder)\n",
    "            target = f\"{VOLUMES_BASE_PATH}/{folder}\"\n",
    "            \n",
    "            if os.path.exists(source):\n",
    "                print(f\"  Kopiowanie: {folder}/\")\n",
    "                \n",
    "                # Utw√≥rz folder w Volumes je≈õli nie istnieje\n",
    "                try:\n",
    "                    dbutils.fs.mkdirs(target)\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                # Kopiuj pliki\n",
    "                for file in os.listdir(source):\n",
    "                    source_file = os.path.join(source, file)\n",
    "                    target_file = f\"{target}/{file}\"\n",
    "                    \n",
    "                    if os.path.isfile(source_file):\n",
    "                        dbutils.fs.cp(f\"file:{source_file}\", target_file, recurse=False)\n",
    "                        print(f\"    ‚úì {file}\")\n",
    "            else:\n",
    "                print(f\"  ‚ö† Folder {folder}/ nie istnieje w dataset/\")\n",
    "        \n",
    "        print(\"\\n‚úì Kopiowanie zako≈Ñczone pomy≈õlnie!\")\n",
    "        print(f\"Dane dostƒôpne w: {VOLUMES_BASE_PATH}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚úó B≈ÇƒÖd kopiowania: {e}\")\n",
    "        print(\"Upewnij siƒô, ≈ºe:\")\n",
    "        print(\"  1. Unity Catalog jest w≈ÇƒÖczony\")\n",
    "        print(\"  2. Volume zosta≈Ç utworzony: CREATE VOLUME IF NOT EXISTS training_catalog.default.kion_datasets\")\n",
    "        print(\"  3. Masz uprawnienia do zapisu w Volume\")\n",
    "        return False\n",
    "\n",
    "# Odkomentuj poni≈ºszƒÖ liniƒô, aby skopiowaƒá dane do Volumes (tylko raz, przed Dzie≈Ñ 3)\n",
    "# copy_dataset_to_volumes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Funkcje diagnostyczne\n",
    "\n",
    "Pomocne funkcje do sprawdzania stanu ≈õrodowiska i danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_environment_info():\n",
    "    \"\"\"Wy≈õwietla pe≈Çne informacje o konfiguracji ≈õrodowiska\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"üìä INFORMACJE O ≈öRODOWISKU SZKOLENIOWYM\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(f\"\\nüë§ U≈ºytkownik: {raw_user}\")\n",
    "    print(f\"   User slug: {user_slug}\")\n",
    "    \n",
    "    print(f\"\\nüìÅ Schematy:\")\n",
    "    print(f\"   Bronze: {CATALOG}.{BRONZE_SCHEMA}\")\n",
    "    print(f\"   Silver: {CATALOG}.{SILVER_SCHEMA}\")\n",
    "    print(f\"   Gold:   {CATALOG}.{GOLD_SCHEMA}\")\n",
    "    \n",
    "    print(f\"\\nüíæ ≈öcie≈ºki do danych:\")\n",
    "    print(f\"   Dataset (Dzie≈Ñ 1-2): {DATASET_BASE_PATH}\")\n",
    "    print(f\"   Volumes (Dzie≈Ñ 3):   {VOLUMES_BASE_PATH}\")\n",
    "    \n",
    "    print(f\"\\n‚öôÔ∏è Spark:\")\n",
    "    print(f\"   Spark version: {spark.version}\")\n",
    "    try:\n",
    "        print(f\"   Databricks Runtime: {spark.conf.get('spark.databricks.clusterUsageTags.sparkVersion')}\")\n",
    "    except:\n",
    "        print(f\"   Databricks Runtime: N/A (local environment)\")\n",
    "    \n",
    "    print(f\"\\nüóÑÔ∏è Unity Catalog:\")\n",
    "    try:\n",
    "        current_catalog = spark.sql(\"SELECT current_catalog()\").first()[0]\n",
    "        current_schema = spark.sql(\"SELECT current_schema()\").first()[0]\n",
    "        print(f\"   Current catalog: {current_catalog}\")\n",
    "        print(f\"   Current schema: {current_schema}\")\n",
    "        print(f\"   Status: ‚úì Aktywny\")\n",
    "    except:\n",
    "        print(f\"   Status: ‚úó Niedostƒôpny\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "def show_tables_summary():\n",
    "    \"\"\"Wy≈õwietla podsumowanie tabel utworzonych w schematach\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"üìã PODSUMOWANIE TABEL W SCHEMATACH\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    for schema_name, schema_var in [\n",
    "        (\"Bronze\", BRONZE_SCHEMA),\n",
    "        (\"Silver\", SILVER_SCHEMA),\n",
    "        (\"Gold\", GOLD_SCHEMA)\n",
    "    ]:\n",
    "        print(f\"\\n{schema_name} Layer ({CATALOG}.{schema_var}):\")\n",
    "        try:\n",
    "            tables = spark.sql(f\"SHOW TABLES IN {CATALOG}.{schema_var}\")\n",
    "            table_count = tables.count()\n",
    "            \n",
    "            if table_count > 0:\n",
    "                print(f\"  ‚úì {table_count} tabel(i):\")\n",
    "                for row in tables.collect():\n",
    "                    table_type = \"VIEW\" if row.isTemporary else \"TABLE\"\n",
    "                    print(f\"    - {row.tableName} ({table_type})\")\n",
    "            else:\n",
    "                print(f\"  ‚ö† Brak tabel (schemat pusty)\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚úó Nie mo≈ºna odczytaƒá tabel: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "def show_dataset_statistics():\n",
    "    \"\"\"Wy≈õwietla statystyki plik√≥w w folderze dataset/\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"üìà STATYSTYKI DANYCH ≈πR√ìD≈ÅOWYCH\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    folders = ['customers', 'orders', 'products']\n",
    "    \n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join(DATASET_BASE_PATH, folder)\n",
    "        print(f\"\\nüìÇ {folder}/\")\n",
    "        \n",
    "        if os.path.exists(folder_path):\n",
    "            files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "            print(f\"  Liczba plik√≥w: {len(files)}\")\n",
    "            \n",
    "            total_size = 0\n",
    "            for file in files:\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                size = os.path.getsize(file_path)\n",
    "                total_size += size\n",
    "                size_mb = size / (1024 * 1024)\n",
    "                print(f\"    - {file}: {size_mb:.2f} MB\")\n",
    "            \n",
    "            total_mb = total_size / (1024 * 1024)\n",
    "            print(f\"  ≈ÅƒÖczny rozmiar: {total_mb:.2f} MB\")\n",
    "        else:\n",
    "            print(f\"  ‚úó Folder nie istnieje\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "# Przyk≈Çad u≈ºycia (odkomentuj aby uruchomiƒá):\n",
    "# show_environment_info()\n",
    "# show_tables_summary()\n",
    "# show_dataset_statistics()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00_setup",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
