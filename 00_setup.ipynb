{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "091d9255-523a-4f23-8b17-8a94d8a0e1f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Inicjalizacja kontekstu u≈ºytkownika\n",
    "\n",
    "**Cel**: Konfiguracja ≈õrodowiska i izolacja zasob√≥w.\n",
    "\n",
    "Skrypt realizuje strategiƒô **Catalog Isolation** (rekomendowana):\n",
    "1.  Tworzy dedykowany katalog dla u≈ºytkownika: `ecommerce_platform_<user_slug>` (np. `ecommerce_platform_kzb`).\n",
    "2.  WewnƒÖtrz katalogu tworzy standardowe schematy warstw: `bronze`, `silver`, `gold`.\n",
    "3.  Ustawia zmienne globalne (`CATALOG`, `BRONZE_SCHEMA` itp.) u≈ºywane w notebookach.\n",
    "\n",
    "*Je≈õli u≈ºytkownik nie ma uprawnie≈Ñ do tworzenia katalog√≥w, skrypt automatycznie prze≈ÇƒÖczy siƒô na tryb izolacji schematami w katalogu `ecommerce_platform`.*\n",
    "\n",
    "**Uruchom tƒô kom√≥rkƒô raz na poczƒÖtku sesji.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d616be3-1dff-4372-a6fb-1be07f8cba57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìÅ Architektura danych w szkoleniu\n",
    "\n",
    "Szkolenie u≈ºywa **dw√≥ch podej≈õƒá do przechowywania danych** w zale≈ºno≈õci od dnia:\n",
    "\n",
    "### Dzie≈Ñ 1-2: Lokalne pliki ‚Üí Delta Tables\n",
    "- **≈πr√≥d≈Ço**: Folder `dataset/` (CSV, JSON, Parquet)\n",
    "- **Zmienna**: `DATASET_BASE_PATH` \n",
    "- **Cel**: Za≈Çadowanie do Delta tables w schematach Bronze/Silver/Gold\n",
    "- **Przyk≈Çad**: `spark.read.csv(f\"{DATASET_BASE_PATH}/customers/customers.csv\")`\n",
    "\n",
    "### Dzie≈Ñ 3: Unity Catalog Volumes\n",
    "- **≈πr√≥d≈Ço**: Unity Catalog Volumes (`/Volumes/ecommerce_platform_<user>/default/kion_datasets`)\n",
    "- **Zmienna**: `VOLUMES_BASE_PATH` (opcjonalne dla Dzie≈Ñ 3)\n",
    "- **Cel**: Demonstracja zaawansowanych feature'√≥w UC (DLT, Lakeflow, Governance)\n",
    "- **Przyk≈Çad**: `spark.read.csv(\"/Volumes/ecommerce_platform_kzb/default/kion_datasets/customers.csv\")`\n",
    "\n",
    "### Dlaczego dwa podej≈õcia?\n",
    "- **Progresja edukacyjna**: Od prostych plik√≥w (Dzie≈Ñ 1) ‚Üí Delta Lake (Dzie≈Ñ 2) ‚Üí Unity Catalog (Dzie≈Ñ 3)\n",
    "- **Real-world scenarios**: W produkcji czƒôsto u≈ºywa siƒô Volumes dla managed data access w UC\n",
    "- **Best practices**: Dzie≈Ñ 3 pokazuje, jak zarzƒÖdzaƒá danymi w enterprise environment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e047da8-3e6c-46d1-9153-094034c7a9d4",
     "showTitle": false,
     "tableResultSettingsMap": {
      "1": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"dataset_path\":322},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1763579086288}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 1
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# === Konfiguracja katalog√≥w i schemat√≥w ===\n",
    "# Pobierz aktualnego u≈ºytkownika (dla ≈õrodowiska produkcyjnego)\n",
    "# raw_user = spark.sql(\"SELECT current_user()\").first()[0]\n",
    "raw_user = \"trainer\"  # Dla ≈õrodowiska szkoleniowego\n",
    "\n",
    "import re\n",
    "user_slug = re.sub(\n",
    "    r'[^a-z0-9]', \n",
    "    '_', \n",
    "    raw_user.lower()\n",
    ")\n",
    "\n",
    "print(f\"User slug: {user_slug}\")\n",
    "\n",
    "# --- KONFIGURACJA ARCHITEKTURY ---\n",
    "# Wyb√≥r strategii izolacji: 'CATALOG' (rekomendowana) lub 'SCHEMA' (fallback)\n",
    "ISOLATION_MODE = 'CATALOG' \n",
    "\n",
    "if ISOLATION_MODE == 'CATALOG':\n",
    "    # Opcja 1: Izolacja Katalogami (Czysty kod: FROM bronze.orders)\n",
    "    # Wymaga uprawnie≈Ñ CREATE CATALOG\n",
    "    CATALOG = f\"ecommerce_platform_{user_slug}\"\n",
    "    BRONZE_SCHEMA = \"bronze\"\n",
    "    SILVER_SCHEMA = \"silver\"\n",
    "    GOLD_SCHEMA   = \"gold\"\n",
    "else:\n",
    "    # Opcja 2: Izolacja Schematami (Wsp√≥lny katalog: FROM user_bronze.orders)\n",
    "    # ≈Åatwiejsze uprawnienia\n",
    "    CATALOG = \"ecommerce_platform\"\n",
    "    BRONZE_SCHEMA = f\"{user_slug}_bronze\"\n",
    "    SILVER_SCHEMA = f\"{user_slug}_silver\"\n",
    "    GOLD_SCHEMA   = f\"{user_slug}_gold\"\n",
    "\n",
    "# === ≈öcie≈ºka do dataset√≥w ===\n",
    "# Dla lokalnego ≈õrodowiska - ≈õcie≈ºka do folderu dataset w tym repo\n",
    "#import os\n",
    "#DATASET_BASE_PATH = os.path.abspath(\"../dataset\")\n",
    "\n",
    " #Dla Databricks ≈õrodowiska - Unity Catalog Volume:\n",
    "# Zak≈Çadamy, ≈ºe dane ≈∫r√≥d≈Çowe sƒÖ we wsp√≥lnym katalogu 'training_sources' lub podobnym\n",
    "# Tutaj dla uproszczenia u≈ºywamy katalogu u≈ºytkownika, ale w realnym scenariuszu by≈Çby to read-only shared volume\n",
    "DATASET_BASE_PATH = f\"/Volumes/{CATALOG}/default/kion_datasets\"\n",
    "\n",
    "\n",
    "print(f\"Dataset base path: {DATASET_BASE_PATH}\")\n",
    "\n",
    "# === Tworzenie katalog√≥w i schemat√≥w (tylko w Databricks) ===\n",
    "try:\n",
    "    if ISOLATION_MODE == 'CATALOG':\n",
    "        print(f\"Creating/Using Catalog: {CATALOG}...\")\n",
    "        spark.sql(f\"CREATE CATALOG IF NOT EXISTS {CATALOG}\")\n",
    "    \n",
    "    spark.sql(f'USE CATALOG {CATALOG}')\n",
    "    \n",
    "    for s in [BRONZE_SCHEMA, SILVER_SCHEMA, GOLD_SCHEMA]:\n",
    "        spark.sql(f'CREATE SCHEMA IF NOT EXISTS {CATALOG}.{s}')\n",
    "    \n",
    "    # Opcjonalnie: Utw√≥rz wolumen na dane je≈õli nie istnieje (dla cel√≥w szkoleniowych)\n",
    "    spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.default\")\n",
    "    # spark.sql(f\"CREATE VOLUME IF NOT EXISTS {CATALOG}.default.kion_datasets\") \n",
    "    \n",
    "    spark.sql(f'USE SCHEMA {BRONZE_SCHEMA}')\n",
    "    print(\"‚úì Unity Catalog resources created successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö† Error configuring Unity Catalog: {e}\")\n",
    "    print(\"Ensure you have CREATE CATALOG or CREATE SCHEMA permissions.\")\n",
    "\n",
    "# === Wy≈õwietl informacje o katalogu ===\n",
    "print(\"\\n=== Informacje o katalogu ===\")\n",
    "display(\n",
    "    spark.sql(f\"DESCRIBE CATALOG EXTENDED {CATALOG}\")\n",
    ")\n",
    "\n",
    "# === Podsumowanie konfiguracji u≈ºytkownika ===\")\n",
    "display(\n",
    "    spark.createDataFrame(\n",
    "        [\n",
    "            (\n",
    "                raw_user, \n",
    "                f'{CATALOG}.{BRONZE_SCHEMA}', \n",
    "                f'{CATALOG}.{SILVER_SCHEMA}', \n",
    "                f'{CATALOG}.{GOLD_SCHEMA}',\n",
    "                DATASET_BASE_PATH\n",
    "            )\n",
    "        ],\n",
    "        ['user', 'bronze_schema', 'silver_schema', 'gold_schema', 'dataset_path']\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Inicjalizacja zako≈Ñczona pomy≈õlnie!\")\n",
    "print(f\"‚úì Tryb izolacji: {ISOLATION_MODE}\")\n",
    "print(f\"‚úì Katalog roboczy: {CATALOG}\")\n",
    "print(f\"‚úì Schematy: {BRONZE_SCHEMA}, {SILVER_SCHEMA}, {GOLD_SCHEMA}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00_setup",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
