{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc1b211",
   "metadata": {},
   "source": [
    "# Unity Catalog Governance - Demo\n",
    "\n",
    "**Cel szkoleniowy:** Opanowanie Unity Catalog jako platformy governance dla Databricks Lakehouse, zarzƒÖdzanie dostƒôpami, data masking, lineage i audit logging\n",
    "\n",
    "**Zakres tematyczny:**\n",
    "- Unity Catalog Architecture: Metastore, Catalog, Schema, Tables/Views/Volumes\n",
    "- ZarzƒÖdzanie dostƒôpami: GRANT/REVOKE privileges\n",
    "- Data Masking i Row-Level Security\n",
    "- Data Lineage i Audit Logging\n",
    "- Delta Sharing - secure data sharing\n",
    "- Best Practices for Data Governance\n",
    "\n",
    "---\n",
    "\n",
    "## Kontekst i wymagania\n",
    "\n",
    "- **Dzie≈Ñ szkolenia**: Dzie≈Ñ 3 - Transformation, Governance & Integrations\n",
    "- **Typ notebooka**: Demo\n",
    "- **Wymagania techniczne**:\n",
    "  - Databricks Runtime 13.0+ (zalecane: 14.3 LTS)\n",
    "  - Unity Catalog w≈ÇƒÖczony (wymagane!)\n",
    "  - Uprawnienia: CREATE CATALOG, CREATE SCHEMA, GRANT/REVOKE\n",
    "  - Klaster: Standard z minimum 2 workers\n",
    "- **Czas trwania**: 45 minut\n",
    "- **Prerekvizity**: 03_databricks_jobs_orchestration.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c043a28",
   "metadata": {},
   "source": [
    "## Wstƒôp teoretyczny\n",
    "\n",
    "**Cel sekcji:** Zrozumienie Unity Catalog jako zunifikowanej platformy governance dla data lakehouse\n",
    "\n",
    "**Podstawowe pojƒôcia:**\n",
    "- **Unity Catalog**: Zunifikowane rozwiƒÖzanie governance dla wszystkich data assets\n",
    "- **Metastore**: Region-level container dla katalog√≥w (top-level)\n",
    "- **Three-level namespace**: catalog.schema.table\n",
    "- **Securable objects**: Tables, Views, Functions, Volumes, Models\n",
    "- **Fine-grained access control**: Table, column, row-level security\n",
    "- **Automatic lineage**: End-to-end data flow tracking bez instrumentacji\n",
    "\n",
    "**Hierarchia obiekt√≥w Unity Catalog:**\n",
    "```\n",
    "Metastore (region-level)\n",
    "    ‚Üì\n",
    "Catalog (domain/environment)\n",
    "    ‚Üì\n",
    "Schema (namespace/layer)\n",
    "    ‚Üì\n",
    "Securable Objects:\n",
    "    - Tables / Views (data)\n",
    "    - Functions (UDF, stored procedures)\n",
    "    - Volumes (file storage)\n",
    "    - Models (ML models)\n",
    "```\n",
    "\n",
    "**Kluczowe cechy:**\n",
    "- **Unified governance**: Jedna platforma dla danych, ML, BI\n",
    "- **ACID transactions**: Gwarancje transakcyjne na poziomie katalogu\n",
    "- **Audit logging**: Who accessed what and when\n",
    "- **Data discovery**: Metadata search i tagging\n",
    "- **Delta Sharing**: Secure cross-organization sharing\n",
    "\n",
    "**Dlaczego to wa≈ºne?**\n",
    "Unity Catalog rozwiƒÖzuje fundamentalne problemy governance w data lake:\n",
    "- Brak centralnej kontroli dostƒôpu\n",
    "- Trudno≈õci z ≈õledzeniem lineage\n",
    "- Brak audytu dostƒôpu do danych\n",
    "- Problemy z compliance (GDPR, HIPAA)\n",
    "- Silosy danych miƒôdzy zespo≈Çami\n",
    "\n",
    "Unity Catalog zapewnia enterprise-grade governance przy zachowaniu flexibility data lakehouse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d418241",
   "metadata": {},
   "source": [
    "## Izolacja per u≈ºytkownik\n",
    "\n",
    "Uruchom skrypt inicjalizacyjny dla per-user izolacji katalog√≥w i schemat√≥w:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03dbe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAGIC %run ../00_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fca07e",
   "metadata": {},
   "source": [
    "## Konfiguracja\n",
    "\n",
    "Import bibliotek i wy≈õwietlenie kontekstu u≈ºytkownika:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f242cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Wy≈õwietl kontekst u≈ºytkownika (zmienne z 00_setup)\n",
    "print(\"=\" * 80)\n",
    "print(\"UNITY CATALOG GOVERNANCE - KONTEKST U≈ªYTKOWNIKA\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Katalog: {CATALOG}\")\n",
    "print(f\"Schema Bronze: {BRONZE_SCHEMA}\")\n",
    "print(f\"Schema Silver: {SILVER_SCHEMA}\")\n",
    "print(f\"Schema Gold: {GOLD_SCHEMA}\")\n",
    "print(f\"U≈ºytkownik: {raw_user}\")\n",
    "print(f\"Dataset path: {DATASET_BASE_PATH}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Ustaw katalog i schemat jako domy≈õlne\n",
    "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
    "spark.sql(f\"USE SCHEMA {SILVER_SCHEMA}\")\n",
    "\n",
    "print(f\"\\n‚úì Aktywny katalog: {CATALOG}\")\n",
    "print(f\"‚úì Aktywny schemat: {SILVER_SCHEMA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fe5c93",
   "metadata": {},
   "source": [
    "## 2.1 Przygotowanie Danych z Dataset\n",
    "\n",
    "Zanim przejdziemy do zarzƒÖdzania dostƒôpami, wczytamy rzeczywiste dane z katalogu dataset/, kt√≥re bƒôdziemy u≈ºywaƒá w przyk≈Çadach Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fabd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie customers z dataset\n",
    "customers_path = \"/dbfs/FileStore/dataset/customers/customers.csv\"\n",
    "\n",
    "customers_df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(customers_path)\n",
    "\n",
    "print(f\"‚úì Wczytano {customers_df.count()} klient√≥w\")\n",
    "customers_df.printSchema()\n",
    "display(customers_df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0ea2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie orders z dataset\n",
    "orders_path = \"/dbfs/FileStore/dataset/orders/orders_batch.json\"\n",
    "\n",
    "orders_df = spark.read \\\n",
    "    .option(\"multiline\", \"true\") \\\n",
    "    .json(orders_path)\n",
    "\n",
    "print(f\"‚úì Wczytano {orders_df.count()} zam√≥wie≈Ñ\")\n",
    "orders_df.printSchema()\n",
    "display(orders_df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5384c1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie products z dataset\n",
    "products_path = \"/dbfs/FileStore/dataset/products/products.parquet\"\n",
    "\n",
    "products_df = spark.read.parquet(products_path)\n",
    "\n",
    "print(f\"‚úì Wczytano {products_df.count()} produkt√≥w\")\n",
    "products_df.printSchema()\n",
    "display(products_df.limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00540f64",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Unity Catalog Architecture\n",
    "\n",
    "**Unity Catalog** to zunifikowane rozwiƒÖzanie governance dla Databricks Lakehouse.\n",
    "\n",
    "### Hierarchia obiekt√≥w:\n",
    "\n",
    "```\n",
    "Metastore (region-level)\n",
    "    ‚Üì\n",
    "Catalog (database/domain)\n",
    "    ‚Üì\n",
    "Schema (namespace)\n",
    "    ‚Üì\n",
    "Securable Objects:\n",
    "    - Tables / Views\n",
    "    - Functions (UDF, stored procedures)\n",
    "    - Volumes (files storage)\n",
    "    - Models (ML models)\n",
    "```\n",
    "\n",
    "### Three-level namespace:\n",
    "```sql\n",
    "catalog.schema.table\n",
    "```\n",
    "\n",
    "Przyk≈Çad:\n",
    "```sql\n",
    "main.sales.orders\n",
    "dev.analytics.customer_metrics\n",
    "prod.gold.daily_revenue\n",
    "```\n",
    "\n",
    "### Kluczowe cechy:\n",
    "- **Unified governance**: jedna platforma dla danych, ML, BI\n",
    "- **Fine-grained access control**: table, column, row level\n",
    "- **Automatic lineage**: end-to-end data flow tracking\n",
    "- **Audit logging**: who accessed what and when\n",
    "- **Data discovery**: metadata search i tagging\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8736432",
   "metadata": {},
   "source": [
    "## üìã Setup i Basic Operations\n",
    "\n",
    "### Creating Catalogs and Schemas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7892116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Catalog\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE CATALOG IF NOT EXISTS {CATALOG}\n",
    "    COMMENT 'Katalog KION dla danych szkoleniowych'\n",
    "\"\"\")\n",
    "\n",
    "print(f\"‚úì Katalog '{CATALOG}' utworzony/zweryfikowany\")\n",
    "\n",
    "# List catalogs\n",
    "spark.sql(\"SHOW CATALOGS\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d941a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Schemas within catalog\n",
    "spark.sql(f\"\"\"\n",
    "  CREATE SCHEMA IF NOT EXISTS {CATALOG}.{BRONZE_SCHEMA}\n",
    "  COMMENT 'Bronze layer - surowe dane'\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "  CREATE SCHEMA IF NOT EXISTS {CATALOG}.{SILVER_SCHEMA}\n",
    "  COMMENT 'Silver layer - oczyszczone dane'\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "  CREATE SCHEMA IF NOT EXISTS {CATALOG}.{GOLD_SCHEMA}\n",
    "  COMMENT 'Gold layer - dane biznesowe'\n",
    "\"\"\")\n",
    "\n",
    "print(f\"‚úì Schematy Bronze, Silver, Gold utworzone w katalogu '{CATALOG}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8f47f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default catalog and schema\n",
    "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
    "spark.sql(f\"USE SCHEMA {SILVER_SCHEMA}\")\n",
    "\n",
    "print(f\"‚úì Aktywny katalog: {CATALOG}\")\n",
    "print(f\"‚úì Aktywny schemat: {SILVER_SCHEMA}\")\n",
    "\n",
    "# Weryfikacja utworzonych schemat√≥w\n",
    "schemas = spark.sql(f\"SHOW SCHEMAS IN {CATALOG}\").select(\"databaseName\").collect()\n",
    "schema_names = [row.databaseName for row in schemas]\n",
    "\n",
    "print(\"\\n‚úì Utworzone schematy w katalogu:\")\n",
    "for schema_name in schema_names:\n",
    "    print(f\"  - {schema_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6becaef",
   "metadata": {},
   "source": [
    "### Creating Tables in Unity Catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8b08e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapisanie tabeli customers w Bronze layer\n",
    "customers_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{CATALOG}.{BRONZE_SCHEMA}.customers\")\n",
    "\n",
    "print(f\"‚úì Tabela customers zapisana w {CATALOG}.{BRONZE_SCHEMA}\")\n",
    "\n",
    "# Weryfikacja\n",
    "result = spark.sql(f\"SELECT COUNT(*) as count FROM {CATALOG}.{BRONZE_SCHEMA}.customers\").collect()[0]\n",
    "print(f\"‚úì Liczba rekord√≥w: {result.count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd48272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add table properties and comments\n",
    "spark.sql(\"\"\"\n",
    "    ALTER TABLE kion_prod.silver.orders\n",
    "    SET TBLPROPERTIES (\n",
    "        'delta.enableChangeDataFeed' = 'true',\n",
    "        'delta.autoOptimize.optimizeWrite' = 'true',\n",
    "        'delta.autoOptimize.autoCompact' = 'true',\n",
    "        'owner' = 'data-engineering-team',\n",
    "        'department' = 'analytics',\n",
    "        'pii_data' = 'true'\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    COMMENT ON TABLE kion_prod.silver.orders IS\n",
    "    'Cleaned orders table with data quality validations applied'\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    COMMENT ON COLUMN kion_prod.silver.orders.customer_id IS\n",
    "    'Customer identifier - PII data, access restricted'\n",
    "\"\"\")\n",
    "\n",
    "# Zapisanie tabeli orders w Bronze layer\n",
    "orders_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{CATALOG}.{BRONZE_SCHEMA}.orders\")\n",
    "\n",
    "print(f\"‚úì Tabela orders zapisana w {CATALOG}.{BRONZE_SCHEMA}\")\n",
    "\n",
    "# Weryfikacja\n",
    "result = spark.sql(f\"SELECT COUNT(*) as count FROM {CATALOG}.{BRONZE_SCHEMA}.orders\").collect()[0]\n",
    "print(f\"‚úì Liczba rekord√≥w: {result.count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1000dd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapisanie tabeli products w Bronze layer\n",
    "products_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{CATALOG}.{BRONZE_SCHEMA}.products\")\n",
    "\n",
    "print(f\"‚úì Tabela products zapisana w {CATALOG}.{BRONZE_SCHEMA}\")\n",
    "\n",
    "# Weryfikacja\n",
    "result = spark.sql(f\"SELECT COUNT(*) as count FROM {CATALOG}.{BRONZE_SCHEMA}.products\").collect()[0]\n",
    "print(f\"‚úì Liczba rekord√≥w: {result.count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2390b00a",
   "metadata": {},
   "source": [
    "## 4. Unity Catalog Volumes\n",
    "\n",
    "**Volumes** to zarzƒÖdzane przestrzenie dla przechowywania plik√≥w (non-tabular data) w Unity Catalog:\n",
    "- **Managed Volumes**: Databricks zarzƒÖdza cyklem ≈ºycia plik√≥w\n",
    "- **External Volumes**: po≈ÇƒÖczenie z zewnƒôtrznymi lokalizacjami storage\n",
    "\n",
    "**Zastosowania**:\n",
    "- Przechowywanie plik√≥w ML models, checkpoints\n",
    "- Staging area dla danych przed ingestion\n",
    "- Archiwum dokument√≥w, log√≥w, raport√≥w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d31ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzenie Managed Volume\n",
    "volume_name = \"files\"\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "  CREATE VOLUME IF NOT EXISTS {CATALOG}.{BRONZE_SCHEMA}.{volume_name}\n",
    "  COMMENT 'Managed volume dla plik√≥w staging'\n",
    "\"\"\")\n",
    "\n",
    "print(f\"‚úì Volume '{volume_name}' utworzony w {CATALOG}.{BRONZE_SCHEMA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01e8172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przyk≈Çad: Zapisanie danych do Volume\n",
    "volume_path = f\"/Volumes/{CATALOG}/{BRONZE_SCHEMA}/{volume_name}\"\n",
    "\n",
    "# Eksport customers do CSV w Volume\n",
    "customers_df.coalesce(1).write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(f\"{volume_path}/customers_export\")\n",
    "\n",
    "print(f\"‚úì Dane customers wyeksportowane do Volume: {volume_path}/customers_export\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf24ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weryfikacja plik√≥w w Volume\n",
    "dbutils.fs.ls(f\"{volume_path}/customers_export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaa74c1",
   "metadata": {},
   "source": [
    "## 5. Unity Catalog Functions (UDF)\n",
    "\n",
    "**Functions** w Unity Catalog pozwalajƒÖ na:\n",
    "- Tworzenie reu≈ºywalnych funkcji SQL/Python\n",
    "- Centralne zarzƒÖdzanie logikƒÖ biznesowƒÖ\n",
    "- Kontrolƒô dostƒôpu przez GRANT/REVOKE\n",
    "- Lineage tracking dla funkcji\n",
    "\n",
    "**Rodzaje funkcji**:\n",
    "- **Scalar Functions**: zwracajƒÖ pojedynczƒÖ warto≈õƒá\n",
    "- **Table Functions**: zwracajƒÖ tabelƒô\n",
    "- **SQL Functions**: napisane w SQL\n",
    "- **Python Functions**: napisane w Python (UDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbd47a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przyk≈Çad 1: SQL Function - maskowanie customer_id\n",
    "spark.sql(f\"\"\"\n",
    "  CREATE OR REPLACE FUNCTION {CATALOG}.{SILVER_SCHEMA}.mask_customer_id(customer_id INT)\n",
    "  RETURNS STRING\n",
    "  LANGUAGE SQL\n",
    "  COMMENT 'Maskuje customer_id, pokazujƒÖc tylko ostatnie 3 cyfry'\n",
    "  RETURN CONCAT('****', SUBSTRING(CAST(customer_id AS STRING), -3))\n",
    "\"\"\")\n",
    "\n",
    "print(f\"‚úì Funkcja mask_customer_id utworzona w {CATALOG}.{SILVER_SCHEMA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ee1499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test funkcji mask_customer_id\n",
    "result_df = spark.sql(f\"\"\"\n",
    "  SELECT \n",
    "    customer_id,\n",
    "    {CATALOG}.{SILVER_SCHEMA}.mask_customer_id(customer_id) as masked_id,\n",
    "    first_name,\n",
    "    last_name\n",
    "  FROM {CATALOG}.{BRONZE_SCHEMA}.customers\n",
    "  LIMIT 5\n",
    "\"\"\")\n",
    "\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ad521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przyk≈Çad 2: Python UDF - kategoryzacja cen\n",
    "spark.sql(f\"\"\"\n",
    "  CREATE OR REPLACE FUNCTION {CATALOG}.{SILVER_SCHEMA}.categorize_price(price DOUBLE)\n",
    "  RETURNS STRING\n",
    "  LANGUAGE PYTHON\n",
    "  COMMENT 'Kategoryzuje ceny: Low, Medium, High'\n",
    "  AS $$\n",
    "    if price < 50:\n",
    "        return \"Low\"\n",
    "    elif price < 200:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "  $$\n",
    "\"\"\")\n",
    "\n",
    "print(f\"‚úì Funkcja categorize_price utworzona w {CATALOG}.{SILVER_SCHEMA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14403cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test funkcji categorize_price\n",
    "result_df = spark.sql(f\"\"\"\n",
    "  SELECT \n",
    "    product_name,\n",
    "    price,\n",
    "    {CATALOG}.{SILVER_SCHEMA}.categorize_price(price) as price_category\n",
    "  FROM {CATALOG}.{BRONZE_SCHEMA}.products\n",
    "  ORDER BY price\n",
    "  LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c83593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe table\n",
    "spark.sql(\"DESCRIBE EXTENDED kion_prod.silver.orders\").display()\n",
    "\n",
    "# Tworzenie View w Silver layer - agregacja zam√≥wie≈Ñ\n",
    "spark.sql(f\"\"\"\n",
    "  CREATE OR REPLACE VIEW {CATALOG}.{SILVER_SCHEMA}.customer_order_summary AS\n",
    "  SELECT \n",
    "    c.customer_id,\n",
    "    c.first_name,\n",
    "    c.last_name,\n",
    "    c.country,\n",
    "    COUNT(o.order_id) as total_orders,\n",
    "    SUM(o.total_amount) as total_spent,\n",
    "    AVG(o.total_amount) as avg_order_value,\n",
    "    MAX(o.order_datetime) as last_order_date\n",
    "  FROM {CATALOG}.{BRONZE_SCHEMA}.customers c\n",
    "  LEFT JOIN {CATALOG}.{BRONZE_SCHEMA}.orders o\n",
    "    ON c.customer_id = o.customer_id\n",
    "  GROUP BY c.customer_id, c.first_name, c.last_name, c.country\n",
    "\"\"\")\n",
    "\n",
    "print(f\"‚úì View customer_order_summary utworzony w {CATALOG}.{SILVER_SCHEMA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3375910",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ ZarzƒÖdzanie dostƒôpami: GRANT / REVOKE\n",
    "\n",
    "### Hierarchia Privileges w Unity Catalog:\n",
    "\n",
    "**Poziomy uprawnie≈Ñ**:\n",
    "1. **Metastore-level**: CREATE CATALOG, USE CATALOG\n",
    "2. **Catalog-level**: USE CATALOG, CREATE SCHEMA\n",
    "3. **Schema-level**: USE SCHEMA, CREATE TABLE, CREATE FUNCTION, CREATE VOLUME\n",
    "4. **Object-level**: SELECT, MODIFY (INSERT/UPDATE/DELETE/MERGE), EXECUTE\n",
    "\n",
    "**Securable Objects - Inheritance**:\n",
    "- Uprawnienia dziedziczƒÖ siƒô w d√≥≈Ç hierarchii\n",
    "- GRANT na Catalog ‚Üí dziedziczy na wszystkie Schemas i Tables\n",
    "- GRANT na Schema ‚Üí dziedziczy na wszystkie Tables w tym Schema\n",
    "- Mo≈ºna nadaƒá uprawnienia na konkretnym poziomie dla fine-grained control\n",
    "\n",
    "### Przyk≈Çady GRANT/REVOKE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f33b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grant catalog access to data analysts\n",
    "spark.sql(f\"\"\"\n",
    "    GRANT USE CATALOG ON CATALOG {CATALOG} TO `data-analysts`\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    GRANT USE SCHEMA ON SCHEMA {SCHEMA} TO `data-analysts`\n",
    "\"\"\")\n",
    "\n",
    "# Analysts can read gold tables\n",
    "spark.sql(f\"\"\"\n",
    "    GRANT SELECT ON SCHEMA {SCHEMA} TO `data-analysts`\n",
    "\"\"\")\n",
    "\n",
    "print(f\"‚úÖ Granted access to data-analysts group for catalog {CATALOG} and schema {SCHEMA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894117a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grant full access to data engineers\n",
    "spark.sql(\"\"\"\n",
    "    GRANT USE CATALOG, CREATE SCHEMA ON CATALOG kion_prod TO `data-engineers`\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "  GRANT USE SCHEMA ON SCHEMA {CATALOG}.{GOLD_SCHEMA} TO `data-analysts`\n",
    "\"\"\")\n",
    "\n",
    "# 3. GRANT SELECT na wszystkich tabelach w Gold\n",
    "spark.sql(f\"\"\"\n",
    "  GRANT SELECT ON SCHEMA {CATALOG}.{GOLD_SCHEMA} TO `data-analysts`\n",
    "\"\"\")\n",
    "\n",
    "print(f\"‚úì Grupa 'data-analysts' ma SELECT na {CATALOG}.{GOLD_SCHEMA}\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    GRANT ALL PRIVILEGES ON SCHEMA kion_prod.bronze TO `data-engineers`\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    GRANT ALL PRIVILEGES ON SCHEMA kion_prod.silver TO `data-engineers`\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    GRANT ALL PRIVILEGES ON SCHEMA kion_prod.gold TO `data-engineers`\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Granted full access to data-engineers group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8511ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grant specific table access\n",
    "spark.sql(\"\"\"\n",
    "    GRANT SELECT ON TABLE kion_prod.gold.daily_sales TO `finance-team`\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    GRANT SELECT ON TABLE kion_prod.gold.customer_metrics TO `marketing-team`\n",
    "\"\"\")\n",
    "\n",
    "# 4. GRANT ALL PRIVILEGES dla data-engineers\n",
    "spark.sql(f\"\"\"\n",
    "  GRANT ALL PRIVILEGES ON SCHEMA {CATALOG}.{BRONZE_SCHEMA} TO `data-engineers`\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "  GRANT ALL PRIVILEGES ON SCHEMA {CATALOG}.{SILVER_SCHEMA} TO `data-engineers`\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "  GRANT ALL PRIVILEGES ON SCHEMA {CATALOG}.{GOLD_SCHEMA} TO `data-engineers`\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Granted table-specific access\")\n",
    "print(f\"‚úì Grupa 'data-engineers' ma ALL PRIVILEGES na Bronze/Silver/Gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575390f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. GRANT EXECUTE na Function\n",
    "spark.sql(f\"\"\"\n",
    "  GRANT EXECUTE ON FUNCTION {CATALOG}.{SILVER_SCHEMA}.mask_customer_id TO `data-analysts`\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "  GRANT EXECUTE ON FUNCTION {CATALOG}.{SILVER_SCHEMA}.categorize_price TO `data-analysts`\n",
    "\"\"\")\n",
    "\n",
    "print(f\"‚úì Grupa 'data-analysts' ma EXECUTE na funkcjach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c599bf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show grants on object\n",
    "spark.sql(f\"\"\"\n",
    "    SHOW GRANTS ON TABLE {CATALOG}.{BRONZE_SCHEMA}.customers\n",
    "\"\"\").display()\n",
    "\n",
    "print(f\"‚úì Uprawnienia na tabeli customers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3a7986",
   "metadata": {},
   "source": [
    "### Ownership and transfer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8c1ef8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Data Masking i Row-Level Security\n",
    "\n",
    "### Column-level masking (Dynamic Views):\n",
    "\n",
    "U≈ºyj funkcji `current_user()` i `is_account_group_member()` do conditional masking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3d4a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create masked view for PII data\n",
    "spark.sql(f\"\"\"\n",
    "  CREATE OR REPLACE VIEW {CATALOG}.{GOLD_SCHEMA}.customers_masked AS\n",
    "  SELECT \n",
    "    customer_id,\n",
    "    CASE \n",
    "      WHEN is_account_group_member('pii-access-group') THEN first_name\n",
    "      ELSE CONCAT(LEFT(first_name, 1), '***')\n",
    "    END as first_name,\n",
    "    CASE \n",
    "      WHEN is_account_group_member('pii-access-group') THEN last_name\n",
    "      ELSE CONCAT(LEFT(last_name, 1), '***')\n",
    "    END as last_name,\n",
    "    city,\n",
    "    country,\n",
    "    registration_date\n",
    "  FROM {CATALOG}.{BRONZE_SCHEMA}.customers\n",
    "\"\"\")\n",
    "\n",
    "print(f\"‚úì View customers_masked utworzony w {CATALOG}.{GOLD_SCHEMA}\")\n",
    "print(\"  - PII-access-group: widzi pe≈Çne dane\")\n",
    "print(\"  - Inne grupy: widzi zamaskowane imiona i nazwiska\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f8d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test View z maskowaniem\n",
    "result_df = spark.sql(f\"\"\"\n",
    "  SELECT * FROM {CATALOG}.{GOLD_SCHEMA}.customers_masked LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "display(result_df)\n",
    "print(\"‚úì Dane z maskowaniem (imiona i nazwiska zamaskowane dla u≈ºytkownik√≥w bez pii-access-group)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71949761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatywnie: Hash sensitive identifiers\n",
    "spark.sql(f\"\"\"\n",
    "  CREATE OR REPLACE VIEW {CATALOG}.{GOLD_SCHEMA}.orders_hashed AS\n",
    "  SELECT \n",
    "    order_id,\n",
    "    SHA2(CAST(customer_id AS STRING), 256) as customer_id_hash,\n",
    "    product_id,\n",
    "    quantity,\n",
    "    total_amount,\n",
    "    order_datetime,\n",
    "    status\n",
    "  FROM {CATALOG}.{BRONZE_SCHEMA}.orders\n",
    "\"\"\")\n",
    "\n",
    "print(f\"‚úì View orders_hashed utworzony - customer_id jest zahashowany\")\n",
    "print(\"  - Analitycy mogƒÖ agregowaƒá bez ujawniania customer_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea8985c",
   "metadata": {},
   "source": [
    "### Row-Level Security (RLS):\n",
    "\n",
    "Restrict which rows users can see based on their identity or group membership:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7624f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create row-level security view - country access\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {CATALOG}.{GOLD_SCHEMA}.customers_rls AS\n",
    "    SELECT *\n",
    "    FROM {CATALOG}.{BRONZE_SCHEMA}.customers\n",
    "    WHERE \n",
    "        CASE \n",
    "            WHEN is_account_group_member('global-access') THEN TRUE\n",
    "            WHEN is_account_group_member('poland-team') THEN country = 'Poland'\n",
    "            WHEN is_account_group_member('germany-team') THEN country = 'Germany'\n",
    "            WHEN is_account_group_member('france-team') THEN country = 'France'\n",
    "            ELSE FALSE\n",
    "        END\n",
    "\"\"\")\n",
    "\n",
    "print(f\"‚úì RLS View utworzony - u≈ºytkownicy widzƒÖ tylko klient√≥w ze swojego kraju\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb7824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLS based on user attribute (e.g., department)\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE VIEW kion_prod.gold.sales_rls AS\n",
    "    SELECT \n",
    "        o.*,\n",
    "        d.department\n",
    "    FROM kion_prod.silver.orders o\n",
    "    JOIN kion_prod.silver.departments d ON o.department_id = d.department_id\n",
    "    WHERE \n",
    "        is_account_group_member('admin') OR\n",
    "        current_user() IN (\n",
    "            SELECT user_email \n",
    "            FROM kion_prod.gold.user_department_mapping \n",
    "            WHERE department = d.department\n",
    "        )\n",
    "\"\"\")\n",
    "\n",
    "# Users only see sales from their own department\n",
    "\n",
    "# RLS na zam√≥wieniach - tylko zam√≥wienia ze statusem zgodnym z uprawnieniami\n",
    "spark.sql(f\"\"\"\n",
    "  CREATE OR REPLACE VIEW {CATALOG}.{GOLD_SCHEMA}.orders_rls AS\n",
    "  SELECT \n",
    "    o.*\n",
    "  FROM {CATALOG}.{BRONZE_SCHEMA}.orders o\n",
    "  WHERE \n",
    "    is_account_group_member('admin') OR\n",
    "    (is_account_group_member('finance-team') AND o.status IN ('completed', 'shipped')) OR\n",
    "    (is_account_group_member('warehouse-team') AND o.status IN ('pending', 'processing', 'shipped'))\n",
    "\"\"\")\n",
    "\n",
    "print(f\"‚úì RLS View dla orders - u≈ºytkownicy widzƒÖ tylko zam√≥wienia zgodne z ich rolƒÖ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db342495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRANT dostƒôp do RLS View\n",
    "spark.sql(f\"\"\"\n",
    "  GRANT SELECT ON VIEW {CATALOG}.{GOLD_SCHEMA}.customers_rls TO `all-users`\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "  GRANT SELECT ON VIEW {CATALOG}.{GOLD_SCHEMA}.orders_rls TO `all-users`\n",
    "\"\"\")\n",
    "\n",
    "# Revoke direct access to base table\n",
    "spark.sql(\"\"\"\n",
    "    REVOKE SELECT ON TABLE kion_prod.silver.orders FROM `all-users`\n",
    "\"\"\")\n",
    "\n",
    "print(f\"‚úì U≈ºytkownicy majƒÖ dostƒôp przez RLS Views\")\n",
    "print(\"  - Automatyczne filtrowanie wierszy bazowane na group membership\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e25cdb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ Data Lineage i Audit Logging\n",
    "\n",
    "### Querying Data Lineage:\n",
    "\n",
    "Unity Catalog automatically tracks lineage for:\n",
    "- Table ‚Üí Table (ETL transformations)\n",
    "- Notebook ‚Üí Table (data writes)\n",
    "- Dashboard ‚Üí Table (BI queries)\n",
    "- ML Model ‚Üí Table (training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfa8af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query table lineage z system tables\n",
    "lineage_df = spark.sql(f\"\"\"\n",
    "  SELECT \n",
    "    source_table_full_name,\n",
    "    source_type,\n",
    "    target_table_full_name,\n",
    "    target_type,\n",
    "    created_at,\n",
    "    created_by\n",
    "  FROM system.access.table_lineage\n",
    "  WHERE target_table_full_name LIKE '{CATALOG}.%'\n",
    "  ORDER BY created_at DESC\n",
    "  LIMIT 50\n",
    "\"\"\")\n",
    "\n",
    "display(lineage_df)\n",
    "print(f\"‚úì Lineage dla tabel w katalogu {CATALOG}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e245a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find upstream dependencies (sources) for a table\n",
    "upstream_df = spark.sql(f\"\"\"\n",
    "    SELECT DISTINCT\n",
    "        source_table_full_name,\n",
    "        source_type\n",
    "    FROM system.access.table_lineage\n",
    "    WHERE target_table_full_name = '{CATALOG}.{SILVER_SCHEMA}.customer_order_summary'\n",
    "\"\"\")\n",
    "\n",
    "display(upstream_df)\n",
    "print(f\"‚¨ÜÔ∏è Upstream: tabele ≈∫r√≥d≈Çowe dla customer_order_summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7af191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find downstream dependencies (consumers) of a table\n",
    "downstream_df = spark.sql(f\"\"\"\n",
    "    SELECT DISTINCT\n",
    "        target_table_full_name,\n",
    "        target_type\n",
    "    FROM system.access.table_lineage\n",
    "    WHERE source_table_full_name = '{CATALOG}.{BRONZE_SCHEMA}.customers'\n",
    "\"\"\")\n",
    "\n",
    "display(downstream_df)\n",
    "print(f\"‚¨áÔ∏è Downstream: Views/Tables korzystajƒÖce z customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b603c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column-level lineage (if available)\n",
    "column_lineage = spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        source_table_full_name,\n",
    "        source_column_name,\n",
    "        target_table_full_name,\n",
    "        target_column_name,\n",
    "        created_at\n",
    "    FROM system.access.column_lineage\n",
    "    WHERE target_table_full_name = '{CATALOG}.{SILVER_SCHEMA}.customer_order_summary'\n",
    "    ORDER BY target_column_name\n",
    "\"\"\")\n",
    "display(column_lineage)\n",
    "\n",
    "print(f\"üìä Column-level lineage dla customer_order_summary View\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d463dc3a",
   "metadata": {},
   "source": [
    "### Audit Logging:\n",
    "\n",
    "Unity Catalog logs all access and operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19308d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query audit logs\n",
    "audit_df = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        event_time,\n",
    "        user_identity.email as user_email,\n",
    "        service_name,\n",
    "        action_name,\n",
    "        request_params.full_name_arg as table_name,\n",
    "        response.status_code,\n",
    "        request_id\n",
    "    FROM system.access.audit\n",
    "    WHERE action_name IN ('getTable', 'createTable', 'deleteTable', 'updateTable')\n",
    "        AND event_date >= current_date() - INTERVAL 7 DAYS\n",
    "    ORDER BY event_time DESC\n",
    "    LIMIT 100\n",
    "\"\"\")\n",
    "audit_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4d02b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track who accessed sensitive tables\n",
    "sensitive_access = spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        event_time,\n",
    "        user_identity.email as user,\n",
    "        action_name,\n",
    "        request_params.full_name_arg as table_accessed,\n",
    "        source_ip_address\n",
    "    FROM system.access.audit\n",
    "    WHERE request_params.full_name_arg LIKE '{CATALOG}.%.customers%'\n",
    "        AND action_name = 'getTable'\n",
    "        AND event_date >= current_date() - INTERVAL 7 DAYS\n",
    "    ORDER BY event_time DESC\n",
    "    LIMIT 100\n",
    "\"\"\")\n",
    "\n",
    "display(sensitive_access)\n",
    "print(f\"üîí Audit logs: dostƒôp do tabeli customers (ostatnie 7 dni)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef51dc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grant/Revoke audit trail\n",
    "grant_audit = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        event_time,\n",
    "        user_identity.email as admin_user,\n",
    "        action_name,\n",
    "        request_params.privilege as privilege_granted,\n",
    "        request_params.securable_full_name as object_name,\n",
    "        request_params.principal as grantee\n",
    "    FROM system.access.audit\n",
    "    WHERE action_name IN ('grantPrivilege', 'revokePrivilege')\n",
    "        AND event_date >= current_date() - INTERVAL 30 DAYS\n",
    "    ORDER BY event_time DESC\n",
    "\"\"\")\n",
    "grant_audit.display()\n",
    "\n",
    "print(\"üìù Audit trail of privilege changes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9122292",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Delta Sharing\n",
    "\n",
    "**Delta Sharing** = Secure data sharing protocol (cross-org, cross-cloud)\n",
    "\n",
    "### Komponenty:\n",
    "- **Share**: kolekcja tabel do udostƒôpnienia\n",
    "- **Recipient**: organizacja/u≈ºytkownik otrzymujƒÖcy dane\n",
    "- **Provider**: w≈Ça≈õciciel danych (Ty)\n",
    "\n",
    "### Create Share:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bb3ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzenie Share dla zewnƒôtrznych partner√≥w\n",
    "share_name = f\"{CATALOG}_partner_share\"\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "  CREATE SHARE IF NOT EXISTS {share_name}\n",
    "  COMMENT 'Udostƒôpnienie danych KION dla partner√≥w biznesowych'\n",
    "\"\"\")\n",
    "\n",
    "print(f\"‚úì Share '{share_name}' utworzony\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9627b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dodanie tabel do Share (tylko Gold layer - agregowane dane)\n",
    "spark.sql(f\"\"\"\n",
    "  ALTER SHARE {share_name}\n",
    "  ADD TABLE {CATALOG}.{GOLD_SCHEMA}.customer_order_summary\n",
    "\"\"\")\n",
    "\n",
    "print(f\"‚úì Tabela customer_order_summary dodana do {share_name}\")\n",
    "print(\"  - Partnerzy otrzymajƒÖ dostƒôp tylko do zagregowanych danych Gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12ecada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weryfikacja zawarto≈õci Share\n",
    "spark.sql(f\"SHOW ALL IN SHARE {share_name}\").display()\n",
    "\n",
    "print(f\"‚úì Tabele w Share: {share_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3497e790",
   "metadata": {},
   "source": [
    "### Create Recipient:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37c7981",
   "metadata": {},
   "source": [
    "### Consuming shared data (as recipient):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c93b7",
   "metadata": {},
   "source": [
    "### Best practices for Delta Sharing:\n",
    "\n",
    "1. **Share only aggregated/gold data**: nie udostƒôpniaj raw/bronze layers\n",
    "2. **Use views for masking**: create view with masked PII before sharing\n",
    "3. **Monitor access**: track who accesses shared data\n",
    "4. **Version control**: use table versions for stable APIs\n",
    "5. **Documentation**: clear documentation dla recipients\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf2d2a8",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Best Practices for Data Governance\n",
    "\n",
    "### 1. Catalog organization strategy:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa58af6",
   "metadata": {},
   "source": [
    "### 2. Access control patterns:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a885ac",
   "metadata": {},
   "source": [
    "### 3. Tagging and documentation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad092e3",
   "metadata": {},
   "source": [
    "### 4. Monitoring and alerts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d58defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular governance health checks\n",
    "\n",
    "# 1. Tables without owners\n",
    "unowned_tables = spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        table_catalog,\n",
    "        table_schema,\n",
    "        table_name\n",
    "    FROM system.information_schema.tables\n",
    "    WHERE table_catalog = '{CATALOG}'\n",
    "        AND table_owner IS NULL\n",
    "\"\"\")\n",
    "\n",
    "display(unowned_tables)\n",
    "print(\"‚ö†Ô∏è Tabele bez w≈Ça≈õcicieli (powinny mieƒá przypisanego owner)\")\n",
    "\n",
    "# 2. Tables without comments\n",
    "undocumented = spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        table_catalog,\n",
    "        table_schema,\n",
    "        table_name\n",
    "    FROM system.information_schema.tables\n",
    "    WHERE table_catalog = '{CATALOG}'\n",
    "        AND (comment IS NULL OR comment = '')\n",
    "\"\"\")\n",
    "\n",
    "display(undocumented)\n",
    "print(\"üìù Tabele bez dokumentacji (dodaj COMMENT ON TABLE)\")\n",
    "\n",
    "# 3. Unused tables (no queries in 90 days)\n",
    "unused_tables = spark.sql(f\"\"\"\n",
    "    WITH recent_access AS (\n",
    "        SELECT DISTINCT request_params.full_name_arg as table_name\n",
    "        FROM system.access.audit\n",
    "        WHERE action_name = 'getTable'\n",
    "            AND event_date >= current_date() - INTERVAL 90 DAYS\n",
    "    )\n",
    "    SELECT \n",
    "        t.table_catalog,\n",
    "        t.table_schema,\n",
    "        t.table_name,\n",
    "        t.created as table_created_at\n",
    "    FROM system.information_schema.tables t\n",
    "    LEFT JOIN recent_access ra \n",
    "        ON CONCAT(t.table_catalog, '.', t.table_schema, '.', t.table_name) = ra.table_name\n",
    "    WHERE t.table_catalog = '{CATALOG}'\n",
    "        AND ra.table_name IS NULL\n",
    "        AND t.created < current_date() - INTERVAL 90 DAYS\n",
    "\"\"\")\n",
    "unused_tables.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7bb92f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Podsumowanie\n",
    "\n",
    "### Nauczy≈Çe≈õ siƒô:\n",
    "\n",
    "‚úÖ **Unity Catalog Architecture**: Metastore ‚Üí Catalog ‚Üí Schema ‚Üí Tables  \n",
    "‚úÖ **Access Control**: GRANT/REVOKE privileges at multiple levels  \n",
    "‚úÖ **Data Masking**: Column-level masking with dynamic views  \n",
    "‚úÖ **Row-Level Security**: Filter data based on user identity  \n",
    "‚úÖ **Data Lineage**: Track data flow through system tables  \n",
    "‚úÖ **Audit Logging**: Monitor who accessed what and when  \n",
    "‚úÖ **Delta Sharing**: Secure cross-organization data sharing  \n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Unified Governance**: Single platform for all data assets\n",
    "2. **Fine-grained Control**: Table, column, row-level security\n",
    "3. **Automatic Lineage**: No extra instrumentation needed\n",
    "4. **Compliance-ready**: Audit logs for regulatory requirements\n",
    "5. **Secure Sharing**: Delta Sharing for external collaboration\n",
    "\n",
    "### Nastƒôpne kroki:\n",
    "- **Notebook 05**: BI & ML Integrations\n",
    "- **Workshop 03**: Governance + Integrations hands-on\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Dodatkowe zasoby\n",
    "\n",
    "- [Unity Catalog Documentation](https://docs.databricks.com/data-governance/unity-catalog/index.html)\n",
    "- [Delta Sharing Protocol](https://delta.io/sharing/)\n",
    "- [Unity Catalog Best Practices](https://docs.databricks.com/data-governance/unity-catalog/best-practices.html)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfd4273",
   "metadata": {},
   "source": [
    "## ‚úÖ Checklist - Unity Catalog Governance\n",
    "\n",
    "Po uko≈Ñczeniu tego notebooka powiniene≈õ umieƒá:\n",
    "\n",
    "- [ ] **UC Architecture**: Zrozumieƒá hierarchiƒô Metastore ‚Üí Catalog ‚Üí Schema ‚Üí Objects\n",
    "- [ ] **Tworzenie obiekt√≥w**: Utworzyƒá Catalog, Schema, Tables, Views, Volumes, Functions\n",
    "- [ ] **GRANT/REVOKE**: ZarzƒÖdzaƒá uprawnieniami na wszystkich poziomach\n",
    "- [ ] **Privileges**: Rozumieƒá SELECT, MODIFY, CREATE TABLE, EXECUTE\n",
    "- [ ] **Data Masking**: Tworzyƒá Views z maskowaniem wra≈ºliwych danych\n",
    "- [ ] **Row-Level Security**: Implementowaƒá RLS bazowane na group membership\n",
    "- [ ] **Lineage**: ≈öledziƒá upstream/downstream dependencies\n",
    "- [ ] **Audit Logging**: Zapytywaƒá system.access.audit o aktywno≈õƒá u≈ºytkownik√≥w\n",
    "- [ ] **Delta Sharing**: Tworzyƒá Share i udostƒôpniaƒá dane zewnƒôtrznym recipientom\n",
    "- [ ] **Best Practices**: Monitorowaƒá governance health (owners, documentation, unused tables)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369b47c8",
   "metadata": {},
   "source": [
    "## üîß Troubleshooting\n",
    "\n",
    "### Problem 1: \"Table or view not found\"\n",
    "**Przyczyna**: Brak uprawnie≈Ñ USE CATALOG lub USE SCHEMA  \n",
    "**RozwiƒÖzanie**:\n",
    "```sql\n",
    "GRANT USE CATALOG ON CATALOG <catalog_name> TO <principal>;\n",
    "GRANT USE SCHEMA ON SCHEMA <catalog>.<schema> TO <principal>;\n",
    "```\n",
    "\n",
    "### Problem 2: \"Permission denied\" przy SELECT\n",
    "**Przyczyna**: Brak uprawnie≈Ñ SELECT na tabeli  \n",
    "**RozwiƒÖzanie**:\n",
    "```sql\n",
    "GRANT SELECT ON TABLE <catalog>.<schema>.<table> TO <principal>;\n",
    "-- lub na ca≈Çym schema:\n",
    "GRANT SELECT ON SCHEMA <catalog>.<schema> TO <principal>;\n",
    "```\n",
    "\n",
    "### Problem 3: \"Cannot execute function\"\n",
    "**Przyczyna**: Brak uprawnienia EXECUTE na funkcji  \n",
    "**RozwiƒÖzanie**:\n",
    "```sql\n",
    "GRANT EXECUTE ON FUNCTION <catalog>.<schema>.<function_name> TO <principal>;\n",
    "```\n",
    "\n",
    "### Problem 4: \"Volume not accessible\"\n",
    "**Przyczyna**: Brak uprawnie≈Ñ READ VOLUME / WRITE VOLUME  \n",
    "**RozwiƒÖzanie**:\n",
    "```sql\n",
    "GRANT READ VOLUME ON VOLUME <catalog>.<schema>.<volume> TO <principal>;\n",
    "GRANT WRITE VOLUME ON VOLUME <catalog>.<schema>.<volume> TO <principal>;\n",
    "```\n",
    "\n",
    "### Problem 5: RLS View nie filtruje danych\n",
    "**Przyczyna**: U≈ºytkownik nie nale≈ºy do ≈ºadnej grupy zdefiniowanej w CASE WHEN  \n",
    "**RozwiƒÖzanie**: Dodaj u≈ºytkownika do odpowiedniej grupy lub dodaj domy≈õlny fallback w View\n",
    "\n",
    "### Problem 6: Lineage nie pokazuje zale≈ºno≈õci\n",
    "**Przyczyna**: Lineage jest automatyczne, ale mo≈ºe op√≥≈∫niaƒá siƒô o kilka minut  \n",
    "**RozwiƒÖzanie**: Poczekaj 5-10 minut i ponownie zapytaj system.access.table_lineage\n",
    "\n",
    "### Problem 7: Share nie widoczny dla recipient\n",
    "**Przyczyna**: Recipient nie aktywowa≈Ç activation link  \n",
    "**RozwiƒÖzanie**: Wy≈õlij activation link z DESCRIBE RECIPIENT\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f38cd24",
   "metadata": {},
   "source": [
    "## üèÜ Best Practices Summary\n",
    "\n",
    "### 1. **Catalog Organization**\n",
    "- ‚úÖ U≈ºywaj environment-based catalogs: `dev`, `test`, `prod`\n",
    "- ‚úÖ Organizuj schematy wed≈Çug warstw: `bronze`, `silver`, `gold`\n",
    "- ‚úÖ Stosuj naming conventions: `<catalog>.<schema>.<object>`\n",
    "\n",
    "### 2. **Access Control**\n",
    "- ‚úÖ **Principle of Least Privilege**: Nadawaj minimalne wymagane uprawnienia\n",
    "- ‚úÖ U≈ºywaj grup, nie indywidualnych u≈ºytkownik√≥w\n",
    "- ‚úÖ Inheritance: GRANT na Catalog ‚Üí dziedziczy na Schema ‚Üí dziedziczy na Tables\n",
    "- ‚úÖ Regularnie audytuj uprawnienia (SHOW GRANTS)\n",
    "\n",
    "### 3. **Data Masking & RLS**\n",
    "- ‚úÖ Maskuj PII w Views dla u≈ºytkownik√≥w bez pii-access-group\n",
    "- ‚úÖ U≈ºywaj RLS dla multi-tenant scenarios\n",
    "- ‚úÖ Zawsze testuj masking z r√≥≈ºnymi group membership\n",
    "\n",
    "### 4. **Lineage & Audit**\n",
    "- ‚úÖ Wykorzystuj automatic lineage do ≈õledzenia data flow\n",
    "- ‚úÖ Regularnie sprawdzaj audit logs dla sensitive tables\n",
    "- ‚úÖ Monitoruj lineage po zmianach w pipeline\n",
    "\n",
    "### 5. **Delta Sharing**\n",
    "- ‚úÖ Udostƒôpniaj tylko Gold layer (aggregated data)\n",
    "- ‚úÖ U≈ºywaj masked Views w Share\n",
    "- ‚úÖ Dokumentuj Share contracts dla recipients\n",
    "\n",
    "### 6. **Documentation & Governance**\n",
    "- ‚úÖ Dodawaj COMMENT do wszystkich tabel, views, functions\n",
    "- ‚úÖ U≈ºywaj Table Properties dla metadata (owner, PII, retention)\n",
    "- ‚úÖ Regularnie sprawdzaj governance health checks\n",
    "\n",
    "### 7. **Volumes & Functions**\n",
    "- ‚úÖ U≈ºywaj Managed Volumes dla ML artifacts i staging\n",
    "- ‚úÖ Centralizuj logikƒô biznesowƒÖ w UC Functions\n",
    "- ‚úÖ Kontroluj dostƒôp przez GRANT EXECUTE\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
