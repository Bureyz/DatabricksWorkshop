{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b79fe2f8",
   "metadata": {},
   "source": [
    "# Warsztat 1: Advanced PySpark Transformations\n",
    "\n",
    "**Cel warsztatu:**\n",
    "- Praktyczne zastosowanie Window Functions (lag, lead, rank, rolling aggregations)\n",
    "- Przetwarzanie z≈Ço≈ºonych struktur (JSON, arrays, structs)\n",
    "- Zaawansowane operacje na datach i czasie\n",
    "- Optymalizacja transformacji dla wydajno≈õci\n",
    "\n",
    "**Czas:** 90 minut\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b049d992",
   "metadata": {},
   "source": [
    "## üìö Inicjalizacja ≈õrodowiska"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06065d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../00_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7079deec",
   "metadata": {},
   "source": [
    "## üéØ Konfiguracja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7cc526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Wy≈õwietl kontekst u≈ºytkownika\n",
    "print(\"=== Kontekst u≈ºytkownika ===\")\n",
    "print(f\"Katalog: {CATALOG}\")\n",
    "print(f\"Schema: {BRONZE_SCHEMA}\")\n",
    "print(f\"U≈ºytkownik: {raw_user}\")\n",
    "\n",
    "# Ustaw katalog i schemat jako domy≈õlne\n",
    "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
    "spark.sql(f\"USE SCHEMA {BRONZE_SCHEMA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba81015",
   "metadata": {},
   "source": [
    "## üìä Przygotowanie danych z Databricks Volume\n",
    "\n",
    "Wczytaj dane z Databricks Volume dla warsztat√≥w:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28939c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ≈öcie≈ºka do Volume\n",
    "volume_path = \"/Volumes/main/default/kion_data\"\n",
    "\n",
    "# Wczytanie danych klient√≥w\n",
    "customers_df = spark.read.csv(f\"{volume_path}/customers/customers.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Wczytanie danych zam√≥wie≈Ñ (batch)\n",
    "orders_df = spark.read.json(f\"{volume_path}/orders/orders_batch.json\")\n",
    "\n",
    "# Wczytanie danych produkt√≥w\n",
    "products_df = spark.read.parquet(f\"{volume_path}/products/products.parquet\")\n",
    "\n",
    "# Przygotowanie z≈ÇƒÖczonego widoku dla ƒáwicze≈Ñ\n",
    "test_orders = (\n",
    "    orders_df\n",
    "    .join(customers_df, \"customer_id\")\n",
    "    .join(products_df, \"product_id\")\n",
    "    .select(\n",
    "        \"order_id\",\n",
    "        \"customer_id\",\n",
    "        F.col(\"order_date\").cast(\"date\").alias(\"order_date\"),\n",
    "        F.col(\"total_amount\"),\n",
    "        F.col(\"status\")\n",
    "    )\n",
    ")\n",
    "\n",
    "test_orders.createOrReplaceTempView(\"orders\")\n",
    "display(test_orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb614d00",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ü™ü Czƒô≈õƒá 1: Window Functions\n",
    "\n",
    "### Zadanie 1.1: Ranking - ROW_NUMBER, RANK, DENSE_RANK\n",
    "\n",
    "**Instrukcje:**\n",
    "1. Dla ka≈ºdego klienta, uszereguj zam√≥wienia po dacie (od najnowszego)\n",
    "2. Dodaj kolumny:\n",
    "   - `row_num`: u≈ºywajƒÖc `row_number()`\n",
    "   - `rank`: u≈ºywajƒÖc `rank()`\n",
    "   - `dense_rank`: u≈ºywajƒÖc `dense_rank()`\n",
    "3. Window spec: `partitionBy(\"customer_id\").orderBy(F.desc(\"order_date\"))`\n",
    "\n",
    "**Oczekiwany rezultat:**\n",
    "- Ka≈ºdy klient ma zam√≥wienia ponumerowane od 1 (najnowsze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04376587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zadanie 1.1 - Ranking functions\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Definicja window spec\n",
    "window_spec = Window.____(\"____\").orderBy(F.____(\"____\"))  # partitionBy customer_id, orderBy desc order_date\n",
    "\n",
    "# Dodaj kolumny ranking\n",
    "orders_ranked = (\n",
    "    test_orders\n",
    "    .withColumn(\"row_num\", F.____().____(window_spec))  # row_number, over\n",
    "    .withColumn(\"rank\", F.____().over(____))  # rank, window_spec\n",
    "    .withColumn(\"dense_rank\", F.____().over(window_spec))  # dense_rank\n",
    ")\n",
    "\n",
    "display(orders_ranked.orderBy(\"customer_id\", \"order_date\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8efa955",
   "metadata": {},
   "source": [
    "**Wyja≈õnienie r√≥≈ºnic:**\n",
    "\n",
    "- **ROW_NUMBER**: Unikalne numery sekwencyjne (1, 2, 3...)\n",
    "- **RANK**: Luki w numeracji przy r√≥wnych warto≈õciach (1, 2, 2, 4...)\n",
    "- **DENSE_RANK**: Brak luk przy r√≥wnych warto≈õciach (1, 2, 2, 3...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69daf8af",
   "metadata": {},
   "source": [
    "### Zadanie 1.2: LAG i LEAD - Por√≥wnanie z poprzednimi/nastƒôpnymi warto≈õciami\n",
    "\n",
    "**Instrukcje:**\n",
    "1. Dla ka≈ºdego klienta, oblicz:\n",
    "   - `previous_order_amount`: warto≈õƒá poprzedniego zam√≥wienia (u≈ºywajƒÖc `lag`)\n",
    "   - `next_order_amount`: warto≈õƒá nastƒôpnego zam√≥wienia (u≈ºywajƒÖc `lead`)\n",
    "   - `amount_diff_vs_previous`: r√≥≈ºnica miƒôdzy aktualnym a poprzednim\n",
    "2. Window spec: `partitionBy(\"customer_id\").orderBy(\"order_date\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5cbec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zadanie 1.2 - LAG i LEAD\n",
    "\n",
    "# Window spec - porzƒÖdek chronologiczny\n",
    "window_chrono = Window.partitionBy(\"____\").orderBy(\"____\")  # customer_id, order_date\n",
    "\n",
    "# U≈ºyj LAG i LEAD\n",
    "orders_lag_lead = (\n",
    "    test_orders\n",
    "    .withColumn(\"previous_order_amount\", F.____(____, ____).over(____))  # lag, total_amount, 1, window_chrono\n",
    "    .withColumn(\"next_order_amount\", F.____(____, 1).over(window_chrono))  # lead, total_amount\n",
    "    .withColumn(\n",
    "        \"amount_diff_vs_previous\",\n",
    "        F.col(\"____\") - F.col(\"____\")  # total_amount, previous_order_amount\n",
    "    )\n",
    ")\n",
    "\n",
    "display(orders_lag_lead.select(\n",
    "    \"customer_id\", \"order_date\", \"total_amount\", \n",
    "    \"previous_order_amount\", \"next_order_amount\", \"amount_diff_vs_previous\"\n",
    ").orderBy(\"customer_id\", \"order_date\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8ac7c9",
   "metadata": {},
   "source": [
    "### Zadanie 1.3: Rolling Aggregations - ≈örednie ruchome\n",
    "\n",
    "**Instrukcje:**\n",
    "1. Oblicz ≈õredniƒÖ ruchomƒÖ (rolling average) dla kwoty zam√≥wienia:\n",
    "   - Okno: 3 ostatnie zam√≥wienia (current + 2 poprzednie)\n",
    "2. U≈ºyj `.rowsBetween(-2, 0)` dla window spec\n",
    "3. Dodaj kolumnƒô `rolling_avg_3_orders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db295511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zadanie 1.3 - Rolling aggregations\n",
    "\n",
    "# Window spec z rowsBetween\n",
    "window_rolling = (\n",
    "    Window\n",
    "    .partitionBy(\"customer_id\")\n",
    "    .orderBy(\"order_date\")\n",
    "    .____(____, ____)  # rowsBetween, -2, 0 (3 ostatnie rekordy)\n",
    ")\n",
    "\n",
    "# Rolling average\n",
    "orders_rolling = (\n",
    "    test_orders\n",
    "    .withColumn(\n",
    "        \"rolling_avg_3_orders\",\n",
    "        F.____(\"____\").over(____)  # avg, total_amount, window_rolling\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"rolling_sum_3_orders\",\n",
    "        F.sum(\"total_amount\").over(window_rolling)\n",
    "    )\n",
    ")\n",
    "\n",
    "display(orders_rolling.select(\n",
    "    \"customer_id\", \"order_date\", \"total_amount\", \n",
    "    \"rolling_avg_3_orders\", \"rolling_sum_3_orders\"\n",
    ").orderBy(\"customer_id\", \"order_date\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da347e5",
   "metadata": {},
   "source": [
    "### Zadanie 1.4: Cumulative Sum - Suma narastajƒÖca\n",
    "\n",
    "**Instrukcje:**\n",
    "1. Oblicz sumƒô narastajƒÖcƒÖ (cumulative sum) kwot zam√≥wie≈Ñ per klient\n",
    "2. U≈ºyj `.rowsBetween(Window.unboundedPreceding, Window.currentRow)`\n",
    "3. Dodaj kolumnƒô `cumulative_amount`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc2f185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zadanie 1.4 - Cumulative sum\n",
    "\n",
    "# Window spec dla cumulative\n",
    "window_cumulative = (\n",
    "    Window\n",
    "    .partitionBy(\"____\")\n",
    "    .orderBy(\"____\")\n",
    "    .rowsBetween(Window.____, Window.____)  # unboundedPreceding, currentRow\n",
    ")\n",
    "\n",
    "# Cumulative sum\n",
    "orders_cumulative = (\n",
    "    test_orders\n",
    "    .withColumn(\n",
    "        \"cumulative_amount\",\n",
    "        F.____(____(\"____\")).over(window_cumulative)  # round, sum total_amount\n",
    "    )\n",
    ")\n",
    "\n",
    "display(orders_cumulative.select(\n",
    "    \"customer_id\", \"order_date\", \"total_amount\", \"cumulative_amount\"\n",
    ").orderBy(\"customer_id\", \"order_date\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b5e47e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üóÇÔ∏è Czƒô≈õƒá 2: Przetwarzanie z≈Ço≈ºonych struktur\n",
    "\n",
    "### Zadanie 2.1: JSON Processing - from_json() i explode()\n",
    "\n",
    "**Instrukcje:**\n",
    "1. Wczytaj dane JSON z Volume (orders)\n",
    "2. U≈ºyj `from_json()` do sparsowania JSON je≈õli potrzeba\n",
    "3. U≈ºyj `explode()` do \"rozpakowania\" array\n",
    "4. WyciƒÖgnij pola z nested struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26a6c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytaj dane JSON z Volume (zam√≥wienia mogƒÖ zawieraƒá nested structures)\n",
    "# Volume zawiera ju≈º sparsowane JSON, ale mo≈ºemy stworzyƒá przyk≈Çad z zagnie≈ºd≈ºonƒÖ strukturƒÖ\n",
    "\n",
    "# Opcja 1: U≈ºyj danych z Volume i stw√≥rz nested JSON\n",
    "json_orders = spark.read.json(f\"{volume_path}/orders/orders_batch.json\")\n",
    "\n",
    "# Opcja 2: Dla ƒáwicze≈Ñ stw√≥rz testowe dane z zagnie≈ºd≈ºonym JSON string\n",
    "json_data = spark.createDataFrame([\n",
    "    (1, '{\"items\": [{\"product\": \"laptop\", \"price\": 1200}, {\"product\": \"mouse\", \"price\": 25}], \"total\": 1225}'),\n",
    "    (2, '{\"items\": [{\"product\": \"keyboard\", \"price\": 80}], \"total\": 80}'),\n",
    "    (3, '{\"items\": [{\"product\": \"monitor\", \"price\": 350}, {\"product\": \"cable\", \"price\": 15}], \"total\": 365}')\n",
    "], [\"order_id\", \"order_json\"])\n",
    "\n",
    "display(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcd357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zadanie 2.1 - JSON processing\n",
    "\n",
    "# Definicja schematu JSON\n",
    "json_schema = StructType([\n",
    "    StructField(\"items\", ArrayType(StructType([\n",
    "        StructField(\"product\", StringType()),\n",
    "        StructField(\"price\", IntegerType())\n",
    "    ]))),\n",
    "    StructField(\"total\", IntegerType())\n",
    "])\n",
    "\n",
    "# Parse JSON\n",
    "orders_parsed = (\n",
    "    json_data\n",
    "    .withColumn(\"parsed\", F.____(____(\"____\"), ____))  # from_json, order_json, json_schema\n",
    ")\n",
    "\n",
    "display(orders_parsed.select(\"order_id\", \"parsed\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa66a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Explode array i wyciƒÖgnij pola\n",
    "\n",
    "orders_exploded = (\n",
    "    orders_parsed\n",
    "    .withColumn(\"item\", F.____(\"____\"))  # explode, parsed.items\n",
    "    .select(\n",
    "        \"order_id\",\n",
    "        F.col(\"____\").alias(\"product_name\"),  # item.product\n",
    "        F.col(\"____\").alias(\"product_price\"),  # item.price\n",
    "        F.col(\"____\").alias(\"order_total\")  # parsed.total\n",
    "    )\n",
    ")\n",
    "\n",
    "display(orders_exploded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8f6ca2",
   "metadata": {},
   "source": [
    "### Zadanie 2.2: Array Functions - collect_list, array_contains\n",
    "\n",
    "**Instrukcje:**\n",
    "1. Zgrupuj zam√≥wienia per klient\n",
    "2. U≈ºyj `collect_list()` do zebrania wszystkich kwot zam√≥wie≈Ñ w array\n",
    "3. U≈ºyj `array_contains()` do sprawdzenia czy klient ma zam√≥wienie > 500\n",
    "4. U≈ºyj `size()` do zliczenia liczby zam√≥wie≈Ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec89493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zadanie 2.2 - Array functions\n",
    "\n",
    "customer_arrays = (\n",
    "    test_orders\n",
    "    .groupBy(\"____\")  # customer_id\n",
    "    .agg(\n",
    "        F.____(____(\"____\")).alias(\"order_amounts\"),  # collect_list, total_amount\n",
    "        F.collect_list(\"order_date\").alias(\"order_dates\"),\n",
    "        F.count(\"*\").alias(\"total_orders\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"num_orders\",\n",
    "        F.____(\"____\")  # size, order_amounts\n",
    "    )\n",
    ")\n",
    "\n",
    "display(customer_arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cba817",
   "metadata": {},
   "source": [
    "### Zadanie 2.3: Struct - ≈ÅƒÖczenie kolumn w struktury\n",
    "\n",
    "**Instrukcje:**\n",
    "1. Utw√≥rz struct `customer_info` zawierajƒÖcy: customer_id, total_orders\n",
    "2. Utw√≥rz struct `order_summary` zawierajƒÖcy: min/max/avg amount\n",
    "3. WyciƒÖgnij pola ze struct u≈ºywajƒÖc `.` notacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b221a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zadanie 2.3 - Struct operations\n",
    "\n",
    "customer_structs = (\n",
    "    test_orders\n",
    "    .groupBy(\"customer_id\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"total_orders\"),\n",
    "        F.min(\"total_amount\").alias(\"min_amount\"),\n",
    "        F.max(\"total_amount\").alias(\"max_amount\"),\n",
    "        F.avg(\"total_amount\").alias(\"avg_amount\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"customer_info\",\n",
    "        F.____(\"____\", \"____\")  # struct, customer_id, total_orders\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"order_summary\",\n",
    "        F.struct(\"min_amount\", \"____\", \"____\")  # max_amount, avg_amount\n",
    "    )\n",
    ")\n",
    "\n",
    "display(customer_structs.select(\"customer_info\", \"order_summary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d4e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WyciƒÖgnij pola ze struct\n",
    "customer_flat = (\n",
    "    customer_structs\n",
    "    .select(\n",
    "        F.col(\"customer_info.____\").alias(\"customer_id\"),  # customer_id\n",
    "        F.col(\"order_summary.____\").alias(\"avg_order_value\")  # avg_amount\n",
    "    )\n",
    ")\n",
    "\n",
    "display(customer_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdf507d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìÖ Czƒô≈õƒá 3: Zaawansowane operacje na datach\n",
    "\n",
    "### Zadanie 3.1: Date truncation i extraction\n",
    "\n",
    "**Instrukcje:**\n",
    "1. U≈ºyj `date_trunc()` do zaokrƒÖglenia dat do: month, quarter, year\n",
    "2. U≈ºyj `year()`, `month()`, `dayofweek()` do ekstrakcji czƒô≈õci daty\n",
    "3. Oblicz `days_since_order` (r√≥≈ºnica miƒôdzy dzisiaj a datƒÖ zam√≥wienia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ae6bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zadanie 3.1 - Date functions\n",
    "\n",
    "orders_dates = (\n",
    "    test_orders\n",
    "    .withColumn(\"order_month\", F.____(____(\"____\"), \"____\"))  # date_trunc, order_date, month\n",
    "    .withColumn(\"order_quarter\", F.date_trunc(\"____\", \"order_date\"))  # quarter\n",
    "    .withColumn(\"order_year_num\", F.____(\"____\"))  # year, order_date\n",
    "    .withColumn(\"order_month_num\", F.____(____(\"____\")))  # month, order_date\n",
    "    .withColumn(\"day_of_week\", F.____(____(\"order_date\")))  # dayofweek\n",
    "    .withColumn(\n",
    "        \"days_since_order\",\n",
    "        F.datediff(F.____, \"____\")  # current_date, order_date\n",
    "    )\n",
    ")\n",
    "\n",
    "display(orders_dates.select(\n",
    "    \"order_id\", \"order_date\", \"order_month\", \"order_quarter\",\n",
    "    \"order_year_num\", \"order_month_num\", \"day_of_week\", \"days_since_order\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faf8565",
   "metadata": {},
   "source": [
    "### Zadanie 3.2: Date arithmetic - dodawanie/odejmowanie okres√≥w\n",
    "\n",
    "**Instrukcje:**\n",
    "1. U≈ºyj `date_add()` do dodania 30 dni do daty zam√≥wienia\n",
    "2. U≈ºyj `add_months()` do dodania 3 miesiƒôcy\n",
    "3. U≈ºyj `last_day()` do uzyskania ostatniego dnia miesiƒÖca\n",
    "4. U≈ºyj `next_day()` do uzyskania najbli≈ºszego poniedzia≈Çku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c0b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zadanie 3.2 - Date arithmetic\n",
    "\n",
    "orders_date_math = (\n",
    "    test_orders\n",
    "    .withColumn(\"delivery_date_estimate\", F.____(____(\"____\"), ____))  # date_add, order_date, 30\n",
    "    .withColumn(\"renewal_date\", F.____(____(\"order_date\"), ____))  # add_months, 3\n",
    "    .withColumn(\"month_end\", F.____(____(\"____\")))  # last_day, order_date\n",
    "    .withColumn(\"next_monday\", F.next_day(\"____\", \"____\"))  # order_date, Monday\n",
    ")\n",
    "\n",
    "display(orders_date_math.select(\n",
    "    \"order_date\", \"delivery_date_estimate\", \"renewal_date\", \n",
    "    \"month_end\", \"next_monday\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91643db",
   "metadata": {},
   "source": [
    "### Zadanie 3.3: Generowanie sekwencji dat\n",
    "\n",
    "**Instrukcje:**\n",
    "1. U≈ºyj `sequence()` do wygenerowania array dat miƒôdzy dwoma datami\n",
    "2. U≈ºyj `explode()` do utworzenia jednego wiersza per data\n",
    "3. Stw√≥rz calendar table z wszystkimi dniami miƒôdzy min a max order_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10cdbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zadanie 3.3 - Date sequences\n",
    "\n",
    "# Znajd≈∫ min i max dates\n",
    "date_range = test_orders.select(\n",
    "    F.min(\"order_date\").alias(\"min_date\"),\n",
    "    F.max(\"order_date\").alias(\"max_date\")\n",
    ").first()\n",
    "\n",
    "# Generuj sekwencjƒô dat\n",
    "calendar = (\n",
    "    spark.range(1)\n",
    "    .select(\n",
    "        F.____(  # explode\n",
    "            F.____(\n",
    "                F.lit(date_range[\"____\"]),  # min_date\n",
    "                F.lit(date_range[\"max_date\"]),\n",
    "                F.expr(\"____\")  # interval 1 day\n",
    "            )\n",
    "        ).alias(\"date\")\n",
    "    )\n",
    "    .withColumn(\"year\", F.year(\"date\"))\n",
    "    .withColumn(\"month\", F.____(____(\"____\")))  # month, date\n",
    "    .withColumn(\"day_of_week\", F.dayofweek(\"date\"))\n",
    ")\n",
    "\n",
    "print(f\"Calendar table: {calendar.count()} dni\")\n",
    "display(calendar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68a6a2b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Podsumowanie warsztatu\n",
    "\n",
    "**Zrealizowane cele:**\n",
    "- ‚úÖ Window Functions (ranking, lag/lead, rolling aggregations, cumulative sum)\n",
    "- ‚úÖ Przetwarzanie JSON (from_json, explode, struct)\n",
    "- ‚úÖ Array operations (collect_list, array_contains, size)\n",
    "- ‚úÖ Zaawansowane operacje na datach (truncation, arithmetic, sequences)\n",
    "\n",
    "**Kluczowe wnioski:**\n",
    "1. Window Functions pozwalajƒÖ na analizy per grupa bez GROUP BY\n",
    "2. JSON i struktury z≈Ço≈ºone sƒÖ native w Spark\n",
    "3. Date functions umo≈ºliwiajƒÖ zaawansowane analizy temporalne\n",
    "4. Optymalizacja: u≈ºyj broadcast dla ma≈Çych tabel w JOIN\n",
    "\n",
    "**Best Practices:**\n",
    "- Window Functions: zawsze definiuj explicit window spec\n",
    "- JSON: u≈ºywaj schema inference tylko dla exploratation\n",
    "- Dates: u≈ºywaj native date types (nie string)\n",
    "- Performance: cache() dla czƒôsto u≈ºywanych DataFrame\n",
    "\n",
    "---\n",
    "\n",
    "## üßπ Cleanup (opcjonalnie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d24a164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyczy≈õƒá temporary views\n",
    "# spark.catalog.dropTempView(\"orders\")\n",
    "# spark.catalog.clearCache()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
